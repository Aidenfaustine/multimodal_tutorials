{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "def one_hot(i):\n",
    "    a=[0 for ii in range(7)]\n",
    "    a[i]=1\n",
    "    return a\n",
    "\n",
    "\n",
    "def get_data_train():\n",
    "    label_transform = {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger': 6}\n",
    "    data_dict = {}\n",
    "    csv_path_train ='C:/Users/faustineljc/Desktop/train_mfcc'\n",
    "    csv_files_train = os.listdir(csv_path_train)\n",
    "    #print(csv_files_train)\n",
    "    csv_files_train.sort(key=lambda x:(int(x.split(\"_\")[0][3:]), int(x.split('_')[1][3:-4])))\n",
    "    for i in range(len(csv_files_train)):\n",
    "        csv_files_train[i]=csv_files_train[i][:-4]\n",
    "    with open('C:/Users/faustineljc/Desktop/melddatasets.yaml', 'rb') as stream:\n",
    "        try:\n",
    "            # print(yaml.safe_load(stream))\n",
    "            output = yaml.safe_load(stream)\n",
    "            # print(output)\n",
    "            # print(len(output), type(output))  # len 3, type dict\n",
    "            # print(output.keys())  # dict_keys(['dev', 'test', 'train'])\n",
    "            # dev:1108 samples , test:2610 samples , train:9989 samples\n",
    "            # print(len(output[\"dev\"]),len(output[\"test\"]),len(output[\"train\"]))\n",
    "            # print(output[\"dev\"])\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    for file in csv_files_train:\n",
    "        for dtt in ['dev', 'test', 'train']:\n",
    "            if file in output[dtt]:\n",
    "                x, y=file, output[dtt][file][\"Emotion\"]\n",
    "                data_dict[x] = one_hot(label_transform[y])\n",
    "                break\n",
    "    tmp_feature = {}\n",
    "    for csv_file in csv_files_train:\n",
    "        data = pd.read_csv(csv_path_train + '/'+ csv_file + '.csv')\n",
    "        feature = np.array(data, dtype= \"float32\")[:,2:].tolist()\n",
    "        tmp_feature[csv_file]=feature\n",
    "    # audio_feature = torch.tensor(tmp_feature)  # (n,num_time_step,39)\n",
    "    # print(audio_feature.shape)\n",
    "    # #print(audio_feature)\n",
    "    # print(csv_files_train[:15])\n",
    "    return data_dict, tmp_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "xy_train=get_data_train()\n",
    "print(type(xy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(xy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Mydata_train(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.xy_train=xy_train  # a dict\n",
    "    def __getitem__(self, index):\n",
    "        file_name_train=list(self.xy_train[0].keys())[index]\n",
    "        # data, emotion pair\n",
    "        #nor = (torch.Tensor(self.xy_train[1][file_name_train])-torch.mean(torch.Tensor(self.xy_train[1][file_name_train]),dim=1,keepdim=True))/torch.std(torch.Tensor(self.xy_train[1][file_name_train]),dim=1,keepdim=True)\n",
    "        nor = torch.Tensor(self.xy_train[1][file_name_train])\n",
    "        sample_train = nor, torch.Tensor(self.xy_train[0][file_name_train])\n",
    "        return sample_train\n",
    "    def __len__(self):\n",
    "        return len(self.xy_train[0])\n",
    "\n",
    "\n",
    "import random\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, = [], []\n",
    "    for (_text, _label) in batch:\n",
    "        label_list.append(_label.tolist())\n",
    "        text_list.append(_text)\n",
    "    #print(label_list)\n",
    "    label_list = torch.Tensor(label_list)\n",
    "    text_list = torch.nn.utils.rnn.pad_sequence(text_list, batch_first=True, padding_value=0)\n",
    "    return text_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_classes = 7\n",
    "num_epochs = 2\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 39 #dim feature\n",
    "sequence_length = 28\n",
    "hidden_size = 128\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "d_train=Mydata_train()\n",
    "print(len(d_train))\n",
    "\n",
    "# Data loader\n",
    "train_loader = DataLoader(dataset=d_train,batch_size=batch_size,collate_fn=collate_batch,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.3030e+01,  3.5267e+00, -8.2260e+00,  ..., -9.7702e-01,\n",
      "           8.6326e-01, -2.7303e-01],\n",
      "         [-1.3329e+01,  5.2657e+00, -2.7618e+00,  ...,  5.3907e-01,\n",
      "           7.2698e-01, -2.7886e-01],\n",
      "         [-1.2651e+01,  2.4219e+00, -1.1064e+01,  ...,  1.2016e+00,\n",
      "          -7.4175e-02, -1.2714e-01],\n",
      "         ...,\n",
      "         [-1.0836e+01,  7.5187e+00,  2.5220e+01,  ..., -2.0832e-01,\n",
      "          -4.3584e-01, -1.8836e-01],\n",
      "         [-1.5357e+01,  9.4457e+00,  2.7792e+01,  ...,  2.8587e-01,\n",
      "          -2.4627e-03,  1.9659e-01],\n",
      "         [-2.1884e+01,  1.0740e+01,  3.2287e+01,  ...,  5.5600e-01,\n",
      "           7.7045e-01,  3.8818e-01]]], device='cuda:0') tensor([0])\n",
      "tensor([[[-16.9995,   0.5699,  10.3545,  ...,   1.2961,   1.7076,  -0.3927],\n",
      "         [-18.8424,  -4.9882,   6.5081,  ...,   0.2750,   1.2597,  -0.2478],\n",
      "         [-18.2444,   2.7000,   2.6667,  ...,  -1.2331,  -0.2474,  -0.0887],\n",
      "         ...,\n",
      "         [-13.5553, -17.8618, -17.0174,  ...,   1.0072,   1.0479,  -4.2384],\n",
      "         [-23.4523, -13.8764, -23.7562,  ...,  -0.3913,   2.2454,  -0.1600],\n",
      "         [-33.1620, -16.4422, -19.8938,  ...,  -0.9354,   1.0002,   4.0742]]],\n",
      "       device='cuda:0') tensor([0])\n",
      "tensor([[[-5.6696e+00,  3.4484e+00, -1.3587e+01,  ...,  2.2504e+00,\n",
      "           4.7665e-01,  1.0548e+00],\n",
      "         [-4.8993e+00,  5.4024e+00, -1.7423e+01,  ...,  1.5246e+00,\n",
      "          -2.3242e-02,  1.3038e+00],\n",
      "         [-5.5738e+00,  6.5314e+00, -1.6819e+01,  ..., -7.7798e-01,\n",
      "          -4.2789e-01,  1.0409e+00],\n",
      "         ...,\n",
      "         [-1.2941e+01, -3.3399e+01, -2.1944e+01,  ..., -1.1936e+00,\n",
      "           3.3950e-01,  1.8046e-01],\n",
      "         [-1.3608e+01, -3.6300e+01, -1.5845e+01,  ...,  1.9054e-01,\n",
      "           9.8789e-01,  9.7911e-02],\n",
      "         [-1.2401e+01, -3.4549e+01, -1.1007e+01,  ...,  1.1472e+00,\n",
      "           1.1652e+00, -7.2904e-02]]], device='cuda:0') tensor([2])\n"
     ]
    }
   ],
   "source": [
    "for i, (mfccdata, labels) in enumerate(train_loader):\n",
    "    # origin shape: [N, NN, 39]\n",
    "    # mfccdata = mfccdata.reshape(-1, sequence_length, input_size).to(device)\n",
    "    mfccdata = mfccdata.to(device)\n",
    "    labels = torch.argmax(labels,dim=1)\n",
    "    print(mfccdata, labels)\n",
    "    if i == 2:\n",
    "        break\n",
    "\n",
    "    # Forward pass\n",
    "    #outputs = model(mfccdata)\n",
    "    #loss = criterion(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(train_loader)._next_data()\n",
    "type(data)\n",
    "data_dict, tmp_feature = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dict torch.Size([1, 96, 39])\n",
      "tmp_feature torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "print('data_dict',data_dict.size())\n",
    "print('tmp_feature',tmp_feature.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, bidirectional=False)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)\n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "        out = self.fc(out)\n",
    "        # out: (n, 10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(input_size, hidden_size, num_layers, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00597285  0.33486202  0.56011283  0.4655632  -0.06833297 -0.02077667\n",
      "   0.235173  ]] <class 'numpy.ndarray'>\n",
      "[[ 0.00293854  0.718094    0.20659319  0.20457831  0.05012473 -0.03791402\n",
      "   0.12174387]] <class 'numpy.ndarray'>\n",
      "[[ 0.00413328  0.7338797   0.1916953   0.1578171  -0.232506   -0.09469978\n",
      "   0.06562211]] <class 'numpy.ndarray'>\n",
      "[[-0.23676828  0.4913298   0.43116328  0.37239733 -0.16658399 -0.16470546\n",
      "   0.2593767 ]] <class 'numpy.ndarray'>\n",
      "[[-0.20504594  0.7021653  -0.05832031  0.5392014  -0.312952    0.00070646\n",
      "   0.31331074]] <class 'numpy.ndarray'>\n",
      "[[ 0.13387406  0.7309747   0.32785875  0.12086102 -0.38612565  0.04860728\n",
      "   0.24248596]] <class 'numpy.ndarray'>\n",
      "[[-0.17883302  0.54422474  0.22406659  0.17864805 -0.34631732  0.22685272\n",
      "   0.21748374]] <class 'numpy.ndarray'>\n",
      "[[-0.07782893  0.39946008  0.92588353  0.22288829 -0.15131548 -0.00866509\n",
      "   0.2967993 ]] <class 'numpy.ndarray'>\n",
      "[[-0.05144903  0.7752793   0.01687102  0.32677487 -0.07162222 -0.32575542\n",
      "   0.29925823]] <class 'numpy.ndarray'>\n",
      "[[ 0.06883773  0.5804424  -0.19980541  0.15309107 -0.2555461  -0.15522856\n",
      "   0.35201985]] <class 'numpy.ndarray'>\n",
      "[[ 0.03962536  0.84957945  0.7825093   0.7009904  -0.04031825 -0.47968426\n",
      "   0.29279882]] <class 'numpy.ndarray'>\n",
      "[[-0.04977572  0.6026529   0.61051047  0.31804657 -0.18431988  0.18853793\n",
      "   0.22625722]] <class 'numpy.ndarray'>\n",
      "[[-0.30579433  0.7190384   0.00481421  0.25298855 -0.31466606  0.1218284\n",
      "   0.24328353]] <class 'numpy.ndarray'>\n",
      "[[ 0.05787671  0.83163995  0.11863282  0.21923968 -0.18447593 -0.08129338\n",
      "   0.15467651]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tmp_feature = []\n",
    "\n",
    "for i, (mfccdata, labels) in enumerate(train_loader):\n",
    "    # origin shape: [N, NN, 39]\n",
    "    # mfccdata = mfccdata.reshape(-1, sequence_length, input_size).to(device)\n",
    "    mfccdata = mfccdata\n",
    "    labels = torch.argmax(labels,dim=1)\n",
    "    #print(mfccdata, labels)\n",
    "    # Forward pass\n",
    "    outputs = model(mfccdata)\n",
    "    outputs = outputs.detach().numpy() \n",
    "    print(outputs,type(outputs))\n",
    "    tmp_feature.append(outputs)\n",
    "    #tensor.detach.numpy()\n",
    "    #print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.25667688,  0.7707814 , -0.09880745, -0.61482984, -0.8358287 ,\n",
      "         0.31941494, -0.40392566]], dtype=float32), array([[-0.13106161,  0.8633822 , -0.11533121, -0.06397115, -0.6422912 ,\n",
      "         0.13768476, -0.63507354]], dtype=float32), array([[-0.2883257 ,  0.7432375 ,  0.0088351 , -0.17591308, -0.8168704 ,\n",
      "         0.4284621 , -0.1895282 ]], dtype=float32), array([[-0.21261677,  0.7016494 ,  0.02871137,  0.03945391, -0.4810274 ,\n",
      "         0.24851874, -0.24236003]], dtype=float32), array([[-0.42240456,  0.52366865,  0.01182967, -0.3933382 , -0.6548294 ,\n",
      "         0.0786937 , -0.5017521 ]], dtype=float32), array([[-0.15000695,  0.8138542 ,  0.04334982,  0.01719181, -0.8008332 ,\n",
      "         0.21447778, -0.1260587 ]], dtype=float32), array([[-0.4591094 ,  0.61273706,  0.08432996, -0.11785401, -0.8977099 ,\n",
      "         0.23411539, -0.24712068]], dtype=float32), array([[-0.21843132,  0.5437145 ,  0.3142205 , -0.19169141, -0.90294546,\n",
      "         0.19101995, -0.31469637]], dtype=float32), array([[-0.17425442,  0.56696844, -0.27662146, -0.6428242 , -0.59375316,\n",
      "         0.08832908, -0.40312853]], dtype=float32), array([[-0.27699947,  0.7036979 , -0.04206149,  0.06266923, -0.616939  ,\n",
      "         0.21859938, -0.5401811 ]], dtype=float32), array([[-0.40710422,  0.3374483 ,  0.04896095, -0.491342  , -0.77100766,\n",
      "         0.41315907, -0.4508958 ]], dtype=float32), array([[-0.25453493,  0.8027928 , -0.01418329, -0.05139695, -0.6648694 ,\n",
      "         0.45757654, -0.2077722 ]], dtype=float32), array([[-0.16100252,  0.5309185 ,  0.3698748 , -0.04943581, -0.69350183,\n",
      "         0.28321755, -0.09889469]], dtype=float32), array([[-0.5647568 ,  0.5654633 ,  0.40823895, -0.30453956, -0.7211033 ,\n",
      "         0.23903346, -0.18681964]], dtype=float32)]\n",
      "torch.Size([14, 1, 7])\n"
     ]
    }
   ],
   "source": [
    "print(tmp_feature)\n",
    "print(torch.tensor(tmp_feature).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 1, 7]) \n",
      " tensor([[[-0.2567,  0.7708, -0.0988, -0.6148, -0.8358,  0.3194, -0.4039]],\n",
      "\n",
      "        [[-0.1311,  0.8634, -0.1153, -0.0640, -0.6423,  0.1377, -0.6351]],\n",
      "\n",
      "        [[-0.2883,  0.7432,  0.0088, -0.1759, -0.8169,  0.4285, -0.1895]],\n",
      "\n",
      "        [[-0.2126,  0.7016,  0.0287,  0.0395, -0.4810,  0.2485, -0.2424]],\n",
      "\n",
      "        [[-0.4224,  0.5237,  0.0118, -0.3933, -0.6548,  0.0787, -0.5018]],\n",
      "\n",
      "        [[-0.1500,  0.8139,  0.0433,  0.0172, -0.8008,  0.2145, -0.1261]],\n",
      "\n",
      "        [[-0.4591,  0.6127,  0.0843, -0.1179, -0.8977,  0.2341, -0.2471]],\n",
      "\n",
      "        [[-0.2184,  0.5437,  0.3142, -0.1917, -0.9029,  0.1910, -0.3147]],\n",
      "\n",
      "        [[-0.1743,  0.5670, -0.2766, -0.6428, -0.5938,  0.0883, -0.4031]],\n",
      "\n",
      "        [[-0.2770,  0.7037, -0.0421,  0.0627, -0.6169,  0.2186, -0.5402]],\n",
      "\n",
      "        [[-0.4071,  0.3374,  0.0490, -0.4913, -0.7710,  0.4132, -0.4509]],\n",
      "\n",
      "        [[-0.2545,  0.8028, -0.0142, -0.0514, -0.6649,  0.4576, -0.2078]],\n",
      "\n",
      "        [[-0.1610,  0.5309,  0.3699, -0.0494, -0.6935,  0.2832, -0.0989]],\n",
      "\n",
      "        [[-0.5648,  0.5655,  0.4082, -0.3045, -0.7211,  0.2390, -0.1868]]])\n"
     ]
    }
   ],
   "source": [
    "audio_feature = torch.tensor(tmp_feature).unsqueeze(1).reshape(14,-1,7)\n",
    "print(audio_feature.shape,'\\n', audio_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#combine models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/COSMIC/erc-training')\n",
    "from dataloader import MELDRobertaCometDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = 'emotion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MELDRobertaCometDataset('train', classify)\n",
    "train_loader = DataLoader(trainset,\n",
    "                            batch_size=1,\n",
    "                            collate_fn=trainset.collate_fn,\n",
    "                            num_workers=0,\n",
    "                            pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(train_loader)._next_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 17)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1, r2, r3, r4, \\\n",
    "x1, x2, x3, x4, x5, x6, \\\n",
    "o1, o2, o3, \\\n",
    "qmask, umask, label = data[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([14, 1, 1024]),\n",
       " torch.Size([14, 1, 1024]),\n",
       " torch.Size([14, 1, 1024]),\n",
       " torch.Size([14, 1, 1024])]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.size() for x in [r1, r2, r3, r4]]  # (seq_len, batch, hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([14, 1, 768]),\n",
       " torch.Size([14, 1, 768]),\n",
       " torch.Size([14, 1, 768]),\n",
       " torch.Size([14, 1, 768]),\n",
       " torch.Size([14, 1, 768]),\n",
       " torch.Size([14, 1, 768])]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.size() for x in [x1, x2, x3, x4, x5, x6]]  # (seq_len, batch, dim_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([14, 1, 768]), torch.Size([14, 1, 768]), torch.Size([14, 1, 768])]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.size() for x in [o1, o2, o3]]  # (seq_len, batch, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 1, 1024]), torch.Size([14, 1, 1031]))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "r = (r1 + r2 + r3 + r4) / 4.0\n",
    "mixed_feature = torch.cat((r, audio_feature), dim=-1)\n",
    "\n",
    "r.size(), mixed_feature.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from commonsense_model import CommonsenseGRUModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonsenseGRUModel_bimodal(CommonsenseGRUModel):\n",
    "\n",
    "    def __init__(self, \n",
    "        D_m, D_s, D_g, D_p, D_r, D_i, D_e, D_h, D_a=100, D_audio=7, \n",
    "        n_classes=7, listener_state=False, context_attention='simple', \n",
    "        dropout_rec=0.5, dropout=0.1, emo_gru=True, mode1=0, norm=0, residual=False\n",
    "        ):\n",
    "        # 增加了一个新的参数 D_audio=384，audio feature 的维度\n",
    "\n",
    "        super().__init__(\n",
    "            D_m, D_s, D_g, D_p, D_r, D_i, D_e, D_h, D_a=D_a, \n",
    "            n_classes=n_classes, listener_state=listener_state, context_attention=context_attention, \n",
    "            dropout_rec=dropout_rec, dropout=dropout, emo_gru=emo_gru, mode1=mode1, norm=norm, residual=residual)\n",
    "\n",
    "        if mode1 == 0:\n",
    "            D_x = 4 * D_m\n",
    "        elif mode1 == 1:\n",
    "            D_x = 2 * D_m\n",
    "        else:\n",
    "            D_x = D_m\n",
    "\n",
    "        self.linear_in_mixed_feature = nn.Linear(D_x + D_audio, D_h)  # D_h 将传给 CommonsenseRNNCell 作为 D_m，即 dim of mixed utterance feature\n",
    "\n",
    "    def forward(self, \n",
    "                r1, r2, r3, r4, audio_feature, \n",
    "                x1, x2, x3, o1, o2, \n",
    "                qmask, umask, att2=False, return_hidden=False\n",
    "                ):\n",
    "        # 增加了 audio_feature 作为语音特征接口\n",
    "        \"\"\"\n",
    "        U -> seq_len, batch, D_m\n",
    "        qmask -> seq_len, batch, party\n",
    "        \"\"\"\n",
    "\n",
    "        seq_len, batch, feature_dim = r1.size()\n",
    "\n",
    "        # args.norm default is 0, namely not normalizing r1 - r4\n",
    "        if self.norm_strategy == 1:\n",
    "            r1 = self.norm1a(r1.transpose(0, 1).reshape(-1, feature_dim)).reshape(-1, seq_len, feature_dim).transpose(1, 0)\n",
    "            r2 = self.norm1b(r2.transpose(0, 1).reshape(-1, feature_dim)).reshape(-1, seq_len, feature_dim).transpose(1, 0)\n",
    "            r3 = self.norm1c(r3.transpose(0, 1).reshape(-1, feature_dim)).reshape(-1, seq_len, feature_dim).transpose(1, 0)\n",
    "            r4 = self.norm1d(r4.transpose(0, 1).reshape(-1, feature_dim)).reshape(-1, seq_len, feature_dim).transpose(1, 0)\n",
    "\n",
    "        elif self.norm_strategy == 2:\n",
    "            norm2 = nn.LayerNorm((seq_len, feature_dim), elementwise_affine=False)\n",
    "            r1 = norm2(r1.transpose(0, 1)).transpose(0, 1)\n",
    "            r2 = norm2(r2.transpose(0, 1)).transpose(0, 1)\n",
    "            r3 = norm2(r3.transpose(0, 1)).transpose(0, 1)\n",
    "            r4 = norm2(r4.transpose(0, 1)).transpose(0, 1)\n",
    "\n",
    "        elif self.norm_strategy == 3:\n",
    "            r1 = self.norm3a(r1.transpose(0, 1).reshape(-1, feature_dim)).reshape(-1, seq_len, feature_dim).transpose(1, 0)\n",
    "            r2 = self.norm3b(r2.transpose(0, 1).reshape(-1, feature_dim)).reshape(-1, seq_len, feature_dim).transpose(1, 0)\n",
    "            r3 = self.norm3c(r3.transpose(0, 1).reshape(-1, feature_dim)).reshape(-1, seq_len, feature_dim).transpose(1, 0)\n",
    "            r4 = self.norm3d(r4.transpose(0, 1).reshape(-1, feature_dim)).reshape(-1, seq_len, feature_dim).transpose(1, 0)\n",
    "\n",
    "        if self.mode1 == 0:\n",
    "            r = torch.cat([r1, r2, r3, r4], axis=-1)\n",
    "        elif self.mode1 == 1:\n",
    "            r = torch.cat([r1, r2], axis=-1)\n",
    "        elif self.mode1 == 2:\n",
    "            r = (r1 + r2 + r3 + r4)/4\n",
    "        elif self.mode1 == 3:\n",
    "            r = r1\n",
    "        elif self.mode1 == 4:\n",
    "            r = r2\n",
    "        elif self.mode1 == 5:\n",
    "            r = r3\n",
    "        elif self.mode1 == 6:\n",
    "            r = r4\n",
    "        elif self.mode1 == 7:\n",
    "            r = self.r_weights[0]*r1 + self.r_weights[1]*r2 + self.r_weights[2]*r3 + self.r_weights[3]*r4\n",
    "        \n",
    "        # combination roberta feature with audio feature\n",
    "        # r [seq_len, batch_size, dim_roberta]\n",
    "        # audio_feature [seq_len, batch_size, dim_audio]\n",
    "        mixed_feature = torch.cat((r, audio_feature), dim=-1)  # [seq_len, batch_size, dim_mixed_feature]\n",
    "        r = self.linear_in_mixed_feature(mixed_feature)\n",
    "        \n",
    "        emotions_f, alpha_f = self.cs_rnn_f(r, x1, x2, x3, o1, o2, qmask)     \n",
    "        out_sense, _ = self.sense_gru(x1)\n",
    "        \n",
    "        rev_r = self._reverse_seq(r, umask)\n",
    "        rev_x1 = self._reverse_seq(x1, umask)\n",
    "        rev_x2 = self._reverse_seq(x2, umask)\n",
    "        rev_x3 = self._reverse_seq(x3, umask)\n",
    "        rev_o1 = self._reverse_seq(o1, umask)\n",
    "        rev_o2 = self._reverse_seq(o2, umask)\n",
    "        rev_qmask = self._reverse_seq(qmask, umask)\n",
    "        emotions_b, alpha_b = self.cs_rnn_r(rev_r, rev_x1, rev_x2, rev_x3, rev_o1, rev_o2, rev_qmask)\n",
    "        emotions_b = self._reverse_seq(emotions_b, umask)\n",
    "        \n",
    "        emotions = torch.cat([emotions_f,emotions_b],dim=-1)\n",
    "        emotions = self.dropout_rec(emotions)\n",
    "        \n",
    "        alpha, alpha_f, alpha_b = [], [], []\n",
    "        if att2:\n",
    "            att_emotions = []\n",
    "            alpha = []\n",
    "            for t in emotions:\n",
    "                att_em, alpha_ = self.matchatt(emotions,t,mask=umask)\n",
    "                att_emotions.append(att_em.unsqueeze(0))\n",
    "                alpha.append(alpha_[:,0,:])\n",
    "            att_emotions = torch.cat(att_emotions,dim=0)\n",
    "            hidden = F.relu(self.linear(att_emotions))\n",
    "        else:\n",
    "            hidden = F.relu(self.linear(emotions))\n",
    "            \n",
    "        hidden = self.dropout(hidden)\n",
    "        \n",
    "        if self.residual:\n",
    "            hidden = hidden + r\n",
    "        \n",
    "        log_prob = F.log_softmax(self.smax_fc(hidden), 2)\n",
    "\n",
    "        if return_hidden:\n",
    "            return hidden, alpha, alpha_f, alpha_b, emotions\n",
    "        return log_prob, out_sense, alpha, alpha_f, alpha_b, emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running emotion classification task on CPU\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "\n",
    "no_cuda = True # 是否禁用 cuda\n",
    "cuda = torch.cuda.is_available() and not no_cuda\n",
    "\n",
    "emo_gru = True\n",
    "batch_size = 1\n",
    "classify = 'emotion'\n",
    "n_classes = 7 if classify == 'emotion' else 3 if classify == 'sentiment' else 0\n",
    "\n",
    "print('Running %s classification task on %s' % (classify, 'GPU' if cuda else 'CPU')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_m = 1024  # roberta 的四个向量的维度，这四个向量平均之后取自 [CLS]在最后四层 hidden representations，四个向量平均之后作为 utterance 的表示\n",
    "D_s = 768  # 5种 常识向量 的 维度 (commonsense)\n",
    "D_g = 150  # dim of context state (global)\n",
    "\n",
    "D_p = 150  # dim of internal state\n",
    "D_r = 150  # dim of external state\n",
    "D_i = 150  # dim of intet state\n",
    "\n",
    "D_h = 100  # 将输入从 D_m 变换到 D_h，模型内部的维度\n",
    "D_a = 100  # dim of attention\n",
    "D_audio = 7\n",
    "\n",
    "D_e = D_p + D_r + D_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CommonsenseGRUModel_bimodal(\n",
    "    D_m, D_s, D_g, D_p, D_r, D_i, D_e, D_h, D_a=D_a, D_audio=D_audio, \n",
    "    n_classes=n_classes, listener_state=True, context_attention='simple',\n",
    "    dropout_rec=0.5, dropout=0.5, emo_gru=True, mode1=2, norm=0, residual=True)\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# set seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward \n",
    "log_prob, out_sense, alpha, alpha_f, alpha_b, emotions = model(r1, r2, r3, r4, audio_feature, x5, x6, x1, o2, o3, qmask, umask, att2=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Tensor, torch.Tensor, list, list, list, torch.Tensor]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shou results\n",
    "[type(x) for x in [log_prob, out_sense, alpha, alpha_f, alpha_b, emotions]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([14, 1, 7]), torch.Size([14, 1, 768]), torch.Size([14, 1, 900])]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.size() for x in [log_prob, out_sense, emotions]]\n",
    "# log_prob   [14, 1, 7]    (seq_len, batch, num_emotions)\n",
    "# 七种 emotion 的预测概率\n",
    "\n",
    "# out_sense  [14, 1, 768]  (seq_len, batch, hidden_size)\n",
    "# self.sense_gru = nn.GRU(input_size=D_s, hidden_size=D_s//2, num_layers=1, bidirectional=True)\n",
    "# out_sense, _ = self.sense_gru(x1)\n",
    "# 不太明白 out_sense 是什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.3965, -1.7546, -2.5307, -1.9847, -2.0252, -2.2455, -1.2689]],\n",
       "\n",
       "        [[-2.2774, -1.6777, -2.4191, -1.9318, -1.9595, -2.3078, -1.4425]],\n",
       "\n",
       "        [[-2.3356, -1.8608, -2.3524, -2.1180, -2.0980, -2.0582, -1.2661]],\n",
       "\n",
       "        [[-2.5710, -1.7643, -2.1608, -2.0205, -2.3415, -2.0340, -1.2822]],\n",
       "\n",
       "        [[-2.6927, -1.6970, -2.2761, -2.1009, -1.9304, -2.0086, -1.4074]],\n",
       "\n",
       "        [[-2.3415, -1.8356, -2.3316, -2.0417, -1.9331, -2.2447, -1.3217]],\n",
       "\n",
       "        [[-2.3137, -1.8975, -2.2358, -1.9741, -2.0540, -1.8869, -1.4889]],\n",
       "\n",
       "        [[-2.1993, -1.8003, -2.2926, -1.8849, -1.9544, -2.3445, -1.4546]],\n",
       "\n",
       "        [[-2.3081, -1.9500, -2.2053, -1.9561, -1.9704, -2.0817, -1.4167]],\n",
       "\n",
       "        [[-2.4409, -2.0596, -2.2035, -2.0172, -2.1868, -2.0494, -1.2010]],\n",
       "\n",
       "        [[-2.1670, -1.9257, -2.1600, -1.8062, -2.1574, -2.3304, -1.3975]],\n",
       "\n",
       "        [[-2.2026, -1.9458, -2.4334, -1.7872, -2.1213, -2.1109, -1.3845]],\n",
       "\n",
       "        [[-2.5038, -1.8859, -2.2161, -1.7887, -2.0049, -2.2290, -1.3943]],\n",
       "\n",
       "        [[-2.3777, -1.9933, -2.2607, -1.9609, -2.0798, -2.1909, -1.2406]]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tutorials combine models \n",
    "1.https://github.com/Min-Sheng/multimodal-speech-emotion-recognizer/blob/master/model/multi_modal_model.py\n",
    "2.https://github.com/Lev-etd/Multimodal-emotion-recognition/blob/master/Model.ipynb\n",
    "3.https://github.com/mishra-pa/Multimodal-Transformer-for-Emotion-Recognition/blob/main/src/models.py\n",
    "4.https://github.com/PoYuYang/EE599-Multi-modal-Sentiment-Analysis-Project\n",
    "5.https://github.com/HandsomeQD/MVAE_Bi-LSTMs_VGG19_pytorch/blob/master/BiLSTM_VGG_VAE.ipynb\n",
    "6.https://github.com/yuanxiaosc/Multimodal-short-video-dataset-and-baseline-classification-model/blob/master/baseline_model/mutimodal_baseline_model.py\n",
    "7.https://github.com/bkoch4142/multimodal-emotion-classification/blob/main/src/models/multimodal_model.py\n",
    "8.https://github.com/mebasiri/Multimodal-Persian-Sentiment-Analysis/blob/main/Multimodal_Persian_SA.ipynb\n",
    "9.https://github.com/sayakpaul/Multimodal-Entailment-Baseline\n",
    "10.https://github.com/david-yoon/multimodal-speech-emotion/blob/master/preprocessing/IEMOCAP_01_wav_to_feature.ipynb\n",
    "11.https://github.com/aris-ai/Audio-and-text-based-emotion-recognition/blob/master/Text_and_Audio_Emotion.ipynb\n",
    "12.https://github.com/TianyiWu96/Multimodal-Sentiment/blob/master/multimodel.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio GRN  models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUDIOGRU(nn.Module):\n",
    "    def __init__(self, ainput_size, ahidden_size, anum_layers, anum_classes):\n",
    "        super().__init__()\n",
    "        self.anum_layers = anum_layers\n",
    "        self.ahidden_size = ahidden_size\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        self.agru = nn.GRU(ainput_size, ahidden_size, anum_layers, batch_first=True, bidirectional=False)\n",
    "        self.afc = nn.Linear(ahidden_size, anum_classes)\n",
    "\n",
    "    def forward(self, ax):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.anum_layers, ax.size(0), self.ahidden_size)\n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.agru(ax, h0)\n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "        out = self.afc(out)\n",
    "        # out: (n, 10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDIOGRU(\n",
      "  (agru): GRU(39, 128, batch_first=True)\n",
      "  (afc): Linear(in_features=128, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "#AudioGRU\n",
    "ainput_size = 39 \n",
    "ahidden_size = 128\n",
    "anum_layers = 1\n",
    "anum_classes = 7\n",
    "\n",
    "#COSMICGRU\n",
    "cinput_size = 39 \n",
    "chidden_size = 128\n",
    "cnum_layers = 1\n",
    "cnum_classes = 7\n",
    "\n",
    "#linear\n",
    "output_dim = 60\n",
    "    \n",
    "model = AUDIOGRU(ainput_size, ahidden_size, anum_layers, anum_classes)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agru.weight_ih_l0 torch.Size([384, 39])\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "agru.weight_hh_l0 torch.Size([384, 128])\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "agru.bias_ih_l0 torch.Size([384])\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "agru.bias_hh_l0 torch.Size([384])\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "afc.weight torch.Size([7, 128])\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "afc.bias torch.Size([7])\n",
      "<class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "#params layers change \n",
    "params = model.named_parameters()\n",
    "for name, param in params:\n",
    "    print(name, param.data.shape)\n",
    "    print(type(param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1446,  0.0278,  0.0085, -0.0728, -0.2254, -0.0280, -0.1586],\n",
       "        [ 0.0435,  0.0471, -0.0866, -0.0736, -0.0048,  0.1223,  0.0235],\n",
       "        [ 0.1835, -0.0421, -0.2117, -0.1400,  0.1453,  0.1927,  0.0646],\n",
       "        [-0.0168, -0.2436,  0.0993, -0.1072, -0.0432,  0.1045, -0.0435],\n",
       "        [ 0.0899,  0.1206,  0.0256, -0.0424, -0.1652,  0.1340,  0.0894]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(5, 3, 39)\n",
    "model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "               GRU-1  [[-1, 3, 128], [-1, 2, 128]]               0\n",
      "            Linear-2                    [-1, 7]             903\n",
      "================================================================\n",
      "Total params: 903\n",
      "Trainable params: 903\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.75\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "#notice h0必须cuda设备 model必须cuda设备\n",
    "model = model.cuda()\n",
    "summary(model, (3, 39))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 107.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "resnet18 = models.resnet18().cuda()\n",
    "summary(resnet18, (3, 224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#audio cosmic models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COSMICGRU(nn.Module):\n",
    "    def __init__(self, cinput_size, chidden_size, cnum_layers, cnum_classes):\n",
    "        super().__init__()\n",
    "        self.cnum_layers = cnum_layers\n",
    "        self.chidden_size = chidden_size\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        self.cgru = nn.GRU(cinput_size, chidden_size, cnum_layers, batch_first=True, bidirectional=False)\n",
    "        self.cfc = nn.Linear(chidden_size, cnum_classes)\n",
    "\n",
    "    def forward(self, cx):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.cnum_layers, cx.size(0), self.chidden_size)\n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.cgru(cx, h0)\n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "        out = self.cfc(out)\n",
    "        # out: (n, 10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COSMICGRU(\n",
       "  (cgru): GRU(39, 128, batch_first=True)\n",
       "  (cfc): Linear(in_features=128, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COSMICGRU(cinput_size,chidden_size, cnum_layers, cnum_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#combine models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalModal(nn.Module):\n",
    "    \n",
    "    def __init__(self,ainput_size, ahidden_size, anum_layers, anum_classes, cinput_size, chidden_size, cnum_layers, cnum_classes):\n",
    "        super(MultimodalModal,self).__init__()\n",
    "        self.ainput_size = ainput_size\n",
    "        self.ahidden_size = ahidden_size\n",
    "        self.anum_layers = anum_layers\n",
    "        self.anum_classes = anum_classes\n",
    "        self.cinput_size = cinput_size\n",
    "        self.chidden_size = chidden_size\n",
    "        self.cnum_layers = cnum_layers\n",
    "        self.cnum_classes = cnum_classes\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.AUDIOGRU = AUDIOGRU(ainput_size = self.ainput_size, ahidden_size = self.ahidden_size, anum_layers = self.anum_layers, anum_classes = self.anum_classes)\n",
    "        \n",
    "        self.COSMICGRU = COSMICGRU(cinput_size = self.cinput_size,chidden_size = self.chidden_size, cnum_layers = self.cnum_layers, cnum_classes =  self.cnum_classes)\n",
    "    \n",
    "        #self.out = nn.Linear(int(self.ahidden_size + self.chidden_size),self.output_dim)\n",
    "        \n",
    "    def forward(self, ax, cx):\n",
    "        \n",
    "        out_audioGRU = self.AUDIOGRU(ax) \n",
    "        out_audioCosmicGRU = self.COSMICGRU(cx)\n",
    "        final = torch.cat((out_audioGRU, out_audioCosmicGRU), dim=1)\n",
    "        print(final.shape)\n",
    "        return final   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultimodalModal = MultimodalModal(ainput_size, ahidden_size, anum_layers, anum_classes, cinput_size, chidden_size, cnum_layers, cnum_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from combine_models.single_text_model import COSMICGRU\n",
    "from combine_models.single_audio_model import AUDIOGRU\n",
    "\n",
    "class CMultimodalModal(nn.Module):\n",
    "    \n",
    "    def __init__(self,ainput_size, ahidden_size, anum_layers, anum_classes, cinput_size, chidden_size, cnum_layers, cnum_classes):\n",
    "        super(CMultimodalModal,self).__init__()\n",
    "        self.ainput_size = ainput_size\n",
    "        self.ahidden_size = ahidden_size\n",
    "        self.anum_layers = anum_layers\n",
    "        self.anum_classes = anum_classes\n",
    "        self.cinput_size = cinput_size\n",
    "        self.chidden_size = chidden_size\n",
    "        self.cnum_layers = cnum_layers\n",
    "        self.cnum_classes = cnum_classes\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.AUDIOGRU = AUDIOGRU(ainput_size = self.ainput_size, ahidden_size = self.ahidden_size, anum_layers = self.anum_layers, anum_classes = self.anum_classes)\n",
    "        \n",
    "        self.COSMICGRU = COSMICGRU(cinput_size = self.cinput_size,chidden_size = self.chidden_size, cnum_layers = self.cnum_layers, cnum_classes =  self.cnum_classes)\n",
    "    \n",
    "        #self.out = nn.Linear(int(self.ahidden_size + self.chidden_size),self.output_dim)\n",
    "        \n",
    "    def forward(self, ax, cx):\n",
    "        \n",
    "        out_audioGRU = self.AUDIOGRU(ax) \n",
    "        out_audioCosmicGRU = self.COSMICGRU(cx)\n",
    "        final = torch.cat((out_audioGRU, out_audioCosmicGRU), dim=1)\n",
    "        print(final.shape)\n",
    "        return final   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMultimodalModal = CMultimodalModal(ainput_size, ahidden_size, anum_layers, anum_classes, cinput_size, chidden_size, cnum_layers, cnum_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "#AudioGRU\n",
    "ainput_size = 39 \n",
    "ahidden_size = 128\n",
    "anum_layers = 1\n",
    "anum_classes = 7\n",
    "\n",
    "#COSMICGRU\n",
    "cinput_size = 39 \n",
    "chidden_size = 128\n",
    "cnum_layers = 1\n",
    "cnum_classes = 7\n",
    "\n",
    "#linear\n",
    "output_dim = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, argparse \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 0.6812245  -0.04862917 -0.10408711 -0.10611243 -0.09928183 -0.6035498\n",
      "  -0.2471769   0.24714881 -0.49965137 -0.71538013 -0.3036044   0.16739881\n",
      "  -0.06476932  0.37533092]] <class 'numpy.ndarray'>\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 0.6581431  -0.737012   -0.07999098 -0.19144666 -0.12357993 -0.5105235\n",
      "  -0.32763776  0.61912507 -0.31017584 -0.78109425 -0.6432464  -0.03616352\n",
      "  -0.44865024  0.5261647 ]] <class 'numpy.ndarray'>\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 0.56383485 -0.5124508   0.06158877 -0.2273463  -0.54517084 -0.4390095\n",
      "  -0.28686917  0.5619225   0.16593805 -0.88103575 -0.3937074  -0.05868623\n",
      "  -0.4033925   0.18011972]] <class 'numpy.ndarray'>\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 0.90701854 -0.3746734  -0.15673012 -0.09624866 -0.04575521 -0.6883424\n",
      "  -0.33255118  0.21348864 -0.42830467 -0.7697725  -0.54777426 -0.059483\n",
      "  -0.50974697  0.32665145]] <class 'numpy.ndarray'>\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 0.5579262  -0.47396106 -0.24527356 -0.18285951  0.02059413 -0.85089934\n",
      "  -0.3916005   0.6599053  -0.4549532  -0.70266217 -0.6317297  -0.27846918\n",
      "  -0.13305882  0.43663478]] <class 'numpy.ndarray'>\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 0.8197389  -0.1432113  -0.18555701 -0.20316043 -0.10891807 -0.74095106\n",
      "  -0.47732872  0.5637336  -0.44327575 -0.7938568  -0.38576066  0.17449322\n",
      "  -0.2709189   0.28179985]] <class 'numpy.ndarray'>\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 0.8462266  -0.37110874  0.2259588  -0.12417809 -0.2865481  -0.4632151\n",
      "  -0.5901281   0.6629534  -0.27145368 -0.9311472  -0.4044239   0.04104348\n",
      "  -0.2594129   0.30295986]] <class 'numpy.ndarray'>\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 0.71728414 -0.5180566  -0.16334361 -0.14000055 -0.08821702 -0.37840837\n",
      "  -0.48427087  0.43563777 -0.547727   -0.7499952  -0.5050694   0.06267857\n",
      "  -0.08328929  0.4600715 ]] <class 'numpy.ndarray'>\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 1.1543369  -0.7804659  -0.12520829 -0.13710335  0.1747375  -0.580577\n",
      "  -0.5472891   0.7672373  -0.6133682  -0.63085705 -0.5379853   0.25071836\n",
      "  -0.7684224   0.3373086 ]] <class 'numpy.ndarray'>\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 0.62977797 -0.38822916 -0.17962098 -0.07533775 -0.10806514 -0.73161733\n",
      "  -0.17642225  0.27360588 -0.44019926 -0.83805454 -0.4267084   0.16551062\n",
      "  -0.33513668  0.37835616]] <class 'numpy.ndarray'>\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 0.9530916  -0.93417835 -0.19032419 -0.3265451   0.15228394 -0.706887\n",
      "  -0.53621334  0.4866721  -0.27008298 -0.47875538 -0.7254467   0.17331684\n",
      "  -0.23140651  0.4826097 ]] <class 'numpy.ndarray'>\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 0.41616446 -0.12961376  0.0952353  -0.04505565 -0.44200122 -0.82546306\n",
      "  -0.30489582  0.39215165 -0.22017443 -1.0283142  -0.39865723  0.05580435\n",
      "  -0.18468359  0.4069991 ]] <class 'numpy.ndarray'>\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 0.88347685 -0.78410625 -0.11201293 -0.32807875  0.18497024 -0.2887835\n",
      "  -0.2343194   0.5781451  -0.37328094 -0.54655397 -0.61377007  0.0617291\n",
      "  -0.6354205   0.5926219 ]] <class 'numpy.ndarray'>\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 14])\n",
      "[[ 0.70799476 -0.15102395  0.09734926 -0.16654027 -0.18008636 -0.5876768\n",
      "  -0.31037557  0.6333354  -0.28353512 -1.0738115  -0.47089645 -0.06193077\n",
      "  -0.23321724  0.21564178]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "combine_feature = []\n",
    "\n",
    "for i, (mfccdata, labels) in enumerate(train_loader):\n",
    "    # origin shape: [N, NN, 39]\n",
    "    # mfccdata = mfccdata.reshape(-1, sequence_length, input_size).to(device)\n",
    "    mfccdata = mfccdata\n",
    "    labels = torch.argmax(labels,dim=1)\n",
    "    #print(mfccdata, labels)\n",
    "    # Forward pass\n",
    "    outputs = MultimodalModal(mfccdata,mfccdata)\n",
    "    print(outputs.shape)\n",
    "    outputs = outputs.detach().numpy() \n",
    "    print(outputs,type(outputs))\n",
    "    combine_feature.append(outputs)\n",
    "    #tensor.detach.numpy()\n",
    "    #print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attention\n",
    "\n",
    "'''\n",
    "动手深度学习Page 407 and Page 410\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, bidirectional=False)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)\n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "        out = self.fc(out)\n",
    "        # out: (n, 10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Shape of `queries`: (`batch_size`, no. of queries, `d`)\n",
    "        # Shape of `keys`: (`batch_size`, no. of key-value pairs, `d`)\n",
    "        # Shape of `values`: (`batch_size`, no. of key-value pairs, value\n",
    "        # dimension)\n",
    "        # Shape of `valid_lens`: (`batch_size`,) or (`batch_size`, no. of queries)\n",
    "        \n",
    "    def forward(self, queries, keys, values):\n",
    "        d = queries.shape[-1]\n",
    "        # Set `transpose_b=True` to swap the last two dimensions of `keys`\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        return torch.bmm(self.dropout(scores), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The scaled dot-product attention of queries Q ∈ R n×d, keys K ∈ R m×d, and values V ∈ R m×v  \n",
    "\n",
    "Encoder  <<< multi-head self attention 动手深度学习Page426\n",
    "\n",
    "'''\n",
    "queries = torch.normal(0, 1, (2, 1, 2))\n",
    "keys = torch.normal(0, 1, (2, 1, 2))\n",
    "values = torch.normal(0, 1, (2, 1, 2))\n",
    "\n",
    "attention = DotProductAttention(dropout=0.5)\n",
    "attention.eval()\n",
    "attention = attention(queries, keys, values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(attention.shape)\n",
    "print(type(attention))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.8423,  0.0613],\n",
       "          [-0.2232, -0.0457]]]])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.reshape(1,1,2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multihead attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_qkv(X, num_heads):\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "def transpose_output(X, num_heads): \n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2]) \n",
    "    X = X.permute(0, 2, 1, 3) \n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "    num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "        \n",
    "    def forward(self, queries, keys, values):\n",
    "        # Shape of `queries`, `keys`, or `values`:\n",
    "        # (`batch_size`, no. of queries or key-value pairs, `num_hiddens`)\n",
    "        # Shape of `valid_lens`:\n",
    "        # (`batch_size`,) or (`batch_size`, no. of queries)\n",
    "        # After transposing, shape of output `queries`, `keys`, or `values`:\n",
    "        # (`batch_size` * `num_heads`, no. of queries or key-value pairs,\n",
    "        # `num_hiddens` / `num_heads`)\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "     \n",
    "        output = self.attention(queries, keys, values)\n",
    "        # Shape of `output_concat`:\n",
    "        # (`batch_size`, no. of queries, `num_hiddens`)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadAttention(\n",
       "  (attention): DotProductAttention(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (W_q): Linear(in_features=100, out_features=100, bias=False)\n",
       "  (W_k): Linear(in_features=100, out_features=100, bias=False)\n",
       "  (W_v): Linear(in_features=100, out_features=100, bias=False)\n",
       "  (W_o): Linear(in_features=100, out_features=100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hiddens, num_heads = 100, 5\n",
    "attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,num_hiddens, num_heads, 0.5)\n",
    "attention.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiHeadAttention(\n",
      "  (attention): DotProductAttention(\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (W_q): Linear(in_features=100, out_features=100, bias=False)\n",
      "  (W_k): Linear(in_features=100, out_features=100, bias=False)\n",
      "  (W_v): Linear(in_features=100, out_features=100, bias=False)\n",
      "  (W_o): Linear(in_features=100, out_features=100, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 100])\n",
      "/n tensor([[[ 2.2436e-01,  1.7030e-01,  1.5454e-01, -5.4209e-01, -1.1723e+00,\n",
      "           3.8347e-01,  6.8882e-04,  6.7641e-01, -6.0793e-01, -8.5367e-01,\n",
      "           1.9934e-01, -8.7626e-01, -3.2894e-01, -8.3591e-01, -1.3181e+00,\n",
      "          -8.7349e-01, -5.5290e-02, -6.2123e-01, -7.3228e-01, -3.1099e-01,\n",
      "          -8.2433e-01,  5.2567e-01,  2.9478e-01,  2.6369e-01, -1.0796e-01,\n",
      "          -1.9514e-02,  2.2952e-01, -7.5005e-01,  5.2535e-01, -1.8827e-01,\n",
      "          -1.7342e-02, -1.9349e-01, -8.2957e-01,  2.0198e-01,  2.5380e-02,\n",
      "          -1.4443e+00, -6.6620e-01, -3.4613e-01,  3.2738e-01, -3.4000e-01,\n",
      "          -4.2898e-01,  4.8691e-01,  2.9637e-01,  9.2918e-01,  3.9288e-02,\n",
      "          -3.8061e-01,  4.6110e-01,  8.8262e-01, -1.7038e+00, -8.3047e-01,\n",
      "           9.6022e-02,  2.2452e-01,  1.3397e-01,  1.5740e-01,  3.9711e-01,\n",
      "           1.7809e+00, -1.4859e-01,  6.1304e-01, -5.1841e-01,  5.9695e-02,\n",
      "          -6.5050e-01, -5.0063e-02, -2.0790e-02, -9.8684e-02, -8.6913e-01,\n",
      "           3.1795e-01,  5.8919e-01, -4.3025e-01,  1.6805e-01, -1.6244e+00,\n",
      "           1.1406e+00, -6.2632e-01,  1.4851e-02, -1.3713e-01,  1.2415e-01,\n",
      "          -8.0380e-01,  1.4809e+00,  8.1456e-01, -7.7490e-01, -5.6696e-01,\n",
      "           2.8069e-01, -3.3325e-01, -6.6795e-01,  4.5635e-01,  1.8636e-01,\n",
      "          -2.7033e-01, -6.1700e-01,  7.7415e-01, -4.7894e-01,  1.2584e+00,\n",
      "          -2.2849e-01,  1.9504e-01,  3.6643e-01, -2.7101e-01,  1.0068e+00,\n",
      "           2.0212e-02,  7.3740e-01,  6.9593e-02,  8.1442e-01,  3.0647e-01],\n",
      "         [ 2.2436e-01,  1.7030e-01,  1.5454e-01, -5.4209e-01, -1.1723e+00,\n",
      "           3.8347e-01,  6.8882e-04,  6.7641e-01, -6.0793e-01, -8.5367e-01,\n",
      "           1.9934e-01, -8.7626e-01, -3.2894e-01, -8.3591e-01, -1.3181e+00,\n",
      "          -8.7349e-01, -5.5290e-02, -6.2123e-01, -7.3228e-01, -3.1099e-01,\n",
      "          -8.2433e-01,  5.2567e-01,  2.9478e-01,  2.6369e-01, -1.0796e-01,\n",
      "          -1.9514e-02,  2.2952e-01, -7.5005e-01,  5.2535e-01, -1.8827e-01,\n",
      "          -1.7342e-02, -1.9349e-01, -8.2957e-01,  2.0198e-01,  2.5380e-02,\n",
      "          -1.4443e+00, -6.6620e-01, -3.4613e-01,  3.2738e-01, -3.4000e-01,\n",
      "          -4.2898e-01,  4.8691e-01,  2.9637e-01,  9.2918e-01,  3.9288e-02,\n",
      "          -3.8061e-01,  4.6110e-01,  8.8262e-01, -1.7038e+00, -8.3047e-01,\n",
      "           9.6022e-02,  2.2452e-01,  1.3397e-01,  1.5740e-01,  3.9711e-01,\n",
      "           1.7809e+00, -1.4859e-01,  6.1304e-01, -5.1841e-01,  5.9695e-02,\n",
      "          -6.5050e-01, -5.0063e-02, -2.0790e-02, -9.8684e-02, -8.6913e-01,\n",
      "           3.1795e-01,  5.8919e-01, -4.3025e-01,  1.6805e-01, -1.6244e+00,\n",
      "           1.1406e+00, -6.2632e-01,  1.4851e-02, -1.3713e-01,  1.2415e-01,\n",
      "          -8.0380e-01,  1.4809e+00,  8.1456e-01, -7.7490e-01, -5.6696e-01,\n",
      "           2.8069e-01, -3.3325e-01, -6.6795e-01,  4.5635e-01,  1.8636e-01,\n",
      "          -2.7033e-01, -6.1700e-01,  7.7415e-01, -4.7894e-01,  1.2584e+00,\n",
      "          -2.2849e-01,  1.9504e-01,  3.6643e-01, -2.7101e-01,  1.0068e+00,\n",
      "           2.0212e-02,  7.3740e-01,  6.9593e-02,  8.1442e-01,  3.0647e-01],\n",
      "         [ 2.2436e-01,  1.7030e-01,  1.5454e-01, -5.4209e-01, -1.1723e+00,\n",
      "           3.8347e-01,  6.8882e-04,  6.7641e-01, -6.0793e-01, -8.5367e-01,\n",
      "           1.9934e-01, -8.7626e-01, -3.2894e-01, -8.3591e-01, -1.3181e+00,\n",
      "          -8.7349e-01, -5.5290e-02, -6.2123e-01, -7.3228e-01, -3.1099e-01,\n",
      "          -8.2433e-01,  5.2567e-01,  2.9478e-01,  2.6369e-01, -1.0796e-01,\n",
      "          -1.9514e-02,  2.2952e-01, -7.5005e-01,  5.2535e-01, -1.8827e-01,\n",
      "          -1.7342e-02, -1.9349e-01, -8.2957e-01,  2.0198e-01,  2.5380e-02,\n",
      "          -1.4443e+00, -6.6620e-01, -3.4613e-01,  3.2738e-01, -3.4000e-01,\n",
      "          -4.2898e-01,  4.8691e-01,  2.9637e-01,  9.2918e-01,  3.9288e-02,\n",
      "          -3.8061e-01,  4.6110e-01,  8.8262e-01, -1.7038e+00, -8.3047e-01,\n",
      "           9.6022e-02,  2.2452e-01,  1.3397e-01,  1.5740e-01,  3.9711e-01,\n",
      "           1.7809e+00, -1.4859e-01,  6.1304e-01, -5.1841e-01,  5.9695e-02,\n",
      "          -6.5050e-01, -5.0063e-02, -2.0790e-02, -9.8684e-02, -8.6913e-01,\n",
      "           3.1795e-01,  5.8919e-01, -4.3025e-01,  1.6805e-01, -1.6244e+00,\n",
      "           1.1406e+00, -6.2632e-01,  1.4851e-02, -1.3713e-01,  1.2415e-01,\n",
      "          -8.0380e-01,  1.4809e+00,  8.1456e-01, -7.7490e-01, -5.6696e-01,\n",
      "           2.8069e-01, -3.3325e-01, -6.6795e-01,  4.5635e-01,  1.8636e-01,\n",
      "          -2.7033e-01, -6.1700e-01,  7.7415e-01, -4.7894e-01,  1.2584e+00,\n",
      "          -2.2849e-01,  1.9504e-01,  3.6643e-01, -2.7101e-01,  1.0068e+00,\n",
      "           2.0212e-02,  7.3740e-01,  6.9593e-02,  8.1442e-01,  3.0647e-01],\n",
      "         [ 2.2436e-01,  1.7030e-01,  1.5454e-01, -5.4209e-01, -1.1723e+00,\n",
      "           3.8347e-01,  6.8882e-04,  6.7641e-01, -6.0793e-01, -8.5367e-01,\n",
      "           1.9934e-01, -8.7626e-01, -3.2894e-01, -8.3591e-01, -1.3181e+00,\n",
      "          -8.7349e-01, -5.5290e-02, -6.2123e-01, -7.3228e-01, -3.1099e-01,\n",
      "          -8.2433e-01,  5.2567e-01,  2.9478e-01,  2.6369e-01, -1.0796e-01,\n",
      "          -1.9514e-02,  2.2952e-01, -7.5005e-01,  5.2535e-01, -1.8827e-01,\n",
      "          -1.7342e-02, -1.9349e-01, -8.2957e-01,  2.0198e-01,  2.5380e-02,\n",
      "          -1.4443e+00, -6.6620e-01, -3.4613e-01,  3.2738e-01, -3.4000e-01,\n",
      "          -4.2898e-01,  4.8691e-01,  2.9637e-01,  9.2918e-01,  3.9288e-02,\n",
      "          -3.8061e-01,  4.6110e-01,  8.8262e-01, -1.7038e+00, -8.3047e-01,\n",
      "           9.6022e-02,  2.2452e-01,  1.3397e-01,  1.5740e-01,  3.9711e-01,\n",
      "           1.7809e+00, -1.4859e-01,  6.1304e-01, -5.1841e-01,  5.9695e-02,\n",
      "          -6.5050e-01, -5.0063e-02, -2.0790e-02, -9.8684e-02, -8.6913e-01,\n",
      "           3.1795e-01,  5.8919e-01, -4.3025e-01,  1.6805e-01, -1.6244e+00,\n",
      "           1.1406e+00, -6.2632e-01,  1.4851e-02, -1.3713e-01,  1.2415e-01,\n",
      "          -8.0380e-01,  1.4809e+00,  8.1456e-01, -7.7490e-01, -5.6696e-01,\n",
      "           2.8069e-01, -3.3325e-01, -6.6795e-01,  4.5635e-01,  1.8636e-01,\n",
      "          -2.7033e-01, -6.1700e-01,  7.7415e-01, -4.7894e-01,  1.2584e+00,\n",
      "          -2.2849e-01,  1.9504e-01,  3.6643e-01, -2.7101e-01,  1.0068e+00,\n",
      "           2.0212e-02,  7.3740e-01,  6.9593e-02,  8.1442e-01,  3.0647e-01]],\n",
      "\n",
      "        [[ 2.2436e-01,  1.7030e-01,  1.5454e-01, -5.4209e-01, -1.1723e+00,\n",
      "           3.8347e-01,  6.8882e-04,  6.7641e-01, -6.0793e-01, -8.5367e-01,\n",
      "           1.9934e-01, -8.7626e-01, -3.2894e-01, -8.3591e-01, -1.3181e+00,\n",
      "          -8.7349e-01, -5.5290e-02, -6.2123e-01, -7.3228e-01, -3.1099e-01,\n",
      "          -8.2433e-01,  5.2567e-01,  2.9478e-01,  2.6369e-01, -1.0796e-01,\n",
      "          -1.9514e-02,  2.2952e-01, -7.5005e-01,  5.2535e-01, -1.8827e-01,\n",
      "          -1.7342e-02, -1.9349e-01, -8.2957e-01,  2.0198e-01,  2.5380e-02,\n",
      "          -1.4443e+00, -6.6620e-01, -3.4613e-01,  3.2738e-01, -3.4000e-01,\n",
      "          -4.2898e-01,  4.8691e-01,  2.9637e-01,  9.2918e-01,  3.9288e-02,\n",
      "          -3.8061e-01,  4.6110e-01,  8.8262e-01, -1.7038e+00, -8.3047e-01,\n",
      "           9.6022e-02,  2.2452e-01,  1.3397e-01,  1.5740e-01,  3.9711e-01,\n",
      "           1.7809e+00, -1.4859e-01,  6.1304e-01, -5.1841e-01,  5.9695e-02,\n",
      "          -6.5050e-01, -5.0063e-02, -2.0790e-02, -9.8684e-02, -8.6913e-01,\n",
      "           3.1795e-01,  5.8919e-01, -4.3025e-01,  1.6805e-01, -1.6244e+00,\n",
      "           1.1406e+00, -6.2632e-01,  1.4851e-02, -1.3713e-01,  1.2415e-01,\n",
      "          -8.0380e-01,  1.4809e+00,  8.1456e-01, -7.7490e-01, -5.6696e-01,\n",
      "           2.8069e-01, -3.3325e-01, -6.6795e-01,  4.5635e-01,  1.8636e-01,\n",
      "          -2.7033e-01, -6.1700e-01,  7.7415e-01, -4.7894e-01,  1.2584e+00,\n",
      "          -2.2849e-01,  1.9504e-01,  3.6643e-01, -2.7101e-01,  1.0068e+00,\n",
      "           2.0212e-02,  7.3740e-01,  6.9593e-02,  8.1442e-01,  3.0647e-01],\n",
      "         [ 2.2436e-01,  1.7030e-01,  1.5454e-01, -5.4209e-01, -1.1723e+00,\n",
      "           3.8347e-01,  6.8882e-04,  6.7641e-01, -6.0793e-01, -8.5367e-01,\n",
      "           1.9934e-01, -8.7626e-01, -3.2894e-01, -8.3591e-01, -1.3181e+00,\n",
      "          -8.7349e-01, -5.5290e-02, -6.2123e-01, -7.3228e-01, -3.1099e-01,\n",
      "          -8.2433e-01,  5.2567e-01,  2.9478e-01,  2.6369e-01, -1.0796e-01,\n",
      "          -1.9514e-02,  2.2952e-01, -7.5005e-01,  5.2535e-01, -1.8827e-01,\n",
      "          -1.7342e-02, -1.9349e-01, -8.2957e-01,  2.0198e-01,  2.5380e-02,\n",
      "          -1.4443e+00, -6.6620e-01, -3.4613e-01,  3.2738e-01, -3.4000e-01,\n",
      "          -4.2898e-01,  4.8691e-01,  2.9637e-01,  9.2918e-01,  3.9288e-02,\n",
      "          -3.8061e-01,  4.6110e-01,  8.8262e-01, -1.7038e+00, -8.3047e-01,\n",
      "           9.6022e-02,  2.2452e-01,  1.3397e-01,  1.5740e-01,  3.9711e-01,\n",
      "           1.7809e+00, -1.4859e-01,  6.1304e-01, -5.1841e-01,  5.9695e-02,\n",
      "          -6.5050e-01, -5.0063e-02, -2.0790e-02, -9.8684e-02, -8.6913e-01,\n",
      "           3.1795e-01,  5.8919e-01, -4.3025e-01,  1.6805e-01, -1.6244e+00,\n",
      "           1.1406e+00, -6.2632e-01,  1.4851e-02, -1.3713e-01,  1.2415e-01,\n",
      "          -8.0380e-01,  1.4809e+00,  8.1456e-01, -7.7490e-01, -5.6696e-01,\n",
      "           2.8069e-01, -3.3325e-01, -6.6795e-01,  4.5635e-01,  1.8636e-01,\n",
      "          -2.7033e-01, -6.1700e-01,  7.7415e-01, -4.7894e-01,  1.2584e+00,\n",
      "          -2.2849e-01,  1.9504e-01,  3.6643e-01, -2.7101e-01,  1.0068e+00,\n",
      "           2.0212e-02,  7.3740e-01,  6.9593e-02,  8.1442e-01,  3.0647e-01],\n",
      "         [ 2.2436e-01,  1.7030e-01,  1.5454e-01, -5.4209e-01, -1.1723e+00,\n",
      "           3.8347e-01,  6.8897e-04,  6.7641e-01, -6.0793e-01, -8.5367e-01,\n",
      "           1.9934e-01, -8.7626e-01, -3.2894e-01, -8.3591e-01, -1.3181e+00,\n",
      "          -8.7349e-01, -5.5290e-02, -6.2123e-01, -7.3228e-01, -3.1099e-01,\n",
      "          -8.2433e-01,  5.2567e-01,  2.9478e-01,  2.6369e-01, -1.0796e-01,\n",
      "          -1.9513e-02,  2.2952e-01, -7.5005e-01,  5.2535e-01, -1.8827e-01,\n",
      "          -1.7342e-02, -1.9349e-01, -8.2957e-01,  2.0198e-01,  2.5380e-02,\n",
      "          -1.4443e+00, -6.6620e-01, -3.4613e-01,  3.2738e-01, -3.4000e-01,\n",
      "          -4.2898e-01,  4.8691e-01,  2.9637e-01,  9.2918e-01,  3.9288e-02,\n",
      "          -3.8061e-01,  4.6110e-01,  8.8262e-01, -1.7038e+00, -8.3047e-01,\n",
      "           9.6022e-02,  2.2452e-01,  1.3397e-01,  1.5740e-01,  3.9711e-01,\n",
      "           1.7809e+00, -1.4859e-01,  6.1304e-01, -5.1841e-01,  5.9695e-02,\n",
      "          -6.5050e-01, -5.0063e-02, -2.0790e-02, -9.8684e-02, -8.6913e-01,\n",
      "           3.1795e-01,  5.8919e-01, -4.3025e-01,  1.6805e-01, -1.6244e+00,\n",
      "           1.1406e+00, -6.2632e-01,  1.4851e-02, -1.3713e-01,  1.2415e-01,\n",
      "          -8.0380e-01,  1.4809e+00,  8.1456e-01, -7.7490e-01, -5.6696e-01,\n",
      "           2.8069e-01, -3.3325e-01, -6.6795e-01,  4.5635e-01,  1.8636e-01,\n",
      "          -2.7033e-01, -6.1700e-01,  7.7415e-01, -4.7894e-01,  1.2584e+00,\n",
      "          -2.2849e-01,  1.9504e-01,  3.6643e-01, -2.7101e-01,  1.0068e+00,\n",
      "           2.0212e-02,  7.3740e-01,  6.9593e-02,  8.1442e-01,  3.0647e-01],\n",
      "         [ 2.2436e-01,  1.7030e-01,  1.5454e-01, -5.4209e-01, -1.1723e+00,\n",
      "           3.8347e-01,  6.8897e-04,  6.7641e-01, -6.0793e-01, -8.5367e-01,\n",
      "           1.9934e-01, -8.7626e-01, -3.2894e-01, -8.3591e-01, -1.3181e+00,\n",
      "          -8.7349e-01, -5.5290e-02, -6.2123e-01, -7.3228e-01, -3.1099e-01,\n",
      "          -8.2433e-01,  5.2567e-01,  2.9478e-01,  2.6369e-01, -1.0796e-01,\n",
      "          -1.9513e-02,  2.2952e-01, -7.5005e-01,  5.2535e-01, -1.8827e-01,\n",
      "          -1.7342e-02, -1.9349e-01, -8.2957e-01,  2.0198e-01,  2.5380e-02,\n",
      "          -1.4443e+00, -6.6620e-01, -3.4613e-01,  3.2738e-01, -3.4000e-01,\n",
      "          -4.2898e-01,  4.8691e-01,  2.9637e-01,  9.2918e-01,  3.9288e-02,\n",
      "          -3.8061e-01,  4.6110e-01,  8.8262e-01, -1.7038e+00, -8.3047e-01,\n",
      "           9.6022e-02,  2.2452e-01,  1.3397e-01,  1.5740e-01,  3.9711e-01,\n",
      "           1.7809e+00, -1.4859e-01,  6.1304e-01, -5.1841e-01,  5.9695e-02,\n",
      "          -6.5050e-01, -5.0063e-02, -2.0790e-02, -9.8684e-02, -8.6913e-01,\n",
      "           3.1795e-01,  5.8919e-01, -4.3025e-01,  1.6805e-01, -1.6244e+00,\n",
      "           1.1406e+00, -6.2632e-01,  1.4851e-02, -1.3713e-01,  1.2415e-01,\n",
      "          -8.0380e-01,  1.4809e+00,  8.1456e-01, -7.7490e-01, -5.6696e-01,\n",
      "           2.8069e-01, -3.3325e-01, -6.6795e-01,  4.5635e-01,  1.8636e-01,\n",
      "          -2.7033e-01, -6.1700e-01,  7.7415e-01, -4.7894e-01,  1.2584e+00,\n",
      "          -2.2849e-01,  1.9504e-01,  3.6643e-01, -2.7101e-01,  1.0068e+00,\n",
      "           2.0212e-02,  7.3740e-01,  6.9593e-02,  8.1442e-01,  3.0647e-01]]],\n",
      "       grad_fn=<UnsafeViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "batch_size, num_queries, num_kvpairs  = 2, 4, 6\n",
    "X = torch.ones((batch_size, num_queries, num_hiddens))\n",
    "Y = torch.ones((batch_size, num_kvpairs, num_hiddens))\n",
    "attention = attention(X,Y,Y)\n",
    "print(attention.shape)\n",
    "print('/n',attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Attention GRU Models \n",
    "\n",
    "'''\n",
    "Attention GRU \n",
    "经典教程 \n",
    "1.https://github.com/bkoch4142/multimodal-emotion-classification/blob/main/src/models/multimodal_model.py\n",
    "2.https://github.com/mebasiri/Multimodal-Persian-Sentiment-Analysis/blob/main/Multimodal_Persian_SA.ipynb\n",
    "3.https://github.com/TianyiWu96/Multimodal-Sentiment/blob/master/multimodel.ipynb\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "'''\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "num_layers = 2\n",
    "dropout = 0.5\n",
    "\n",
    "'''\n",
    "class AttentionGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout,sequence_length,classes, **kwargs ):\n",
    "        super(AttentionGRU,self).__init__(**kwargs)\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length \n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.classes = classes\n",
    "        # -> x needs to be: (batch_size, seq, input_size) #rnn = nn.GRU(10, 20, 2)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, bidirectional=False)\n",
    "        self.attention =  DotProductAttention(dropout)\n",
    "        self.fc = nn.Linear(hidden_size*sequence_length,classes)\n",
    "\n",
    "    \n",
    "    def forward(self,X):\n",
    "        h0 = torch.randn(2, 5, 20) #h0 = torch.randn(2, 3, 20)\n",
    "        output, hn = self.gru(X, h0)\n",
    "        output = self.attention(output,output,output)\n",
    "        output = output.view(5, -1)\n",
    "        output = self.fc(output)\n",
    "    \n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " #hyper parameters\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "num_layers = 2\n",
    "dropout = 0.5\n",
    "sequence_length = 3\n",
    "classes = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "/n tensor([[-0.2684],\n",
      "        [-0.0181],\n",
      "        [ 0.2665],\n",
      "        [ 0.2027],\n",
      "        [-0.4124]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "input = torch.randn(5, 3, 10) #batch_size, sequence length, input_size \n",
    "model = AttentionGRU(input_size, hidden_size, num_layers, dropout, sequence_length, classes)\n",
    "output = attention(input)\n",
    "print(output.shape)\n",
    "print('/n',output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: argparseAttentionGRU.py [-h] [-input_size INPUT_SIZE] [-hidden_size HIDDEN_SIZE] [-num_layers NUM_LAYERS]\n",
      "                               [-dropout DROPOUT]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -input_size INPUT_SIZE\n",
      "                        input_size value\n",
      "  -hidden_size HIDDEN_SIZE\n",
      "                        hidden_size value\n",
      "  -num_layers NUM_LAYERS\n",
      "                        num_layers value\n",
      "  -dropout DROPOUT      num_layers value\n"
     ]
    }
   ],
   "source": [
    "#parse 命令行交互\n",
    "\n",
    "%run argparseAttentionGRU.py -h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dropout=0.5, hidden_size=20, input_size=10, num_layers=2)\n",
      "torch.Size([5, 3, 20])\n",
      "/n tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 3.4058e-01,  1.6781e-01,  2.1736e-01, -1.8409e-01, -5.5026e-01,\n",
      "           6.3767e-02, -4.6631e-01, -2.8172e-02,  6.9431e-01,  2.7502e-01,\n",
      "           2.6080e-01,  8.6338e-01,  2.5791e-01, -1.4861e+00, -4.2175e-02,\n",
      "          -3.3868e-01,  4.8211e-01, -5.0012e-01, -5.2207e-01, -9.6348e-02],\n",
      "         [ 1.2039e-01,  5.7068e-02,  1.1424e-01, -8.4617e-02, -2.4293e-01,\n",
      "           2.0479e-02, -2.3074e-01, -6.6432e-03,  3.2634e-01,  1.1089e-01,\n",
      "           8.7724e-02,  3.6122e-01,  1.1445e-01, -6.7487e-01, -1.4012e-02,\n",
      "          -1.7232e-01,  2.2308e-01, -2.1329e-01, -2.1174e-01, -9.5305e-02]],\n",
      "\n",
      "        [[ 7.3566e-01, -3.1927e+00,  2.6244e+00, -3.8447e+00, -5.1967e-01,\n",
      "           6.1603e+00,  3.4618e+00, -3.8055e+00,  3.7798e+00, -5.7217e-03,\n",
      "           9.2391e+00,  7.8353e-01, -4.3306e+00, -2.4316e+00,  1.7919e+00,\n",
      "           8.5637e-01,  2.7745e+00, -3.4547e+00, -3.8386e+00,  3.7610e+00],\n",
      "         [ 6.1982e-01, -2.5035e+00,  2.0689e+00, -3.0280e+00, -4.1184e-01,\n",
      "           4.8287e+00,  2.6883e+00, -2.9498e+00,  2.9680e+00,  4.3588e-02,\n",
      "           7.2611e+00,  6.3512e-01, -3.3629e+00, -1.9054e+00,  1.4404e+00,\n",
      "           6.6172e-01,  2.1933e+00, -2.7286e+00, -2.9661e+00,  2.9471e+00],\n",
      "         [-2.1690e-02, -1.1363e+00,  8.6105e-01, -1.2813e+00, -1.5620e-01,\n",
      "           2.2042e+00,  1.4054e+00, -1.5796e+00,  1.3176e+00, -3.1925e-01,\n",
      "           3.1796e+00,  1.4209e-01, -1.7579e+00, -8.7449e-01,  4.0439e-01,\n",
      "           3.6932e-01,  8.7011e-01, -1.1000e+00, -1.6551e+00,  1.3522e+00]],\n",
      "\n",
      "        [[-2.4143e-01,  2.8474e-01, -1.3191e-01, -4.8730e-02,  2.1902e-01,\n",
      "           7.4995e-03, -2.6051e-01,  4.0768e-01,  1.2589e-01, -3.7788e-02,\n",
      "           7.1581e-02, -6.8506e-02,  1.8533e-01,  2.1059e-01, -1.7985e-01,\n",
      "           3.4063e-01,  1.8545e-01, -4.4789e-01,  8.9650e-02, -2.6118e-01],\n",
      "         [-1.7722e+00,  2.1268e+00, -8.2584e-01, -1.0422e+00,  1.4121e+00,\n",
      "           7.1697e-01, -9.4561e-01,  2.4846e+00, -3.8627e-01, -1.1686e+00,\n",
      "          -1.1508e-01, -4.8241e-01,  5.0772e-01,  4.3978e-01, -1.0385e+00,\n",
      "           1.0055e+00,  9.9314e-02, -3.1450e+00, -1.8332e-01, -8.2808e-01],\n",
      "         [-6.0077e-01,  7.6335e-01, -3.1067e-01, -4.8953e-01,  5.0301e-01,\n",
      "           3.4785e-01, -2.2913e-01,  8.2693e-01, -2.9688e-01, -5.0494e-01,\n",
      "          -1.4386e-01, -1.3573e-01,  1.0478e-01,  3.0380e-02, -3.2511e-01,\n",
      "           2.1615e-01, -1.5298e-01, -1.1341e+00, -1.6828e-01, -1.0521e-01]],\n",
      "\n",
      "        [[-2.5741e-01, -3.4670e-01, -1.7612e+00,  4.3918e-01, -5.1562e-01,\n",
      "          -1.3356e+00, -8.4714e-01,  8.7958e-01,  4.1924e-01, -7.4513e-03,\n",
      "           5.1644e-01,  8.2839e-01,  2.6067e-01,  4.0070e-01, -8.1764e-01,\n",
      "           5.9733e-01,  1.0532e-01,  4.8875e-01, -6.1483e-01,  1.0789e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [-4.5507e-02, -9.1740e-02, -3.3243e-01, -5.3872e-04, -1.8460e-01,\n",
      "          -2.8376e-01, -1.9579e-01,  8.8642e-02,  2.3282e-01,  5.9416e-03,\n",
      "           2.6010e-01,  1.4099e-01,  2.5380e-02,  1.5084e-01, -1.2291e-01,\n",
      "           5.3561e-02,  6.1052e-02,  7.0342e-02, -1.9778e-01,  7.2282e-02]],\n",
      "\n",
      "        [[ 8.1659e-01,  1.0690e-01, -7.1177e-01,  7.3599e-02, -1.9023e+00,\n",
      "          -8.6004e-01, -2.1275e+00,  3.7534e-01, -9.1755e-01, -5.2631e-01,\n",
      "           6.8499e-01,  8.8676e-01,  9.1877e-01, -8.4269e-01,  9.2798e-01,\n",
      "          -3.6085e-01,  1.5262e+00, -2.0402e+00,  7.9073e-01, -3.0129e-01],\n",
      "         [ 6.5122e-01,  7.8271e-02, -5.4902e-01, -3.8665e-02, -1.4630e+00,\n",
      "          -6.9485e-01, -1.6963e+00,  3.8657e-01, -6.5855e-01, -2.8965e-01,\n",
      "           6.6047e-01,  7.3026e-01,  7.0957e-01, -7.2456e-01,  7.2370e-01,\n",
      "          -1.2186e-01,  1.3965e+00, -1.7569e+00,  6.1394e-01, -1.8678e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "       grad_fn=<BmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "%run argparseAttentionGRU.py -input_size 10 -hidden_size 20 -num_layers 2 -dropout 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save models \n",
    "torch.save(attention.state_dict(),'ckpt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'>\n"
     ]
    }
   ],
   "source": [
    "#load models\n",
    "path = \"‪C:/Users/faustineljc/ckpt.pt\"\n",
    "path = path.strip('\\u202a')\n",
    "\n",
    "save_file = torch.load(path)\n",
    "print(type(save_file))\n",
    "print(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter:  gru.weight_ih_l0 value： tensor([[-0.0234,  0.1535,  0.0039, -0.1389,  0.2227, -0.0492, -0.0702, -0.1888,\n",
      "          0.1331, -0.0688],\n",
      "        [-0.0030,  0.0479,  0.0667, -0.2131, -0.0623, -0.2042,  0.2223, -0.1043,\n",
      "         -0.0053,  0.0620],\n",
      "        [ 0.1338, -0.1320,  0.0929,  0.0018, -0.1536, -0.1907, -0.1617,  0.1501,\n",
      "          0.1340,  0.0870],\n",
      "        [ 0.0960,  0.2024, -0.2114,  0.0578,  0.0968, -0.0255,  0.0992, -0.0854,\n",
      "         -0.1059, -0.1644],\n",
      "        [-0.0155,  0.0243,  0.1070, -0.0035,  0.1032,  0.0946, -0.0908, -0.1152,\n",
      "          0.0237,  0.0245],\n",
      "        [ 0.0461, -0.1165,  0.1645,  0.0752,  0.1066,  0.1112, -0.0887, -0.0754,\n",
      "         -0.0216,  0.1216],\n",
      "        [-0.1473, -0.1237, -0.1776,  0.0838,  0.2006, -0.0533,  0.1327, -0.1997,\n",
      "         -0.2010,  0.1693],\n",
      "        [-0.2169,  0.1044, -0.1931,  0.0790, -0.0850,  0.0166,  0.2194, -0.0294,\n",
      "         -0.1334, -0.0756],\n",
      "        [ 0.1139, -0.1640, -0.1121,  0.1406, -0.0686, -0.1956,  0.2181, -0.1623,\n",
      "         -0.1291, -0.2204],\n",
      "        [-0.1314,  0.0410,  0.1173, -0.1249, -0.1625,  0.1719, -0.0736, -0.0979,\n",
      "         -0.0575, -0.1830],\n",
      "        [-0.1578, -0.1942, -0.1005, -0.1022,  0.1914, -0.0958, -0.1804,  0.2188,\n",
      "          0.1980,  0.1714],\n",
      "        [-0.1532, -0.0947, -0.0404,  0.1569, -0.1349,  0.0546,  0.1014,  0.1897,\n",
      "          0.0757,  0.0881],\n",
      "        [-0.1089, -0.2033,  0.0061,  0.0208,  0.1254, -0.0991, -0.0005, -0.0453,\n",
      "          0.1083, -0.0550],\n",
      "        [-0.1111, -0.0109,  0.1511, -0.2199,  0.1138, -0.2126, -0.1675, -0.1125,\n",
      "         -0.1352, -0.1477],\n",
      "        [-0.0264, -0.0684,  0.1833,  0.1565, -0.0553, -0.2123, -0.1640,  0.1742,\n",
      "          0.0304, -0.1837],\n",
      "        [ 0.1762,  0.1833, -0.1638, -0.1093,  0.1026, -0.0240,  0.1472, -0.0042,\n",
      "          0.1388,  0.0254],\n",
      "        [ 0.2021,  0.1402, -0.0781, -0.1555,  0.1769,  0.1081,  0.2092, -0.0456,\n",
      "          0.1968,  0.0822],\n",
      "        [ 0.2054, -0.1003, -0.1291, -0.1428,  0.2088,  0.1688,  0.1777, -0.1794,\n",
      "         -0.1853, -0.0801],\n",
      "        [-0.1163, -0.0988, -0.0528, -0.0535, -0.1091, -0.1346, -0.1508, -0.0475,\n",
      "         -0.0208,  0.1119],\n",
      "        [-0.0787,  0.1962,  0.0911, -0.2028, -0.1786,  0.1997,  0.0685,  0.1421,\n",
      "          0.1310,  0.0719],\n",
      "        [-0.0147, -0.1328, -0.1823,  0.1831,  0.0469,  0.2035, -0.1097, -0.0630,\n",
      "         -0.0151, -0.1750],\n",
      "        [-0.1496,  0.1625,  0.0915,  0.0585,  0.1590,  0.0375, -0.1555, -0.2163,\n",
      "         -0.0950, -0.0507],\n",
      "        [ 0.0678, -0.1129, -0.0457, -0.0632, -0.1239,  0.1092,  0.0550,  0.2153,\n",
      "         -0.1090,  0.0520],\n",
      "        [-0.1661,  0.2187,  0.1964,  0.1045, -0.0992,  0.0345,  0.0764,  0.0181,\n",
      "          0.1340, -0.1786],\n",
      "        [ 0.0206, -0.1931,  0.0973, -0.2004, -0.1475,  0.0122, -0.0782,  0.1312,\n",
      "          0.1096, -0.0051],\n",
      "        [ 0.0139, -0.2120, -0.0268,  0.1939, -0.0887,  0.0238,  0.0149,  0.1598,\n",
      "          0.1672,  0.1425],\n",
      "        [ 0.0706,  0.1625,  0.0764,  0.1097,  0.0649, -0.0399, -0.0682,  0.0467,\n",
      "         -0.2227,  0.1319],\n",
      "        [-0.1939, -0.1067, -0.0183, -0.0944, -0.0947, -0.1767, -0.0130,  0.2133,\n",
      "          0.1354, -0.1786],\n",
      "        [-0.1435,  0.1246,  0.1430,  0.2083, -0.0280, -0.1797,  0.1652,  0.1020,\n",
      "          0.0716,  0.0110],\n",
      "        [ 0.1674,  0.1899, -0.1026,  0.1837,  0.1763,  0.0476, -0.0556, -0.1278,\n",
      "          0.0446,  0.2027],\n",
      "        [-0.0506, -0.0427,  0.1758,  0.0776,  0.2184, -0.1201, -0.1517, -0.0420,\n",
      "         -0.0601, -0.0484],\n",
      "        [ 0.1698,  0.0817, -0.1132,  0.1637,  0.1994, -0.1284, -0.1960, -0.0948,\n",
      "         -0.1775,  0.1489],\n",
      "        [-0.1488,  0.1640,  0.1006,  0.1480,  0.1658, -0.1883,  0.1624,  0.1233,\n",
      "          0.0741, -0.2056],\n",
      "        [ 0.0570, -0.0377, -0.1428, -0.1974, -0.2170, -0.0886, -0.1403,  0.0107,\n",
      "          0.0582, -0.1108],\n",
      "        [ 0.0980, -0.0905,  0.1866,  0.0108, -0.0878,  0.0605,  0.1058, -0.1155,\n",
      "          0.0221,  0.2180],\n",
      "        [-0.0309, -0.0320,  0.1429,  0.0401,  0.0806,  0.1035, -0.1537,  0.0813,\n",
      "          0.1799,  0.1065],\n",
      "        [ 0.0635,  0.0162, -0.1264, -0.0904,  0.0253, -0.1959,  0.2119,  0.1671,\n",
      "          0.0016, -0.1590],\n",
      "        [-0.1994,  0.2000, -0.0705, -0.0056, -0.0703, -0.2202,  0.0440,  0.0908,\n",
      "         -0.0349,  0.2203],\n",
      "        [ 0.1480, -0.1300,  0.1632,  0.2012,  0.0364,  0.0223, -0.0760, -0.1475,\n",
      "         -0.0387, -0.0556],\n",
      "        [-0.1538,  0.1169, -0.0413, -0.0966, -0.2140, -0.1360, -0.0451, -0.2112,\n",
      "         -0.0856,  0.2141],\n",
      "        [-0.0674, -0.0242,  0.0072,  0.0469,  0.1056,  0.0204,  0.1850,  0.0404,\n",
      "          0.0771,  0.0363],\n",
      "        [-0.1778,  0.0765, -0.1559, -0.0921, -0.0182,  0.2124, -0.0802,  0.0084,\n",
      "         -0.0687,  0.1502],\n",
      "        [ 0.0750, -0.1353,  0.1352, -0.0336, -0.0051,  0.2156, -0.0897,  0.1432,\n",
      "         -0.0196, -0.0052],\n",
      "        [ 0.1844,  0.2050,  0.2113,  0.1515, -0.1886, -0.1353, -0.0583, -0.1883,\n",
      "         -0.0181,  0.0670],\n",
      "        [ 0.1350,  0.1747, -0.0026,  0.1720, -0.1543, -0.0297, -0.0578,  0.0495,\n",
      "         -0.0930,  0.0227],\n",
      "        [-0.2052, -0.1182, -0.1873, -0.1788, -0.0352, -0.0375,  0.1198, -0.1179,\n",
      "          0.1846, -0.2038],\n",
      "        [-0.1055,  0.1006, -0.1330, -0.1487,  0.1648, -0.2099, -0.0688, -0.0505,\n",
      "          0.2008,  0.1549],\n",
      "        [ 0.1155,  0.1512, -0.1997, -0.1647,  0.1538, -0.2162,  0.1927,  0.0524,\n",
      "          0.1182,  0.0697],\n",
      "        [-0.1828, -0.0618, -0.2024, -0.1249,  0.0491,  0.1805, -0.1883, -0.0197,\n",
      "         -0.0504,  0.0438],\n",
      "        [-0.0224,  0.1097,  0.0469,  0.1854,  0.1806,  0.1985, -0.0301,  0.1480,\n",
      "         -0.1495, -0.0148],\n",
      "        [-0.1748, -0.0891, -0.1596, -0.0007, -0.0799,  0.1630,  0.2194,  0.1654,\n",
      "          0.1723, -0.0643],\n",
      "        [-0.1298, -0.0819,  0.2069,  0.1593,  0.1838, -0.0624,  0.1592, -0.2144,\n",
      "          0.1811,  0.1640],\n",
      "        [-0.0696, -0.0414, -0.1250,  0.1869,  0.0685,  0.0130, -0.1242, -0.0086,\n",
      "         -0.0372, -0.1114],\n",
      "        [-0.1290,  0.1342,  0.1435,  0.1363, -0.0759, -0.1484,  0.1822, -0.0757,\n",
      "         -0.0428, -0.1312],\n",
      "        [-0.1425,  0.1081,  0.0722,  0.0410,  0.2176,  0.2214, -0.1965,  0.1750,\n",
      "          0.0901,  0.1015],\n",
      "        [-0.2026, -0.1235,  0.1958,  0.2064,  0.1536,  0.0601,  0.0056,  0.0027,\n",
      "          0.1435,  0.2125],\n",
      "        [-0.1348, -0.1368, -0.2177, -0.0042,  0.1675, -0.0654,  0.0529,  0.1004,\n",
      "          0.0301, -0.0765],\n",
      "        [-0.0783, -0.2031,  0.1756, -0.2213, -0.0689,  0.1191,  0.0500, -0.0949,\n",
      "         -0.2185,  0.1607],\n",
      "        [-0.0732,  0.1362, -0.0984, -0.1311, -0.0356,  0.1567,  0.1659, -0.0256,\n",
      "          0.0115, -0.0526],\n",
      "        [-0.0680, -0.0889,  0.1229, -0.0223, -0.0670, -0.1355, -0.1195, -0.1949,\n",
      "          0.0375,  0.0253]])\n",
      "parameter:  gru.weight_hh_l0 value： tensor([[ 0.1723,  0.0895, -0.0738,  ...,  0.2136,  0.0998,  0.1787],\n",
      "        [-0.0844,  0.0170,  0.0158,  ..., -0.0295, -0.0185, -0.1248],\n",
      "        [ 0.2222,  0.0988, -0.0838,  ...,  0.0156, -0.1835,  0.1347],\n",
      "        ...,\n",
      "        [-0.1715,  0.1802, -0.1177,  ...,  0.0901,  0.2215, -0.0220],\n",
      "        [ 0.1259, -0.1400, -0.0998,  ...,  0.0892, -0.0370, -0.1957],\n",
      "        [-0.1437, -0.1053, -0.1106,  ...,  0.0133, -0.2123, -0.1063]])\n",
      "parameter:  gru.bias_ih_l0 value： tensor([-0.1907,  0.1721, -0.1499, -0.1032, -0.1445,  0.1148,  0.0878,  0.1585,\n",
      "         0.0106,  0.0887,  0.1965, -0.1039,  0.1488,  0.0790, -0.1734,  0.1134,\n",
      "        -0.1893, -0.0606, -0.1014,  0.0445, -0.0886, -0.0248,  0.0860,  0.0185,\n",
      "         0.0078,  0.1838, -0.0935, -0.1811,  0.0618,  0.0222,  0.0067,  0.1574,\n",
      "        -0.2170,  0.1313,  0.0753, -0.2157,  0.2006,  0.0409, -0.1043, -0.1839,\n",
      "         0.0349,  0.0283, -0.1258,  0.1605,  0.0430,  0.0243, -0.0276,  0.0203,\n",
      "        -0.1442,  0.1758,  0.0719, -0.1394, -0.1489,  0.1432,  0.0648, -0.0230,\n",
      "        -0.0296, -0.0611, -0.0027,  0.0590])\n",
      "parameter:  gru.bias_hh_l0 value： tensor([-0.1777,  0.1721, -0.0370, -0.2163, -0.1357, -0.0683, -0.0608,  0.0758,\n",
      "        -0.1925, -0.0122,  0.2039, -0.0305, -0.1060, -0.0798,  0.0637,  0.2069,\n",
      "        -0.1123, -0.0684,  0.1108, -0.0530, -0.0424, -0.0782,  0.0572, -0.1497,\n",
      "        -0.1109,  0.0832, -0.0232, -0.0121,  0.1594, -0.1682, -0.0728,  0.0262,\n",
      "        -0.1897, -0.1103, -0.1925, -0.0117, -0.1741,  0.1934,  0.0887, -0.1248,\n",
      "         0.1300,  0.1951, -0.1038, -0.2205, -0.0928,  0.0747, -0.1941,  0.0927,\n",
      "         0.1963,  0.1830,  0.0203,  0.1836,  0.1263,  0.1062,  0.1163, -0.0621,\n",
      "        -0.0153,  0.0495,  0.1725, -0.1655])\n",
      "parameter:  gru.weight_ih_l1 value： tensor([[ 0.0860, -0.1881,  0.1175,  ..., -0.1533, -0.0570,  0.1255],\n",
      "        [ 0.2085,  0.1594, -0.0043,  ..., -0.0139,  0.1362, -0.0342],\n",
      "        [ 0.0450, -0.0952,  0.0356,  ..., -0.0646,  0.0587,  0.0974],\n",
      "        ...,\n",
      "        [-0.1753, -0.2157,  0.0546,  ..., -0.0180,  0.1999, -0.1788],\n",
      "        [ 0.1726, -0.1254,  0.0265,  ..., -0.0847,  0.0561,  0.1247],\n",
      "        [ 0.1422, -0.0802,  0.1983,  ..., -0.0733, -0.0382, -0.1836]])\n",
      "parameter:  gru.weight_hh_l1 value： tensor([[-0.0585, -0.0848, -0.1674,  ...,  0.1796, -0.0331, -0.1516],\n",
      "        [ 0.1120,  0.0250, -0.1567,  ...,  0.0942, -0.2034, -0.0659],\n",
      "        [ 0.0907,  0.0516, -0.2106,  ...,  0.0079,  0.2131, -0.2203],\n",
      "        ...,\n",
      "        [-0.0862, -0.0085, -0.1559,  ..., -0.2058, -0.0957,  0.1376],\n",
      "        [-0.0558,  0.1156, -0.0639,  ...,  0.1890,  0.1458, -0.0494],\n",
      "        [-0.1362,  0.0992,  0.0480,  ...,  0.1215, -0.0908,  0.0135]])\n",
      "parameter:  gru.bias_ih_l1 value： tensor([ 0.1417,  0.0158,  0.0538,  0.0546,  0.1792, -0.1105,  0.2036, -0.1156,\n",
      "        -0.1881, -0.0097, -0.1424,  0.0238, -0.0701, -0.1997, -0.1605,  0.0878,\n",
      "        -0.1500,  0.1921,  0.1214, -0.0082,  0.0798,  0.1656,  0.2131,  0.2027,\n",
      "         0.1652, -0.1977,  0.0555,  0.1863, -0.1114, -0.1522, -0.1154, -0.0511,\n",
      "         0.1170, -0.1835, -0.1816, -0.0910,  0.0170, -0.0360,  0.1525, -0.1214,\n",
      "         0.1131,  0.0011, -0.1154, -0.1177,  0.0731,  0.1422,  0.1287,  0.0866,\n",
      "         0.0119,  0.1216,  0.1883,  0.2160,  0.0708, -0.1199,  0.0924,  0.1164,\n",
      "         0.0402, -0.2210, -0.1461,  0.0529])\n",
      "parameter:  gru.bias_hh_l1 value： tensor([-0.0472, -0.2141,  0.2033, -0.0571, -0.0667, -0.2196, -0.1365, -0.0631,\n",
      "         0.0157, -0.1149,  0.0156,  0.0262,  0.0696,  0.1536,  0.0434, -0.0211,\n",
      "         0.1679,  0.1138, -0.0002,  0.0566,  0.1155,  0.0846,  0.0299, -0.2016,\n",
      "         0.1082,  0.0136,  0.0583,  0.1503,  0.1242,  0.1292, -0.1209,  0.0979,\n",
      "         0.0364,  0.0137,  0.0325,  0.2153, -0.1329, -0.0427, -0.0618,  0.0600,\n",
      "         0.1022, -0.1683, -0.1386,  0.2166, -0.0998,  0.0469, -0.1477,  0.1126,\n",
      "        -0.2213,  0.1637, -0.0150,  0.2020,  0.0814,  0.0815,  0.0321,  0.1781,\n",
      "         0.1280, -0.0346,  0.2163, -0.0766])\n"
     ]
    }
   ],
   "source": [
    "for k,v in save_file.items():\n",
    "    print('parameter: ',k,  'value：', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nn.Linear models \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#tensorboard 使用tutorials\n",
    "pytorch数据展示summarywriter的两个函数 \n",
    "https://blog.csdn.net/M_arshal_/article/details/120324253\n",
    "https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-tensorboard-with-pytorch.md\n",
    "https://www.jianshu.com/p/46eb3004beca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "from torchvision import datasets, transforms \n",
    "\n",
    "#writer will output to ./runs/directory by default \n",
    "\n",
    "writer = SummaryWriter('C:/Users/faustineljc/Desktop')\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))])\n",
    "trainset = datasets.MNIST('mnist_train',train = True, download = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 6, shuffle = True)\n",
    "\n",
    "model = torchvision.models.resnet50(False)\n",
    "print(model)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image('images',grid, 0 )\n",
    "writer.add_graph(model, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This can then be visualized wit tensorboard, which should be installed and runnable with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#log dir:tensorboard 文件的存放路径\n",
    "writer = SummaryWriter(log_dir = 'runs/exp1')\n",
    "x = range(100)\n",
    "for i in x:\n",
    "    writer.add_scalar('y=2x', i * 2, i)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser 函数\n",
    "'''\n",
    "https://www.jianshu.com/p/27ce67dab97e\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytroch dataset dataloader 经典教程\n",
    "\n",
    "'''\n",
    "1.https://blog.csdn.net/sdnuwjw/article/details/111227327\n",
    "2.https://geek-docs.com/pytorch/pytorch-tutorial/pytorch-dataset.html\n",
    "3.http://www.pytorchmaster.com/5-1%2CDataset%E5%92%8CDataLoader/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "#packages load datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "source_data = np.random.randn(100,3, 10)\n",
    "source_data = torch.from_numpy(source_data)\n",
    "\n",
    "source_label = np.random.randint(0,6,(100, 1))\n",
    "source_label =  torch.from_numpy(source_label)\n",
    "print(\"#\"*len(source_data))\n",
    "\n",
    "\n",
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, data_root,data_label):\n",
    "        self.data = data_root\n",
    "        self.label= data_label\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        label = self.label[idx]\n",
    "        return data, label\n",
    "\n",
    "\n",
    "#print(type(custom_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyDataSet object at 0x000001A0F80CDE50>\n"
     ]
    }
   ],
   "source": [
    "custom_dataset = MyDataSet(source_data, source_label)\n",
    "print(custom_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def get_loaders(dataset = custom_dataset, batch_size = 5, num_workers  = 0):\n",
    " \n",
    "    return  DataLoader(dataset = dataset, batch_size=batch_size, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001A0F80CDE20>\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_loaders()\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[[ 0.5906,  2.1254, -1.4106, -0.0708, -1.1566,  0.3031,  0.4593,\n",
      "           0.6527,  0.4387, -0.1382],\n",
      "         [ 1.0361,  0.8170, -2.2161, -1.2387, -1.0338, -1.1582,  1.0863,\n",
      "          -1.2731,  0.2998,  1.0527],\n",
      "         [ 0.9313,  1.5582,  2.1073, -0.7450, -0.0034,  1.5202, -1.3243,\n",
      "          -0.9366,  2.6180, -0.6339]],\n",
      "\n",
      "        [[ 0.5543,  0.5932,  0.1466,  0.2104, -0.2425,  0.0335, -0.2221,\n",
      "           0.9109,  0.3075, -0.5472],\n",
      "         [ 2.1602, -2.2460,  0.1286,  0.3825,  0.0081,  1.1463,  0.5968,\n",
      "           3.0428,  0.0080, -2.1197],\n",
      "         [-0.0711, -2.6423,  1.9394, -0.4242,  0.0202, -2.4865,  1.3386,\n",
      "           1.6613,  1.0677,  1.8485]],\n",
      "\n",
      "        [[-0.8536, -1.0123, -0.1331, -0.4215, -0.3352, -0.3252,  0.4758,\n",
      "           0.3469,  0.3074, -0.3635],\n",
      "         [ 0.5422,  0.9570, -0.3695, -0.3208,  1.7008, -1.5595,  0.3833,\n",
      "          -0.9529,  0.9771, -1.1279],\n",
      "         [ 1.3337, -1.8153, -1.0798,  0.7307, -0.9975, -1.1125,  1.3222,\n",
      "          -0.7713, -0.8510,  0.7217]],\n",
      "\n",
      "        [[ 0.4440, -1.7295,  0.0793,  1.0823,  1.5424, -0.3692, -0.1173,\n",
      "           1.0512,  0.0453, -0.0541],\n",
      "         [ 0.9509, -0.4926,  0.4038, -0.4120, -1.1851, -0.6540,  0.9156,\n",
      "           0.6040, -0.2844,  1.0970],\n",
      "         [-0.5381, -1.8375, -0.6264, -1.0921,  0.7082, -0.5643, -0.3928,\n",
      "          -2.0412,  1.4737,  0.3660]],\n",
      "\n",
      "        [[-0.9275,  1.0108, -0.9923,  0.7328, -0.9495,  1.0516,  0.1982,\n",
      "          -0.1757,  0.9012, -1.6065],\n",
      "         [ 1.1149, -0.0299, -1.3812,  0.8027,  0.2500,  0.5463, -0.6949,\n",
      "           0.6455, -0.5047, -1.8994],\n",
      "         [-1.6678, -1.8103, -0.3139,  0.7271, -0.4832, -2.0842, -0.6923,\n",
      "           0.6334,  0.3888,  0.8223]]], dtype=torch.float64), tensor([[4],\n",
      "        [4],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3]], dtype=torch.int32)] \n",
      "1 [tensor([[[-0.0949,  0.7080, -0.5131,  0.4428, -1.0632, -1.2070, -1.4654,\n",
      "          -1.4019,  0.3885,  0.0444],\n",
      "         [-0.2163,  1.5797, -2.3284, -0.2002,  1.0102,  0.8071, -0.1719,\n",
      "          -1.5339, -2.7852,  0.0300],\n",
      "         [-1.0980, -0.6542,  0.2559,  1.4871,  1.1421,  0.1982, -0.5651,\n",
      "           1.0988, -1.3647, -0.4150]],\n",
      "\n",
      "        [[-0.4661, -0.9245,  1.0228, -2.0793,  1.2367, -0.8241, -0.1151,\n",
      "          -1.2304,  1.4202,  1.2492],\n",
      "         [ 0.4103, -0.1162, -0.1575,  1.4049, -1.0699,  0.4610,  0.7069,\n",
      "          -0.2875, -1.2860, -0.0065],\n",
      "         [-1.6151, -0.5694,  0.9032, -2.4375,  0.7907,  0.2492,  0.7452,\n",
      "          -0.3478, -1.9159, -0.8729]],\n",
      "\n",
      "        [[ 1.3050,  0.6495, -0.4474,  0.8267,  0.3562, -0.8689, -1.5568,\n",
      "          -0.1751,  0.1181,  0.5334],\n",
      "         [-2.4406,  0.7252,  1.7886, -1.3036, -0.0106, -1.5277,  0.4094,\n",
      "           1.7230,  1.1520, -2.6296],\n",
      "         [-0.1682, -2.0730,  0.9472, -1.5080, -1.2599, -0.9248,  0.3760,\n",
      "          -1.3401, -0.3404, -0.8197]],\n",
      "\n",
      "        [[-2.9619,  0.2467,  0.2410,  0.6730,  0.0587,  0.5787,  0.0552,\n",
      "          -1.0068,  0.7005, -1.5077],\n",
      "         [-2.1030,  1.0850,  1.1668,  1.0056, -0.7988,  0.2729,  1.9007,\n",
      "          -0.8814, -0.9082,  0.8118],\n",
      "         [ 0.1106, -1.4344,  0.0820, -0.4009, -1.4669,  0.3131,  0.9349,\n",
      "          -0.7973, -1.3628, -0.7520]],\n",
      "\n",
      "        [[ 0.8104, -1.0592,  1.7683,  1.0795,  1.1360, -0.5845,  0.9309,\n",
      "           0.7926, -1.0430,  0.7946],\n",
      "         [ 0.3294, -0.0733,  1.3231, -1.2054, -0.7307,  0.0816,  2.5534,\n",
      "          -0.4607, -2.1539,  0.8422],\n",
      "         [-1.8459,  1.6656, -2.2630,  0.2276,  0.9046,  0.7245, -0.9726,\n",
      "           0.0862, -1.8375, -0.5234]]], dtype=torch.float64), tensor([[1],\n",
      "        [5],\n",
      "        [3],\n",
      "        [4],\n",
      "        [0]], dtype=torch.int32)] \n",
      "2 [tensor([[[ 1.3920e+00,  4.6078e-01, -3.7886e-01, -9.2843e-01, -4.4077e-01,\n",
      "           4.9887e-01,  5.3318e-01, -2.1577e-01,  2.4723e+00,  1.3886e+00],\n",
      "         [-9.2654e-01,  5.0082e-01, -7.2481e-01, -2.0918e+00, -9.1295e-01,\n",
      "          -1.5673e-01, -1.0445e+00, -6.4367e-01,  5.8199e-01, -1.9195e+00],\n",
      "         [-1.0051e+00, -5.8944e-01,  3.3119e-01,  4.3328e-01, -2.0050e-02,\n",
      "           1.8534e+00, -1.0206e+00, -8.2508e-01, -3.4331e-01,  9.5665e-01]],\n",
      "\n",
      "        [[ 1.0101e+00, -4.2809e-02, -4.5551e-01, -1.9430e+00, -1.2067e+00,\n",
      "          -6.3950e-01,  2.5787e-01, -1.3563e+00,  5.8462e-01, -4.4776e-01],\n",
      "         [-1.0310e+00,  1.6253e-01,  4.0450e-01, -4.0122e-01,  1.8345e+00,\n",
      "           1.8974e-01,  7.5762e-01,  2.0223e-01,  5.6129e-01,  5.8581e-02],\n",
      "         [ 2.1483e+00, -1.2603e+00, -6.3599e-01,  1.6770e-01,  1.7713e+00,\n",
      "          -1.0820e-01,  5.5307e-01, -9.9773e-01, -1.8843e+00,  6.4260e-01]],\n",
      "\n",
      "        [[-8.1549e-03, -2.9538e+00,  6.5840e-01, -1.2724e+00,  8.8170e-03,\n",
      "          -1.1571e-01, -1.0188e+00, -9.7413e-01,  1.8890e+00,  1.1177e+00],\n",
      "         [ 5.4900e-01,  1.0619e+00,  1.9073e+00, -8.7582e-01, -1.8017e-01,\n",
      "          -5.3752e-01, -1.2437e-01,  6.5472e-01,  1.1142e+00,  6.0078e-01],\n",
      "         [ 1.4496e-02, -1.1515e+00,  1.4940e-02,  7.8904e-01, -2.9214e-02,\n",
      "           1.0388e-01, -9.5165e-01, -4.1124e-01,  7.6528e-01,  1.0876e+00]],\n",
      "\n",
      "        [[-6.4688e-01, -1.1467e+00, -9.2257e-01,  8.1176e-02, -2.4105e-01,\n",
      "           6.8864e-01, -5.8827e-01, -1.2741e+00, -1.8039e+00,  9.6308e-01],\n",
      "         [ 8.8955e-01,  7.3893e-01, -4.1587e-01,  1.4273e-01,  7.8002e-01,\n",
      "          -3.5832e-01, -9.1465e-01,  2.0325e+00, -1.7860e+00,  3.7876e-01],\n",
      "         [ 1.1883e+00, -5.8658e-01,  3.2299e-01,  8.1036e-01,  8.0202e-01,\n",
      "          -1.7051e-01,  2.3824e+00, -3.7971e-01, -9.8327e-02,  2.4168e+00]],\n",
      "\n",
      "        [[ 6.1731e-01,  1.0923e+00,  4.7874e-01,  3.3491e-01,  3.1385e-02,\n",
      "           3.7517e-01, -5.8057e-01,  2.7951e-01, -3.8482e+00, -1.1966e+00],\n",
      "         [-2.1063e-03, -1.1740e+00, -9.3362e-01, -4.0880e-01, -8.4994e-01,\n",
      "          -4.7075e-01, -9.1843e-01, -1.0171e+00,  2.0688e-02,  3.8766e-01],\n",
      "         [-1.0144e+00,  2.2429e-01, -1.4325e-01,  3.6225e-01, -1.8824e+00,\n",
      "           1.1312e+00,  1.4658e+00,  9.1357e-01, -1.1968e-01, -5.2362e-01]]],\n",
      "       dtype=torch.float64), tensor([[3],\n",
      "        [2],\n",
      "        [0],\n",
      "        [4],\n",
      "        [1]], dtype=torch.int32)] \n",
      "3 [tensor([[[ 0.6218, -0.1379,  0.6448,  1.1409, -0.2219,  0.2550, -2.1344,\n",
      "          -1.8216, -0.8037,  0.5489],\n",
      "         [ 1.0215, -0.5328,  0.9757, -0.6689,  0.1132,  0.1331,  0.1265,\n",
      "           0.0890,  0.0097,  1.0574],\n",
      "         [ 0.4329,  0.1180, -0.5775, -2.8882,  0.7746, -1.3284, -1.6978,\n",
      "          -1.2284, -0.8530,  1.7133]],\n",
      "\n",
      "        [[-1.6209, -0.4424, -1.0045, -0.8201,  2.3449, -0.8167, -0.3538,\n",
      "          -0.0826, -1.1026,  0.4596],\n",
      "         [ 0.2861,  1.5082, -1.2012,  2.9257,  0.0195,  0.6442, -0.1041,\n",
      "          -0.1769, -0.7671, -0.0668],\n",
      "         [-0.3801,  0.0912, -0.8603,  1.2547,  1.9479, -0.8477, -0.6186,\n",
      "           1.0175,  0.8038, -2.2488]],\n",
      "\n",
      "        [[ 0.8293, -0.4936,  0.2203, -1.0850,  0.4440, -1.0664,  1.6776,\n",
      "          -0.7175,  0.0709, -1.3955],\n",
      "         [-0.5435, -0.5828,  0.4608,  0.5132, -0.9156,  0.2433, -0.6948,\n",
      "          -0.2402, -0.6465,  0.3714],\n",
      "         [ 1.7818,  0.8697,  0.0608, -0.0052, -1.9309,  0.4730, -0.9200,\n",
      "          -0.8222,  1.1786, -1.1762]],\n",
      "\n",
      "        [[ 1.2072,  0.2567, -1.2889, -1.5255, -1.3400,  0.5121,  0.6608,\n",
      "          -0.2148, -0.2831,  1.4310],\n",
      "         [-0.7861,  0.3904, -0.4646, -0.1533,  0.6653, -0.3047, -0.0885,\n",
      "          -0.5744,  0.7044,  0.2542],\n",
      "         [-1.1362, -0.6653,  0.9210, -0.8413, -2.2070, -0.1942, -0.1740,\n",
      "           1.2312,  0.8335,  0.2429]],\n",
      "\n",
      "        [[ 0.0543, -1.1312, -2.2913,  0.1490,  0.6792, -0.4907, -0.7317,\n",
      "           0.8063, -1.1178, -0.3797],\n",
      "         [-1.3184, -0.4599, -0.0394,  1.0986,  0.4313,  0.1638, -0.8602,\n",
      "          -1.2861, -1.2918, -0.8032],\n",
      "         [ 0.8137,  0.5846, -1.2779,  1.6127,  0.2861,  0.4747,  0.5463,\n",
      "          -0.2385,  2.9946,  0.3179]]], dtype=torch.float64), tensor([[5],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]], dtype=torch.int32)] \n",
      "4 [tensor([[[ 1.2476,  0.0664,  0.8243,  0.7315,  0.8890, -0.3770,  1.1006,\n",
      "           0.2162, -0.9773,  0.7722],\n",
      "         [-2.5534, -0.3023, -0.5040, -0.5954, -0.2909,  1.0048, -1.1719,\n",
      "           1.2084, -0.5077, -0.4362],\n",
      "         [ 0.2572,  0.9917,  1.1758,  0.7229, -0.4803, -0.3817,  0.2294,\n",
      "          -1.1181, -0.0305,  0.4972]],\n",
      "\n",
      "        [[ 1.2983, -0.4175,  1.0302, -1.0713, -0.4236, -0.5372,  0.7951,\n",
      "          -1.2911,  1.4959, -0.6367],\n",
      "         [ 0.8821, -0.3426, -0.1836, -0.9706, -1.0084,  0.6380,  1.2972,\n",
      "           0.5705, -1.0941,  0.9452],\n",
      "         [-0.8010,  0.6604,  2.2809, -0.0318, -0.1239,  0.9109, -2.3298,\n",
      "           0.6747, -0.1639,  0.1964]],\n",
      "\n",
      "        [[-0.2348,  0.9549,  0.0607, -0.5008,  0.5363, -0.0817, -1.4568,\n",
      "          -0.3966,  0.5445,  0.6195],\n",
      "         [ 0.9860,  1.5625, -0.6870,  0.1691, -0.4497,  0.7267, -1.3507,\n",
      "          -0.5543,  0.3439,  0.5305],\n",
      "         [ 0.2197,  0.8385,  0.3287, -1.4835, -2.6550,  1.9982,  1.0703,\n",
      "          -0.7490, -0.6349, -0.8954]],\n",
      "\n",
      "        [[ 1.2559, -0.9134, -0.5697,  0.9118, -0.4926, -2.1872,  0.4535,\n",
      "           0.0121,  0.9907, -0.5246],\n",
      "         [-0.5047, -1.9358, -0.3455, -0.3975,  0.6847, -0.2936, -1.2656,\n",
      "          -0.1055, -0.2062, -1.3848],\n",
      "         [ 0.7959, -0.0668,  1.2892,  0.2322, -0.2942,  0.2511, -0.0517,\n",
      "          -0.2095, -0.7166,  0.0252]],\n",
      "\n",
      "        [[ 0.2681,  0.7501,  0.2096, -2.0080,  0.1667, -0.3904, -0.4364,\n",
      "          -0.8531, -1.0062,  0.2736],\n",
      "         [-0.7366,  0.2966, -0.5598,  1.2793,  0.3011, -1.3595, -0.5907,\n",
      "           0.0883,  0.7170,  1.8682],\n",
      "         [-0.7004,  1.8745,  0.7760,  0.2063,  1.1512, -0.1796,  0.2776,\n",
      "           0.1364, -0.3464, -0.2956]]], dtype=torch.float64), tensor([[2],\n",
      "        [0],\n",
      "        [5],\n",
      "        [0],\n",
      "        [3]], dtype=torch.int32)] \n",
      "5 [tensor([[[ 2.1954e+00,  2.0413e+00, -1.0302e+00,  5.9008e-01, -6.2682e-01,\n",
      "           1.5547e+00, -2.6049e+00,  1.3278e+00,  1.5147e+00,  1.5768e+00],\n",
      "         [ 1.0501e+00,  1.4774e+00,  4.4021e-01, -3.1458e-01, -1.0427e+00,\n",
      "           3.3037e-01, -5.9728e-01, -1.0346e+00, -1.2288e-03, -9.7175e-02],\n",
      "         [ 7.2961e-01,  1.8569e-01, -7.0533e-01, -2.6218e-03, -1.9602e-02,\n",
      "          -7.4849e-01,  4.0274e-01, -9.2556e-01, -1.1866e+00, -1.9086e+00]],\n",
      "\n",
      "        [[ 5.5677e-01,  4.0842e-01,  1.7454e+00, -1.3209e+00,  1.0772e+00,\n",
      "          -4.1005e-01, -1.7163e-01, -2.8440e-01, -9.5185e-01,  2.7571e-01],\n",
      "         [-1.9108e-01, -3.9086e-01,  1.4458e+00,  2.5428e-02,  4.9925e-01,\n",
      "           4.1370e-01,  1.0094e+00,  1.9200e-01,  1.9969e+00, -2.7468e-01],\n",
      "         [-3.7836e-01,  1.1542e+00, -1.4626e+00, -1.3466e+00,  3.5076e-01,\n",
      "          -8.9630e-01, -2.7254e-01,  4.0795e-01,  2.1489e+00,  1.0773e+00]],\n",
      "\n",
      "        [[-1.3204e+00,  5.7296e-01,  4.0872e-01,  1.1685e+00, -1.8644e+00,\n",
      "           3.5383e-01, -4.7345e-01,  4.5238e-01,  7.9784e-01, -1.3752e+00],\n",
      "         [-2.4723e-03, -6.5432e-01,  1.2994e+00,  2.8515e-01, -6.4645e-01,\n",
      "          -5.9459e-01,  1.5838e+00, -6.8981e-01, -2.6090e+00,  6.3390e-01],\n",
      "         [ 1.3993e+00, -1.5895e+00, -2.0165e-01, -1.1534e+00,  5.3631e-01,\n",
      "           4.3734e-01, -5.2542e-01, -1.6103e+00, -2.1887e-01, -1.1088e+00]],\n",
      "\n",
      "        [[ 1.9090e-03, -5.3440e-01, -3.6191e-01, -6.1268e-01, -5.9193e-01,\n",
      "          -7.0229e-01,  1.3135e+00, -5.7362e-01, -5.6966e-01, -2.6722e+00],\n",
      "         [ 2.2681e-01,  8.4205e-02, -6.3899e-01,  1.1040e+00, -3.9971e-01,\n",
      "           2.1528e-01,  8.4723e-02, -7.4526e-01, -8.3955e-03, -6.6525e-02],\n",
      "         [-4.0768e-01,  6.3407e-01,  1.4659e+00, -6.4440e-02,  4.9169e-01,\n",
      "          -1.6848e-01, -5.5436e-01, -7.9841e-01,  1.7186e-01,  8.9513e-01]],\n",
      "\n",
      "        [[-1.0495e-01,  1.5164e+00, -3.3694e-01, -3.7183e-01,  1.3115e-01,\n",
      "          -5.7142e-01, -1.7377e-01,  1.4472e-01, -1.6457e+00,  4.1116e-02],\n",
      "         [-1.2806e+00, -5.6779e-01, -3.6660e-01, -1.1165e+00,  7.7708e-02,\n",
      "          -8.8558e-01, -5.3287e-01, -3.9005e-01, -1.2065e+00,  4.7280e-01],\n",
      "         [ 7.4820e-01,  1.1602e+00, -2.5335e-01,  3.1846e-01, -6.1755e-01,\n",
      "           3.1391e-01, -5.7019e-01,  1.3936e+00,  7.9201e-01,  9.0119e-01]]],\n",
      "       dtype=torch.float64), tensor([[3],\n",
      "        [5],\n",
      "        [2],\n",
      "        [4],\n",
      "        [3]], dtype=torch.int32)] \n",
      "6 [tensor([[[-1.6616, -0.4362, -0.6296, -0.6937,  0.3366,  0.7174,  0.5820,\n",
      "           1.2031,  2.1291, -0.3023],\n",
      "         [ 0.4985, -1.0043,  1.3988,  0.3488, -2.2021,  0.2070,  0.9292,\n",
      "          -2.4826, -0.8595, -0.9881],\n",
      "         [ 1.4238,  0.1522, -0.8946,  0.6898,  0.6420, -0.4268, -0.3226,\n",
      "          -1.0279,  0.4537, -0.0803]],\n",
      "\n",
      "        [[ 0.3231, -1.2087,  2.6093,  0.5295, -1.4839,  0.0090,  0.2540,\n",
      "          -0.0144, -0.0572,  2.1276],\n",
      "         [ 0.6816,  0.4148, -1.8670, -0.7738, -0.3247, -0.2418,  1.2455,\n",
      "          -0.0736, -0.7175,  0.1884],\n",
      "         [ 0.6989,  0.1664, -1.3504,  0.4991,  0.8932, -0.8877,  1.0383,\n",
      "          -0.5141, -0.7636, -0.5667]],\n",
      "\n",
      "        [[ 0.2075, -1.1324, -0.3901, -2.6784, -0.6552,  1.6556,  1.0765,\n",
      "          -0.0815,  1.4088,  1.0757],\n",
      "         [-1.1479,  0.3607,  0.0546,  0.7663, -2.0182, -1.5295, -0.1570,\n",
      "          -1.5227, -1.0098, -0.5544],\n",
      "         [-0.3714, -0.9753,  0.9007, -1.1449,  0.8147, -1.6277, -1.0848,\n",
      "           1.0554, -1.4622,  0.0071]],\n",
      "\n",
      "        [[ 0.8802, -0.4782,  0.4724, -1.2683, -0.5889,  1.4097, -0.2903,\n",
      "          -0.3838,  1.2641,  0.6907],\n",
      "         [-0.9695, -1.0476, -2.1754,  0.9287,  0.8287,  1.3823,  0.9458,\n",
      "           2.0500, -1.6545, -0.7345],\n",
      "         [ 1.6669,  0.7129,  0.3521,  0.2093, -2.7757, -1.5469, -0.0143,\n",
      "           0.8303, -0.0948, -1.1195]],\n",
      "\n",
      "        [[-1.1023, -0.8379, -0.1031,  1.0183, -0.0735,  0.0923,  0.5871,\n",
      "           2.6212,  0.6271, -0.2106],\n",
      "         [ 0.2246, -0.1897, -1.8827, -1.4804, -1.5942, -1.6024, -0.9199,\n",
      "           0.0725,  1.6732,  0.8104],\n",
      "         [ 0.8738, -1.0933,  1.5869, -0.2717,  0.9565, -0.2368, -1.5000,\n",
      "           0.2308, -0.5263, -0.0483]]], dtype=torch.float64), tensor([[3],\n",
      "        [2],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5]], dtype=torch.int32)] \n",
      "7 [tensor([[[ 6.5692e-01,  1.5827e-01, -2.5506e+00, -2.7498e-01, -3.5804e-01,\n",
      "           2.6947e-01, -3.7414e-02, -3.6697e-01,  1.3588e-01, -3.0182e-01],\n",
      "         [-1.1481e+00,  4.0083e-01,  9.4261e-01,  1.0945e+00, -3.9219e-02,\n",
      "          -1.9225e+00,  1.6822e+00,  4.9638e-01,  2.2713e-01, -1.4095e+00],\n",
      "         [ 1.8321e+00,  6.7823e-01, -8.8254e-01,  1.7902e+00, -2.6494e-01,\n",
      "           3.2978e-01, -8.8683e-02,  3.6929e-01,  6.3852e-01,  1.2965e+00]],\n",
      "\n",
      "        [[ 5.6813e-01, -1.8251e+00, -6.5169e-02, -4.1962e-02, -1.8315e-01,\n",
      "           6.5254e-01, -1.7679e-01,  1.4152e+00, -2.4848e-01, -8.5534e-01],\n",
      "         [ 1.0736e+00,  5.2759e-01,  4.2943e-01, -1.8858e-01,  1.3029e+00,\n",
      "           2.1565e+00,  5.2678e-01, -1.0109e+00, -1.3542e+00, -7.5939e-01],\n",
      "         [ 1.2182e+00, -2.0402e+00, -1.5109e+00,  5.4246e-01,  1.3959e+00,\n",
      "          -6.0146e-01, -7.4382e-01, -5.0698e-01, -7.5603e-01, -9.6647e-01]],\n",
      "\n",
      "        [[ 2.1587e-02,  9.9096e-01, -5.3360e-02,  2.8061e-01,  1.9424e-01,\n",
      "           4.4628e-01,  5.0748e-01,  2.0203e-01, -2.5760e-01,  1.8560e-01],\n",
      "         [ 7.3957e-02,  1.3097e+00, -4.7241e-02, -1.4783e+00, -4.9962e-01,\n",
      "          -9.3071e-01, -7.6359e-01, -5.8344e-02, -4.7371e-01,  8.3757e-01],\n",
      "         [-9.0101e-01, -2.1035e-01, -1.5996e-01,  3.9335e-01,  1.1764e+00,\n",
      "           1.2078e+00, -3.8023e-01, -5.5291e-01,  2.0036e-01, -3.5962e-01]],\n",
      "\n",
      "        [[ 3.9517e-01,  6.7089e-01, -4.6188e-01,  7.8820e-01, -9.5673e-01,\n",
      "           1.1761e-01,  5.9658e-01,  6.8543e-01,  8.0924e-01,  8.0112e-01],\n",
      "         [ 1.5245e+00, -3.3428e-01,  7.2126e-01, -1.6932e-01,  6.6179e-02,\n",
      "          -6.5709e-01,  1.4023e+00, -3.1669e-01,  8.3220e-01, -1.5419e+00],\n",
      "         [ 9.3005e-01, -1.3252e-01, -8.2606e-01, -2.7602e-01, -1.6976e+00,\n",
      "          -5.2113e-01, -1.6797e+00, -4.2769e-01, -1.8019e+00, -1.1660e+00]],\n",
      "\n",
      "        [[-7.3531e-01,  1.5274e+00,  6.1390e-01, -9.4127e-02, -1.2202e+00,\n",
      "           1.9152e+00,  3.0494e-01, -1.3465e+00,  7.5965e-01, -8.1066e-02],\n",
      "         [-2.5328e-01,  3.7406e-01,  4.9813e-01, -2.3227e-03,  3.2558e-01,\n",
      "          -2.0350e+00, -9.0363e-01,  1.5670e+00, -1.8091e-01,  2.4967e+00],\n",
      "         [-9.6019e-01, -9.4251e-02,  1.1304e+00,  9.5042e-01,  4.8709e-02,\n",
      "           1.4631e-01, -1.0902e+00,  6.6368e-01,  5.4083e-01,  7.0352e-01]]],\n",
      "       dtype=torch.float64), tensor([[3],\n",
      "        [5],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2]], dtype=torch.int32)] \n",
      "8 [tensor([[[-1.8229e+00, -4.2188e-01,  4.0657e-02, -2.4550e-02, -6.8679e-01,\n",
      "          -1.9168e+00,  3.1839e-01, -5.8241e-01, -5.3345e-01, -4.6943e-01],\n",
      "         [ 6.7608e-01, -6.0399e-01,  1.5783e+00,  8.5429e-01, -1.6201e+00,\n",
      "          -9.3450e-01,  2.6995e-01,  6.7186e-01,  1.4181e+00,  7.3858e-01],\n",
      "         [-6.4064e-01,  1.1666e+00,  6.8678e-01, -1.2197e-01,  9.7301e-01,\n",
      "           1.8324e+00, -3.7502e-01,  3.1407e-01, -2.2832e-01,  4.3584e-01]],\n",
      "\n",
      "        [[-5.2214e-01, -3.8637e-01, -6.6671e-02, -1.8718e+00,  1.4981e-01,\n",
      "           1.2127e-01,  9.9175e-01, -1.7929e+00, -5.2725e-01, -8.2993e-01],\n",
      "         [-2.6528e-01, -1.7491e+00,  2.7889e-01,  3.8455e-01, -2.1122e-01,\n",
      "           1.0120e-01, -1.4726e+00,  1.9840e+00, -1.7575e+00, -2.9915e-01],\n",
      "         [-1.0477e+00, -1.3501e+00, -2.4942e-01, -6.5950e-01, -6.8669e-01,\n",
      "           2.1898e-01,  1.8586e-01, -9.3126e-01, -2.2479e-01, -1.9185e+00]],\n",
      "\n",
      "        [[ 5.2599e-01, -1.6682e+00, -2.7602e-01,  1.1611e+00, -2.5889e-01,\n",
      "           9.9123e-02, -1.1059e-01, -6.3031e-02, -1.3718e+00, -4.1905e-01],\n",
      "         [ 4.2992e-01,  7.9173e-01, -4.5854e-01,  4.9148e-02,  1.1203e+00,\n",
      "          -8.4525e-01, -6.3008e-02,  4.7827e-01, -3.1843e-01, -3.2342e-01],\n",
      "         [-1.4402e+00,  8.6052e-01, -5.1915e-01,  5.4713e-01, -9.8412e-01,\n",
      "           3.3205e-01, -1.3128e+00, -2.7503e+00, -4.2986e-01, -1.8068e+00]],\n",
      "\n",
      "        [[-2.5032e-01,  4.1707e-01, -4.8269e-01,  1.5547e-02, -3.2729e-01,\n",
      "          -2.3837e-01, -4.4244e-01,  2.7512e-01,  1.4367e+00, -2.4809e-01],\n",
      "         [-9.7232e-01, -5.6442e-01, -5.5746e-02,  5.0109e-01,  5.4768e-01,\n",
      "           8.1686e-01, -1.2662e-03,  5.1533e-02, -5.0900e-01, -9.0054e-01],\n",
      "         [ 2.1603e+00, -7.9490e-01, -6.5575e-01, -3.8299e-01, -8.9461e-01,\n",
      "          -1.2755e+00,  7.1577e-01, -1.6559e+00,  5.2484e-01, -1.2794e+00]],\n",
      "\n",
      "        [[-1.3723e+00, -1.5296e+00,  2.4836e-01,  7.0112e-01,  9.2906e-01,\n",
      "          -1.4513e+00,  4.4398e-01,  1.2787e+00, -5.8555e-01,  1.8864e-01],\n",
      "         [-8.3483e-01,  1.3961e-01,  5.5458e-01, -6.1143e-01,  2.3065e-01,\n",
      "           2.7577e-01, -2.2570e+00, -4.6077e-02,  1.6909e+00,  7.1686e-01],\n",
      "         [ 1.2791e-01, -8.7069e-01, -1.7591e+00,  7.0042e-01, -3.4449e-01,\n",
      "          -2.7313e-01,  7.1792e-01, -7.6194e-01,  1.3712e+00,  1.8802e-01]]],\n",
      "       dtype=torch.float64), tensor([[3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [3],\n",
      "        [3]], dtype=torch.int32)] \n",
      "9 [tensor([[[ 0.8709, -0.7901, -1.4789, -0.0964,  1.1457, -0.0642,  1.2311,\n",
      "          -0.7383,  0.6167, -0.4559],\n",
      "         [-2.0291,  1.5080, -1.1700,  0.4486,  1.2809,  0.1260,  0.3850,\n",
      "           0.9656, -0.0390,  0.9566],\n",
      "         [ 1.6328,  2.8585,  0.7102,  0.7285, -0.8805,  0.1032,  0.6447,\n",
      "          -0.2221, -0.1618,  0.1660]],\n",
      "\n",
      "        [[ 0.9605, -1.2466,  1.4023, -0.1510, -0.2676,  1.3207,  0.6033,\n",
      "          -1.1172,  1.9433, -0.0515],\n",
      "         [ 1.5221, -1.0091, -0.3065,  0.5690,  0.8471, -0.3572,  0.9809,\n",
      "          -0.0733, -0.6611,  0.4799],\n",
      "         [-0.0428,  0.7364,  1.4159, -1.7175,  0.5814,  0.1964, -0.2267,\n",
      "           0.7696, -0.5972, -0.6164]],\n",
      "\n",
      "        [[ 0.8998, -0.2609,  0.6246,  1.9578,  1.7188, -1.2667,  0.8076,\n",
      "           1.0300, -0.0784,  0.3197],\n",
      "         [ 0.5241,  1.8560, -0.0200,  1.2982, -0.3366, -1.3749, -0.4042,\n",
      "           1.2611, -0.5126,  0.2200],\n",
      "         [-1.7577,  1.0028,  0.5529, -1.4688, -0.1058,  1.5165,  1.5137,\n",
      "          -0.8366,  0.0795,  0.2757]],\n",
      "\n",
      "        [[-0.9608, -1.2207, -0.7676, -1.1971, -0.0207,  0.8582,  1.5307,\n",
      "           0.1603, -0.0731, -1.7888],\n",
      "         [-2.7782, -1.4237, -0.7878,  0.2441, -0.4907, -0.9918, -1.1921,\n",
      "          -1.1391,  2.0167,  0.9573],\n",
      "         [-1.7440, -0.6473, -0.5495,  0.0370,  0.0746, -0.6159, -0.2768,\n",
      "          -1.7208, -0.7289, -1.5608]],\n",
      "\n",
      "        [[-0.3970, -2.6007,  0.3353, -0.9591,  0.7765, -0.6974,  0.2804,\n",
      "           2.0103,  1.0839,  1.9008],\n",
      "         [-0.9839, -0.8165,  1.0935,  0.1768, -0.5347, -1.4411,  0.8348,\n",
      "          -0.9115,  0.6108,  0.0101],\n",
      "         [-1.1866, -0.3055, -0.2879,  0.2228, -0.3578, -2.9971,  0.2326,\n",
      "          -0.1810,  0.2027, -2.2666]]], dtype=torch.float64), tensor([[3],\n",
      "        [5],\n",
      "        [2],\n",
      "        [4],\n",
      "        [4]], dtype=torch.int32)] \n",
      "10 [tensor([[[-0.5963,  1.2567,  0.5359, -0.4420, -0.8003,  0.9363,  0.0055,\n",
      "           1.3395,  0.7272,  0.6201],\n",
      "         [ 0.1669, -0.6037,  0.9674, -1.4896, -2.1189, -1.5211,  1.0139,\n",
      "          -0.4225,  0.8618,  0.0352],\n",
      "         [ 1.1310, -1.6743, -1.2841,  0.5414, -0.5972, -0.8980, -0.2749,\n",
      "          -0.8151, -0.3849,  1.2985]],\n",
      "\n",
      "        [[-0.4018,  2.1061,  1.8805, -0.4380,  1.4920, -0.6180,  0.7227,\n",
      "           1.3750,  0.6798,  1.6252],\n",
      "         [-0.4738,  1.8661,  0.9733, -0.9393, -0.1914,  0.6447, -0.2075,\n",
      "          -0.2475, -0.3157,  1.0103],\n",
      "         [ 1.7660, -1.3461, -0.0565, -1.3891, -0.2085,  0.4665,  0.7021,\n",
      "          -1.0939,  1.0098, -0.8662]],\n",
      "\n",
      "        [[-1.3442,  1.1238, -0.9469, -0.7816, -2.6661, -2.2047,  0.9071,\n",
      "          -0.5736, -0.8904,  0.2574],\n",
      "         [ 0.9740, -0.9567,  0.3392,  0.7354,  0.3423,  0.1701,  1.0860,\n",
      "           0.1218,  1.1665,  0.6451],\n",
      "         [-0.0061, -0.2965,  2.9782, -0.1822, -0.6489,  1.2825, -0.5519,\n",
      "           0.5751,  0.6385,  1.9233]],\n",
      "\n",
      "        [[-0.1806, -0.3235, -0.8803,  0.0859, -0.2671,  0.8481,  0.4340,\n",
      "           2.0029,  1.8363,  0.7378],\n",
      "         [-0.4777,  0.3214, -0.0989,  0.0603, -0.3880, -1.3584,  0.3385,\n",
      "          -1.0516, -0.3866, -1.0971],\n",
      "         [-2.4667, -0.5785, -1.8920, -0.9923,  0.2123, -0.0700,  1.2326,\n",
      "          -0.3605,  0.4809, -0.7242]],\n",
      "\n",
      "        [[-1.5639, -0.1750, -0.3350,  0.8567,  1.1407,  1.1940, -0.4790,\n",
      "           0.6446, -0.6918,  3.9456],\n",
      "         [-0.8726,  1.2506,  0.8967, -0.6860,  0.4657,  1.4339,  0.5104,\n",
      "           2.1967, -0.3002,  0.1761],\n",
      "         [ 0.3291, -0.6200,  1.0180,  1.7202, -0.8191, -0.4687,  1.0281,\n",
      "          -0.0676, -0.6047, -2.4247]]], dtype=torch.float64), tensor([[0],\n",
      "        [4],\n",
      "        [4],\n",
      "        [3],\n",
      "        [2]], dtype=torch.int32)] \n",
      "11 [tensor([[[ 0.8749, -1.1422,  0.2591,  0.2737, -0.7894, -0.0530, -0.5102,\n",
      "          -0.2174,  0.5994,  0.9240],\n",
      "         [-0.1523,  2.0906, -1.3606,  0.1877,  1.0112, -0.8758, -1.0226,\n",
      "           1.0975,  0.2195,  0.0871],\n",
      "         [-0.1503, -0.5556, -0.0877,  0.3565,  2.4068, -0.3916, -1.2838,\n",
      "           0.5377, -0.5098, -0.6009]],\n",
      "\n",
      "        [[-0.3246, -1.0785,  1.9727, -0.5752,  0.5417,  0.9253,  0.1096,\n",
      "          -0.9036, -0.7518,  0.0310],\n",
      "         [-0.5500,  1.3074, -0.6310, -0.2122,  0.7581, -0.2971, -0.8723,\n",
      "           0.0888, -1.1083,  0.8603],\n",
      "         [ 0.4955,  1.4371,  1.3023, -0.5387, -0.6794, -0.8027,  0.4242,\n",
      "           0.7773,  0.2547,  0.4937]],\n",
      "\n",
      "        [[-0.0401,  0.9648, -1.2421,  0.9259, -1.5052,  0.1651, -0.2464,\n",
      "          -0.6448, -0.3069,  0.9209],\n",
      "         [ 0.0100, -0.2253,  0.2312,  0.4386,  0.5928, -0.1939, -1.8784,\n",
      "           0.5140, -0.8138, -0.5087],\n",
      "         [-1.5609, -1.1985, -0.1672,  0.0803,  0.0750, -0.3113,  1.0022,\n",
      "          -0.4182, -0.7101, -1.0872]],\n",
      "\n",
      "        [[ 1.6743, -0.1088,  0.8493, -0.1019, -0.0747, -0.0424, -0.1296,\n",
      "           0.1885,  1.2648, -0.1861],\n",
      "         [-0.1751, -0.8148,  0.0716,  1.2574, -0.0247,  1.1933,  0.3415,\n",
      "          -0.5254,  1.2236, -0.0812],\n",
      "         [ 1.2108,  0.0520, -0.3983,  0.2023,  1.7991, -0.8611, -0.2089,\n",
      "           0.9785, -0.5612, -0.7101]],\n",
      "\n",
      "        [[ 0.0866, -0.2128,  1.2280, -0.7317, -0.6931, -0.3195, -1.5446,\n",
      "          -1.8283,  0.0064,  0.3286],\n",
      "         [ 1.8030, -0.8234,  0.4600,  0.3003,  0.5771,  0.0697,  0.7319,\n",
      "          -0.7804, -0.3448, -0.4368],\n",
      "         [ 0.4080, -0.0665, -1.7367, -1.3661, -0.3806,  0.3014, -0.0599,\n",
      "           0.0865, -1.0006, -0.2317]]], dtype=torch.float64), tensor([[3],\n",
      "        [3],\n",
      "        [5],\n",
      "        [0],\n",
      "        [5]], dtype=torch.int32)] \n",
      "12 [tensor([[[-0.2486,  0.0187, -0.9267,  0.5687,  0.0316,  1.8365, -0.6928,\n",
      "          -0.3094, -1.1646, -1.6991],\n",
      "         [ 1.7072,  1.2584, -0.4794,  0.5146,  0.6566, -0.5943, -0.7954,\n",
      "           0.7190, -1.0893, -0.6320],\n",
      "         [ 0.9881, -0.4523, -1.2181, -0.9970,  0.5939, -0.0158,  0.7638,\n",
      "          -1.0787, -0.0651,  0.2986]],\n",
      "\n",
      "        [[-0.8001,  0.3683, -1.0915, -0.7268,  0.9762, -1.2403, -1.5997,\n",
      "          -0.2668,  0.1181, -0.9132],\n",
      "         [ 0.7976,  0.1993,  0.2155,  0.2699,  0.1950, -0.2085,  1.3340,\n",
      "           2.1257,  0.5479, -0.1881],\n",
      "         [ 0.3928, -0.6214,  0.7390,  0.6800,  0.5157, -0.9172,  1.9327,\n",
      "           1.4087, -1.1149,  0.2947]],\n",
      "\n",
      "        [[ 0.3801, -0.8357,  0.3765,  1.4153,  0.3834,  1.4883, -0.2363,\n",
      "          -0.0975, -1.3774, -0.6395],\n",
      "         [ 0.6548,  2.5587,  0.8459, -0.6849,  0.6154, -0.8756,  2.4440,\n",
      "          -0.3632, -0.5817, -1.5395],\n",
      "         [-0.4304, -1.6430, -1.9374, -0.3044, -0.3952, -1.2936,  0.6544,\n",
      "          -0.4498,  1.0207,  0.2118]],\n",
      "\n",
      "        [[-0.0271,  0.7145, -0.7281,  0.0587, -0.0041, -0.1194,  0.2393,\n",
      "          -0.4217,  1.1278, -0.4591],\n",
      "         [ 1.6479, -1.3090,  0.1279,  1.5867, -0.3817,  1.5907,  0.8100,\n",
      "          -0.1185,  0.6852,  0.8137],\n",
      "         [ 0.1461, -0.7329, -0.2139, -0.7900,  0.5716, -1.4353, -1.4812,\n",
      "          -1.0599,  0.4085,  2.0480]],\n",
      "\n",
      "        [[ 0.4170,  0.8654, -0.6161,  0.1520, -2.2998, -0.1183, -0.1483,\n",
      "           0.5263, -0.8085, -1.6461],\n",
      "         [ 0.9144, -0.5356, -0.4787, -1.6349, -2.1395,  0.5496, -0.8109,\n",
      "           0.1825,  0.3190,  1.5765],\n",
      "         [-0.4488, -0.1243, -0.9289,  0.2481, -0.2082,  0.4841, -0.9794,\n",
      "          -1.5957,  1.0379, -0.2863]]], dtype=torch.float64), tensor([[2],\n",
      "        [0],\n",
      "        [4],\n",
      "        [0],\n",
      "        [1]], dtype=torch.int32)] \n",
      "13 [tensor([[[-1.0331,  0.7678,  0.9204,  1.5904, -0.2694, -0.3173,  1.0601,\n",
      "           0.2834, -0.8552,  1.4086],\n",
      "         [-0.8804,  0.6278,  0.5260, -1.4553, -0.1812,  0.2841, -0.9927,\n",
      "           0.9540, -0.8106, -0.3721],\n",
      "         [-1.3165, -1.1219, -1.9285,  0.6265, -0.5539, -0.2115,  0.1672,\n",
      "           0.2745,  1.2939, -0.6496]],\n",
      "\n",
      "        [[ 0.1385,  0.4068,  1.2215, -0.4296,  0.6535,  0.1224,  0.6332,\n",
      "          -0.7107,  2.1146, -0.2166],\n",
      "         [-0.5371, -0.6121,  0.8866, -0.5338,  0.1897,  1.5594, -0.7018,\n",
      "          -1.7331, -0.3901, -0.3984],\n",
      "         [-0.3982, -0.2631,  0.0683,  1.9257, -1.8430, -0.9068,  0.8909,\n",
      "           1.8274,  1.2345,  0.1637]],\n",
      "\n",
      "        [[ 1.5444,  0.4480,  1.2115, -1.0744, -0.0941, -0.5957,  2.0063,\n",
      "          -1.0655, -1.5938, -1.2358],\n",
      "         [ 1.5356, -0.3569,  0.0466,  0.0457,  0.5572, -0.6076,  0.4535,\n",
      "          -2.0457, -0.5183,  0.7077],\n",
      "         [ 0.7301,  2.5882, -0.0502,  1.3577, -1.0116, -1.5892,  0.2767,\n",
      "           1.8522, -0.5088,  0.8174]],\n",
      "\n",
      "        [[-1.1622, -0.2369,  1.3552,  0.9923, -0.3115, -0.0213, -1.1956,\n",
      "          -0.7571, -0.2906,  1.2353],\n",
      "         [-0.6604, -0.7556,  0.3709,  0.1432,  0.0247, -0.4674,  0.2215,\n",
      "          -0.3746,  0.0362, -1.1245],\n",
      "         [ 0.9500, -1.1444,  1.5617, -0.8144, -0.1433,  0.4360,  0.0893,\n",
      "           1.6168, -0.2356, -0.9721]],\n",
      "\n",
      "        [[-0.2092,  1.2182, -0.5130,  0.4535,  1.9540, -0.3823,  1.7881,\n",
      "           0.1044, -1.7530, -0.9511],\n",
      "         [ 0.6607, -0.5704, -0.7847, -0.8039,  0.0673,  0.6672, -2.7785,\n",
      "          -0.5821, -0.1606,  0.5084],\n",
      "         [-1.6438,  0.7798,  0.2720,  1.0605,  1.9734,  0.6271,  0.6587,\n",
      "           0.6842, -0.1360, -1.7239]]], dtype=torch.float64), tensor([[2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [4]], dtype=torch.int32)] \n",
      "14 [tensor([[[-1.8831e+00, -1.2778e+00,  9.6487e-01, -2.6196e-01,  1.0138e-01,\n",
      "           1.3572e+00, -4.4614e-01,  1.7419e+00, -1.3699e+00,  5.0411e-01],\n",
      "         [ 3.9880e-01,  1.2966e+00,  1.2174e-01,  1.2775e+00, -7.6223e-01,\n",
      "          -4.8299e-01,  4.5207e-01,  4.6039e-01, -2.5747e+00, -4.2994e-01],\n",
      "         [ 2.6675e+00,  6.6050e-01, -5.2349e-01,  2.7695e+00,  1.5951e-01,\n",
      "           9.7562e-02,  4.5296e-01, -3.2900e-01, -1.3429e+00,  5.4895e-01]],\n",
      "\n",
      "        [[ 8.0974e-01,  2.3467e+00,  6.9933e-01,  7.0394e-01,  6.3585e-01,\n",
      "           5.3351e-01,  1.2765e+00,  1.3648e+00, -1.1239e+00,  6.9488e-01],\n",
      "         [ 2.5777e-02, -1.0130e-01, -4.2663e-01, -1.8196e-01,  1.2802e+00,\n",
      "          -1.0764e+00,  4.6832e-01,  8.7760e-01, -2.0474e-02,  1.2260e+00],\n",
      "         [-8.6371e-01, -2.6112e-01,  1.1968e+00,  3.6548e-01, -1.2422e-01,\n",
      "          -1.0030e+00,  1.3561e+00, -4.8139e-01,  9.6848e-01, -1.2521e+00]],\n",
      "\n",
      "        [[ 1.4578e+00,  1.4007e+00, -4.1358e-01,  1.4500e+00,  2.6171e-01,\n",
      "          -1.2629e+00,  1.5589e+00, -7.5511e-01, -3.2299e-01, -1.4283e+00],\n",
      "         [-7.9206e-01,  1.8439e+00, -3.7557e-01, -5.1064e-01,  1.7191e+00,\n",
      "          -5.4719e-02,  1.2931e+00, -1.1654e+00, -5.5435e-01, -8.4164e-01],\n",
      "         [ 1.5410e+00,  9.3669e-01, -4.6910e-01, -4.4797e-01,  6.8429e-03,\n",
      "           1.5544e+00, -1.0921e-01, -1.9937e+00, -5.9208e-01, -1.3850e+00]],\n",
      "\n",
      "        [[-6.7384e-01, -1.6555e+00,  7.6806e-01,  1.2829e+00,  8.9516e-01,\n",
      "           1.8130e-01,  6.1903e-01, -5.9428e-01,  1.5364e+00,  7.5152e-01],\n",
      "         [ 1.8051e+00, -2.6035e-01, -3.9272e-01,  9.6182e-01,  2.1301e-01,\n",
      "          -8.5444e-05,  4.8070e-01, -4.8090e-01,  6.6775e-01,  8.6739e-01],\n",
      "         [-1.5267e+00, -1.6650e+00, -1.8349e+00, -8.0716e-01, -2.3577e+00,\n",
      "           3.0761e-01,  1.1334e+00, -1.8813e-01, -4.4305e-01, -3.5500e-01]],\n",
      "\n",
      "        [[ 1.3284e+00, -2.3715e-01,  1.9856e-03, -6.0227e-01, -7.8676e-01,\n",
      "           2.7747e-02,  6.8617e-01, -6.4503e-01, -7.8201e-01, -6.6247e-01],\n",
      "         [ 7.9261e-01,  3.2618e-01, -1.4357e+00, -3.9920e-01,  6.1515e-02,\n",
      "          -1.9076e+00,  3.4716e-01,  2.6496e-01, -1.1353e+00, -2.3565e-01],\n",
      "         [-1.0185e-01,  7.6394e-03, -2.4557e-01, -9.7330e-01,  4.6963e-01,\n",
      "          -1.2638e+00,  4.6269e-01, -1.1632e+00, -4.1820e-01,  3.2696e-01]]],\n",
      "       dtype=torch.float64), tensor([[2],\n",
      "        [2],\n",
      "        [5],\n",
      "        [1],\n",
      "        [4]], dtype=torch.int32)] \n",
      "15 [tensor([[[ 1.3295,  0.7948,  1.0093, -2.2373, -0.0052, -1.5027, -0.4331,\n",
      "          -1.4540,  0.0510, -0.4577],\n",
      "         [ 0.7236,  0.7766,  0.2276,  0.9606, -0.6943,  1.9622,  2.0998,\n",
      "          -1.0685,  0.3413,  0.2951],\n",
      "         [ 0.5825,  0.4513, -1.0701, -0.6911, -0.8328,  0.7916, -0.2314,\n",
      "          -0.4438, -0.1022,  0.0751]],\n",
      "\n",
      "        [[ 2.1341, -0.5432,  1.0399, -0.6218,  0.8143,  0.7147,  0.8798,\n",
      "          -0.2306,  0.3811, -1.5206],\n",
      "         [-1.7231,  0.4183, -0.8888,  0.0920,  0.0552,  0.2086, -1.8265,\n",
      "          -0.0613,  0.2754, -1.8049],\n",
      "         [ 0.7628,  1.3807, -1.6412, -1.7414, -0.1225, -0.4877,  0.1744,\n",
      "          -1.5600, -1.4199,  0.2130]],\n",
      "\n",
      "        [[ 0.7316,  1.0082, -0.9975, -0.6804,  0.3295,  2.1050, -0.7152,\n",
      "          -0.0835,  0.9718,  0.0849],\n",
      "         [-1.1581,  2.2742, -0.7191, -0.1625, -1.5761, -1.2525, -0.9713,\n",
      "          -1.1614, -0.2613, -0.3311],\n",
      "         [-0.4119,  0.7482,  0.5434, -0.8849, -0.2444, -0.5347, -0.7700,\n",
      "          -0.6212, -0.4499,  0.6313]],\n",
      "\n",
      "        [[ 0.0437,  1.3592, -0.9289,  0.3429,  0.0652, -2.1405, -0.1966,\n",
      "           0.5339, -0.3681, -0.3405],\n",
      "         [-1.3595, -0.6711, -0.7025,  0.4012,  0.5866,  1.8305, -0.1013,\n",
      "          -0.0913,  1.1529,  0.4571],\n",
      "         [-0.4626,  0.3411,  0.5653,  1.8679,  0.3800,  1.0986, -0.4720,\n",
      "           0.9197, -0.6511,  1.1871]],\n",
      "\n",
      "        [[-0.1014,  1.2360,  0.3772, -1.0156,  1.6263,  0.7922,  0.5097,\n",
      "           0.7930,  0.0863,  0.6230],\n",
      "         [-0.4681, -0.1196,  0.2724,  0.3366,  0.1044, -0.2968, -0.3098,\n",
      "           0.1973, -0.1482, -2.0075],\n",
      "         [-0.0593, -0.8660, -0.8910,  1.5666,  0.8606, -0.4713,  0.8810,\n",
      "           1.0548,  0.8678, -0.9633]]], dtype=torch.float64), tensor([[0],\n",
      "        [5],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]], dtype=torch.int32)] \n",
      "16 [tensor([[[-0.1387, -0.1378, -0.4426, -0.4024, -1.9599,  0.7894, -1.8825,\n",
      "           1.7588,  0.5057,  0.6941],\n",
      "         [ 0.9415,  0.9415, -1.5377, -0.7049,  0.0754, -0.8757, -1.6195,\n",
      "          -1.1612, -0.8419, -0.5615],\n",
      "         [ 1.2492, -1.0840,  0.3661, -0.1981,  0.1369,  0.5760,  0.9790,\n",
      "           0.6402, -2.0673,  0.6146]],\n",
      "\n",
      "        [[-0.5147, -1.5793, -0.9492,  0.9377,  0.3823, -1.0301,  0.4916,\n",
      "           0.0219, -0.1144,  0.3462],\n",
      "         [ 0.5540,  1.8163, -1.2126, -0.4285,  0.8663,  0.6830, -0.2864,\n",
      "           0.0063,  1.1334,  0.2201],\n",
      "         [ 0.3197,  0.1771, -0.1498, -1.0396,  1.0246,  2.0046,  0.3115,\n",
      "          -1.0670,  0.2442, -1.8789]],\n",
      "\n",
      "        [[-1.6923,  1.5139, -0.1123, -1.8745, -0.6296,  0.6403, -0.2255,\n",
      "           0.2306, -0.3927, -0.5948],\n",
      "         [ 1.8715, -0.2030, -0.4952,  2.3092,  0.0229, -0.7460,  0.3828,\n",
      "           0.8821,  0.8727,  0.2124],\n",
      "         [-0.1908,  0.6711,  0.1929, -1.0749, -1.3589,  0.5145,  2.2001,\n",
      "          -1.9942, -1.9600,  0.1471]],\n",
      "\n",
      "        [[ 0.7251, -0.8512,  0.4877, -0.5182,  0.6046, -2.6028, -0.2704,\n",
      "           0.0366, -0.3629,  1.7918],\n",
      "         [-1.4171, -0.4809, -0.0153,  1.0743,  0.3310, -0.2712, -0.3287,\n",
      "           0.1721,  0.3579,  0.4853],\n",
      "         [ 1.2273, -0.4926, -0.3727, -1.0056,  0.2418, -1.3713,  1.1192,\n",
      "          -0.9253,  0.8102, -0.4748]],\n",
      "\n",
      "        [[ 0.3836,  0.0731, -1.5656, -1.7993, -0.8100, -1.4915, -1.1910,\n",
      "          -0.7087,  0.0495, -1.0706],\n",
      "         [ 1.8150, -0.0088,  0.6239,  0.4815, -1.0258,  0.4998, -0.5467,\n",
      "           0.8177, -1.2467,  1.3216],\n",
      "         [-0.3753,  0.6075, -1.2044, -0.6951,  0.3196,  1.1391, -0.0528,\n",
      "           0.9199,  1.0517,  1.7705]]], dtype=torch.float64), tensor([[0],\n",
      "        [4],\n",
      "        [3],\n",
      "        [3],\n",
      "        [5]], dtype=torch.int32)] \n",
      "17 [tensor([[[ 2.8305, -0.7733,  0.9616, -0.1314,  2.1867, -0.3367,  1.4247,\n",
      "           2.9995, -2.1161, -0.2387],\n",
      "         [ 2.5997,  0.2189, -0.0668, -0.6205, -1.2236,  1.0894,  0.4670,\n",
      "          -0.7637, -0.1144,  0.6006],\n",
      "         [ 0.3219,  0.0587,  0.0405, -0.0965, -0.3596, -0.1914, -1.4644,\n",
      "           0.4113,  2.4608,  1.6571]],\n",
      "\n",
      "        [[-0.3876, -1.7979,  0.6625,  0.7532,  0.4976, -0.5552, -1.0446,\n",
      "          -0.6214, -0.2353, -0.1708],\n",
      "         [-0.7675,  0.7697,  0.3167,  2.0004,  0.0828, -0.8133, -1.2535,\n",
      "          -0.6247,  1.0097,  0.6335],\n",
      "         [ 0.4382, -0.6753, -0.1603, -0.6491, -0.2831,  1.6529, -0.6801,\n",
      "          -0.4539,  0.5371,  1.6240]],\n",
      "\n",
      "        [[ 1.3289, -0.0429, -0.0947,  0.2062, -0.0250, -1.9846, -0.8438,\n",
      "          -0.2908,  1.7081, -1.9083],\n",
      "         [-0.8481, -0.1104, -0.9568, -0.9212,  0.6865,  0.3790,  1.1562,\n",
      "          -0.7139,  0.8592, -1.9722],\n",
      "         [ 2.2417,  1.1649, -0.1075,  0.1175, -0.4627, -0.6525,  2.4785,\n",
      "          -0.0462, -0.4335, -1.2640]],\n",
      "\n",
      "        [[ 2.1516,  0.2133,  0.8255, -1.2146, -0.4933,  1.0497, -0.0459,\n",
      "           0.8074, -0.0523, -1.2666],\n",
      "         [ 2.3068, -0.3106,  0.2243, -0.7980,  1.0488, -0.8406, -0.9392,\n",
      "          -1.4976, -0.5330, -1.7024],\n",
      "         [-0.0932, -0.4622, -1.1206,  0.8512,  0.0228, -1.4917, -1.8864,\n",
      "           0.7206,  0.0673, -0.5106]],\n",
      "\n",
      "        [[-1.2880,  2.4739, -1.0732,  1.7229,  1.1263,  0.3027, -1.1416,\n",
      "          -1.4414, -0.3253, -1.1007],\n",
      "         [ 0.3917, -2.3326, -0.0595,  0.0890, -0.6478, -0.1907,  0.3671,\n",
      "           0.1524,  0.3876, -0.2213],\n",
      "         [ 1.2380, -0.8271, -0.7212,  0.1526,  1.2627,  1.6915,  2.0799,\n",
      "           1.7343, -1.4956,  0.6886]]], dtype=torch.float64), tensor([[4],\n",
      "        [3],\n",
      "        [2],\n",
      "        [5],\n",
      "        [4]], dtype=torch.int32)] \n",
      "18 [tensor([[[ 0.1759,  0.4597,  1.6673,  1.2819, -0.4483, -0.1649, -2.4297,\n",
      "          -0.6954,  0.0698,  0.9635],\n",
      "         [ 0.3600,  2.0152,  0.8489,  0.4938, -0.0830,  0.0737, -1.1972,\n",
      "           0.0241, -0.6234, -1.1991],\n",
      "         [-1.6346, -0.3559,  1.9251,  1.2836,  0.4658, -0.0981,  0.8273,\n",
      "          -0.0594, -0.0780, -1.8383]],\n",
      "\n",
      "        [[-0.1069, -0.3994,  1.0789,  0.0354, -1.4266, -0.2821, -0.5042,\n",
      "          -2.3301,  1.0004,  1.1280],\n",
      "         [-0.0299, -2.1641, -0.5637, -0.1260,  0.1190,  1.0045, -0.1909,\n",
      "           0.9134, -0.1499,  0.7028],\n",
      "         [ 0.0360,  1.6404, -0.8304, -1.4296,  0.0984, -1.5339,  0.2075,\n",
      "          -0.3917,  0.4204, -1.5259]],\n",
      "\n",
      "        [[ 1.0917,  0.4771,  0.9914,  1.0565,  0.0040, -1.8628,  1.4074,\n",
      "          -0.4935, -0.5071,  0.3847],\n",
      "         [-1.3221, -0.2368,  0.3784,  0.3070, -0.3858, -0.4613, -0.7336,\n",
      "           0.3339,  0.7672,  0.0743],\n",
      "         [ 0.1692, -0.2498, -0.9317,  0.8377, -1.9176,  0.2482,  1.5264,\n",
      "           1.1034, -2.0450, -0.2053]],\n",
      "\n",
      "        [[-1.0490, -0.1430,  0.1528, -0.5119, -0.1319,  1.8096, -0.1682,\n",
      "          -0.1965,  0.9459,  2.2870],\n",
      "         [ 0.1163, -0.5132,  0.4183, -0.9297, -0.3846, -0.7250, -0.5630,\n",
      "           2.4522, -0.9293, -1.6303],\n",
      "         [-0.8886,  0.8732, -0.5757,  0.4799, -0.5185,  0.3991,  0.2299,\n",
      "           0.3490, -0.0886,  0.8398]],\n",
      "\n",
      "        [[ 0.2635, -0.4976,  0.0351, -0.2754,  2.0393,  0.0630,  0.1934,\n",
      "          -0.2812, -0.3247, -0.2497],\n",
      "         [-0.6556, -0.3518,  0.0837,  1.5807, -0.6449, -0.2812, -0.3074,\n",
      "           1.0879, -0.3511, -1.5218],\n",
      "         [ 0.0873, -2.4815,  0.7322, -0.8480,  0.3619,  0.6864,  0.2371,\n",
      "          -0.6637,  0.1836,  1.7176]]], dtype=torch.float64), tensor([[3],\n",
      "        [4],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2]], dtype=torch.int32)] \n",
      "19 [tensor([[[ 2.3362e-01,  6.1597e-01,  9.8933e-04,  3.7298e-01, -5.6701e-01,\n",
      "          -1.7045e+00, -5.4830e-01,  1.1333e+00, -7.1757e-01,  5.5733e-01],\n",
      "         [-1.2676e+00,  1.6952e+00,  2.6994e-01, -9.2099e-01, -1.0910e+00,\n",
      "          -1.3458e+00,  5.8945e-02,  5.7516e-02, -3.8298e-01,  3.0620e-01],\n",
      "         [ 6.7234e-01,  1.6726e+00,  2.8030e-02,  1.0764e+00,  3.4095e-03,\n",
      "           1.7870e-01, -4.6543e-01, -1.1706e+00, -1.8748e-01, -9.7308e-01]],\n",
      "\n",
      "        [[-8.4601e-01, -1.2267e-02,  2.6876e-01,  5.4652e-01,  1.4452e+00,\n",
      "           1.4397e+00, -1.1496e+00, -6.7270e-01, -2.0152e+00, -3.5457e-01],\n",
      "         [-4.2294e-01, -7.0251e-02,  1.2993e+00,  9.5108e-01,  1.4118e+00,\n",
      "           7.0071e-01,  6.3474e-01, -5.8975e-01, -2.4949e+00, -3.8309e-01],\n",
      "         [-8.8142e-01, -5.6056e-01,  8.8714e-01, -8.2614e-01,  2.3124e+00,\n",
      "           5.8005e-01, -2.3541e+00, -3.6049e-01, -1.5856e+00, -5.8257e-01]],\n",
      "\n",
      "        [[-6.6500e-01, -1.8652e+00, -2.7342e-01,  8.7448e-01, -7.6779e-01,\n",
      "          -1.3178e+00,  1.0958e+00, -9.0556e-01,  4.8190e-03,  1.1275e+00],\n",
      "         [-1.1703e+00, -2.4215e-01, -1.0727e+00, -1.5388e-02, -3.1739e-01,\n",
      "          -1.2681e+00, -1.0426e+00, -1.1718e+00, -1.0919e-01,  1.4476e+00],\n",
      "         [ 1.3115e-01,  8.7373e-01, -6.5596e-01, -8.0818e-01, -8.6850e-01,\n",
      "           2.0468e+00,  4.5248e-01, -1.1618e+00,  4.4834e-01, -4.9434e-01]],\n",
      "\n",
      "        [[ 1.5333e-02,  7.9503e-01, -2.0908e+00, -9.3809e-01,  3.4906e-01,\n",
      "           6.6645e-01,  1.2842e-01, -1.0455e-01,  2.6798e-01, -1.7941e-01],\n",
      "         [ 1.1078e+00,  1.5865e-01,  5.3361e-02,  8.8220e-01,  2.0352e+00,\n",
      "          -1.7988e+00,  1.1013e+00, -1.5224e+00,  8.4751e-01, -4.6754e-01],\n",
      "         [-7.4587e-01, -7.3626e-01, -1.3579e-01, -7.7555e-01, -9.8268e-01,\n",
      "          -8.2316e-01, -3.0877e-01,  2.1580e-01,  1.1113e+00,  1.1056e+00]],\n",
      "\n",
      "        [[-2.8321e-01, -1.9104e-02,  1.7689e+00, -7.6713e-02,  5.0915e-02,\n",
      "          -1.7225e+00,  2.3124e-01, -1.0766e+00,  1.3340e+00, -8.5688e-01],\n",
      "         [-7.6256e-01,  6.5435e-01,  2.0074e-01, -2.4792e-01, -5.9594e-01,\n",
      "           1.5894e+00,  8.8458e-01, -1.5882e-02,  8.3565e-01,  4.8899e-01],\n",
      "         [ 6.1850e-01, -7.6660e-01,  8.0023e-01,  1.4583e-01, -3.8996e-02,\n",
      "           7.3777e-02, -1.5397e+00, -8.6300e-01, -1.5117e+00, -7.0100e-01]]],\n",
      "       dtype=torch.float64), tensor([[0],\n",
      "        [1],\n",
      "        [4],\n",
      "        [3],\n",
      "        [2]], dtype=torch.int32)] \n"
     ]
    }
   ],
   "source": [
    "for  i, train_sample in enumerate(train_loader):\n",
    "     print(\"{} {} \".format(i, train_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 0 个Batch \n",
      "[tensor([[[ 0.5906,  2.1254, -1.4106, -0.0708, -1.1566,  0.3031,  0.4593,\n",
      "           0.6527,  0.4387, -0.1382],\n",
      "         [ 1.0361,  0.8170, -2.2161, -1.2387, -1.0338, -1.1582,  1.0863,\n",
      "          -1.2731,  0.2998,  1.0527],\n",
      "         [ 0.9313,  1.5582,  2.1073, -0.7450, -0.0034,  1.5202, -1.3243,\n",
      "          -0.9366,  2.6180, -0.6339]],\n",
      "\n",
      "        [[ 0.5543,  0.5932,  0.1466,  0.2104, -0.2425,  0.0335, -0.2221,\n",
      "           0.9109,  0.3075, -0.5472],\n",
      "         [ 2.1602, -2.2460,  0.1286,  0.3825,  0.0081,  1.1463,  0.5968,\n",
      "           3.0428,  0.0080, -2.1197],\n",
      "         [-0.0711, -2.6423,  1.9394, -0.4242,  0.0202, -2.4865,  1.3386,\n",
      "           1.6613,  1.0677,  1.8485]],\n",
      "\n",
      "        [[-0.8536, -1.0123, -0.1331, -0.4215, -0.3352, -0.3252,  0.4758,\n",
      "           0.3469,  0.3074, -0.3635],\n",
      "         [ 0.5422,  0.9570, -0.3695, -0.3208,  1.7008, -1.5595,  0.3833,\n",
      "          -0.9529,  0.9771, -1.1279],\n",
      "         [ 1.3337, -1.8153, -1.0798,  0.7307, -0.9975, -1.1125,  1.3222,\n",
      "          -0.7713, -0.8510,  0.7217]],\n",
      "\n",
      "        [[ 0.4440, -1.7295,  0.0793,  1.0823,  1.5424, -0.3692, -0.1173,\n",
      "           1.0512,  0.0453, -0.0541],\n",
      "         [ 0.9509, -0.4926,  0.4038, -0.4120, -1.1851, -0.6540,  0.9156,\n",
      "           0.6040, -0.2844,  1.0970],\n",
      "         [-0.5381, -1.8375, -0.6264, -1.0921,  0.7082, -0.5643, -0.3928,\n",
      "          -2.0412,  1.4737,  0.3660]],\n",
      "\n",
      "        [[-0.9275,  1.0108, -0.9923,  0.7328, -0.9495,  1.0516,  0.1982,\n",
      "          -0.1757,  0.9012, -1.6065],\n",
      "         [ 1.1149, -0.0299, -1.3812,  0.8027,  0.2500,  0.5463, -0.6949,\n",
      "           0.6455, -0.5047, -1.8994],\n",
      "         [-1.6678, -1.8103, -0.3139,  0.7271, -0.4832, -2.0842, -0.6923,\n",
      "           0.6334,  0.3888,  0.8223]]], dtype=torch.float64), tensor([[4],\n",
      "        [4],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3]], dtype=torch.int32)]\n",
      "第 1 个Batch \n",
      "[tensor([[[-0.0949,  0.7080, -0.5131,  0.4428, -1.0632, -1.2070, -1.4654,\n",
      "          -1.4019,  0.3885,  0.0444],\n",
      "         [-0.2163,  1.5797, -2.3284, -0.2002,  1.0102,  0.8071, -0.1719,\n",
      "          -1.5339, -2.7852,  0.0300],\n",
      "         [-1.0980, -0.6542,  0.2559,  1.4871,  1.1421,  0.1982, -0.5651,\n",
      "           1.0988, -1.3647, -0.4150]],\n",
      "\n",
      "        [[-0.4661, -0.9245,  1.0228, -2.0793,  1.2367, -0.8241, -0.1151,\n",
      "          -1.2304,  1.4202,  1.2492],\n",
      "         [ 0.4103, -0.1162, -0.1575,  1.4049, -1.0699,  0.4610,  0.7069,\n",
      "          -0.2875, -1.2860, -0.0065],\n",
      "         [-1.6151, -0.5694,  0.9032, -2.4375,  0.7907,  0.2492,  0.7452,\n",
      "          -0.3478, -1.9159, -0.8729]],\n",
      "\n",
      "        [[ 1.3050,  0.6495, -0.4474,  0.8267,  0.3562, -0.8689, -1.5568,\n",
      "          -0.1751,  0.1181,  0.5334],\n",
      "         [-2.4406,  0.7252,  1.7886, -1.3036, -0.0106, -1.5277,  0.4094,\n",
      "           1.7230,  1.1520, -2.6296],\n",
      "         [-0.1682, -2.0730,  0.9472, -1.5080, -1.2599, -0.9248,  0.3760,\n",
      "          -1.3401, -0.3404, -0.8197]],\n",
      "\n",
      "        [[-2.9619,  0.2467,  0.2410,  0.6730,  0.0587,  0.5787,  0.0552,\n",
      "          -1.0068,  0.7005, -1.5077],\n",
      "         [-2.1030,  1.0850,  1.1668,  1.0056, -0.7988,  0.2729,  1.9007,\n",
      "          -0.8814, -0.9082,  0.8118],\n",
      "         [ 0.1106, -1.4344,  0.0820, -0.4009, -1.4669,  0.3131,  0.9349,\n",
      "          -0.7973, -1.3628, -0.7520]],\n",
      "\n",
      "        [[ 0.8104, -1.0592,  1.7683,  1.0795,  1.1360, -0.5845,  0.9309,\n",
      "           0.7926, -1.0430,  0.7946],\n",
      "         [ 0.3294, -0.0733,  1.3231, -1.2054, -0.7307,  0.0816,  2.5534,\n",
      "          -0.4607, -2.1539,  0.8422],\n",
      "         [-1.8459,  1.6656, -2.2630,  0.2276,  0.9046,  0.7245, -0.9726,\n",
      "           0.0862, -1.8375, -0.5234]]], dtype=torch.float64), tensor([[1],\n",
      "        [5],\n",
      "        [3],\n",
      "        [4],\n",
      "        [0]], dtype=torch.int32)]\n",
      "第 2 个Batch \n",
      "[tensor([[[ 1.3920e+00,  4.6078e-01, -3.7886e-01, -9.2843e-01, -4.4077e-01,\n",
      "           4.9887e-01,  5.3318e-01, -2.1577e-01,  2.4723e+00,  1.3886e+00],\n",
      "         [-9.2654e-01,  5.0082e-01, -7.2481e-01, -2.0918e+00, -9.1295e-01,\n",
      "          -1.5673e-01, -1.0445e+00, -6.4367e-01,  5.8199e-01, -1.9195e+00],\n",
      "         [-1.0051e+00, -5.8944e-01,  3.3119e-01,  4.3328e-01, -2.0050e-02,\n",
      "           1.8534e+00, -1.0206e+00, -8.2508e-01, -3.4331e-01,  9.5665e-01]],\n",
      "\n",
      "        [[ 1.0101e+00, -4.2809e-02, -4.5551e-01, -1.9430e+00, -1.2067e+00,\n",
      "          -6.3950e-01,  2.5787e-01, -1.3563e+00,  5.8462e-01, -4.4776e-01],\n",
      "         [-1.0310e+00,  1.6253e-01,  4.0450e-01, -4.0122e-01,  1.8345e+00,\n",
      "           1.8974e-01,  7.5762e-01,  2.0223e-01,  5.6129e-01,  5.8581e-02],\n",
      "         [ 2.1483e+00, -1.2603e+00, -6.3599e-01,  1.6770e-01,  1.7713e+00,\n",
      "          -1.0820e-01,  5.5307e-01, -9.9773e-01, -1.8843e+00,  6.4260e-01]],\n",
      "\n",
      "        [[-8.1549e-03, -2.9538e+00,  6.5840e-01, -1.2724e+00,  8.8170e-03,\n",
      "          -1.1571e-01, -1.0188e+00, -9.7413e-01,  1.8890e+00,  1.1177e+00],\n",
      "         [ 5.4900e-01,  1.0619e+00,  1.9073e+00, -8.7582e-01, -1.8017e-01,\n",
      "          -5.3752e-01, -1.2437e-01,  6.5472e-01,  1.1142e+00,  6.0078e-01],\n",
      "         [ 1.4496e-02, -1.1515e+00,  1.4940e-02,  7.8904e-01, -2.9214e-02,\n",
      "           1.0388e-01, -9.5165e-01, -4.1124e-01,  7.6528e-01,  1.0876e+00]],\n",
      "\n",
      "        [[-6.4688e-01, -1.1467e+00, -9.2257e-01,  8.1176e-02, -2.4105e-01,\n",
      "           6.8864e-01, -5.8827e-01, -1.2741e+00, -1.8039e+00,  9.6308e-01],\n",
      "         [ 8.8955e-01,  7.3893e-01, -4.1587e-01,  1.4273e-01,  7.8002e-01,\n",
      "          -3.5832e-01, -9.1465e-01,  2.0325e+00, -1.7860e+00,  3.7876e-01],\n",
      "         [ 1.1883e+00, -5.8658e-01,  3.2299e-01,  8.1036e-01,  8.0202e-01,\n",
      "          -1.7051e-01,  2.3824e+00, -3.7971e-01, -9.8327e-02,  2.4168e+00]],\n",
      "\n",
      "        [[ 6.1731e-01,  1.0923e+00,  4.7874e-01,  3.3491e-01,  3.1385e-02,\n",
      "           3.7517e-01, -5.8057e-01,  2.7951e-01, -3.8482e+00, -1.1966e+00],\n",
      "         [-2.1063e-03, -1.1740e+00, -9.3362e-01, -4.0880e-01, -8.4994e-01,\n",
      "          -4.7075e-01, -9.1843e-01, -1.0171e+00,  2.0688e-02,  3.8766e-01],\n",
      "         [-1.0144e+00,  2.2429e-01, -1.4325e-01,  3.6225e-01, -1.8824e+00,\n",
      "           1.1312e+00,  1.4658e+00,  9.1357e-01, -1.1968e-01, -5.2362e-01]]],\n",
      "       dtype=torch.float64), tensor([[3],\n",
      "        [2],\n",
      "        [0],\n",
      "        [4],\n",
      "        [1]], dtype=torch.int32)]\n",
      "第 3 个Batch \n",
      "[tensor([[[ 0.6218, -0.1379,  0.6448,  1.1409, -0.2219,  0.2550, -2.1344,\n",
      "          -1.8216, -0.8037,  0.5489],\n",
      "         [ 1.0215, -0.5328,  0.9757, -0.6689,  0.1132,  0.1331,  0.1265,\n",
      "           0.0890,  0.0097,  1.0574],\n",
      "         [ 0.4329,  0.1180, -0.5775, -2.8882,  0.7746, -1.3284, -1.6978,\n",
      "          -1.2284, -0.8530,  1.7133]],\n",
      "\n",
      "        [[-1.6209, -0.4424, -1.0045, -0.8201,  2.3449, -0.8167, -0.3538,\n",
      "          -0.0826, -1.1026,  0.4596],\n",
      "         [ 0.2861,  1.5082, -1.2012,  2.9257,  0.0195,  0.6442, -0.1041,\n",
      "          -0.1769, -0.7671, -0.0668],\n",
      "         [-0.3801,  0.0912, -0.8603,  1.2547,  1.9479, -0.8477, -0.6186,\n",
      "           1.0175,  0.8038, -2.2488]],\n",
      "\n",
      "        [[ 0.8293, -0.4936,  0.2203, -1.0850,  0.4440, -1.0664,  1.6776,\n",
      "          -0.7175,  0.0709, -1.3955],\n",
      "         [-0.5435, -0.5828,  0.4608,  0.5132, -0.9156,  0.2433, -0.6948,\n",
      "          -0.2402, -0.6465,  0.3714],\n",
      "         [ 1.7818,  0.8697,  0.0608, -0.0052, -1.9309,  0.4730, -0.9200,\n",
      "          -0.8222,  1.1786, -1.1762]],\n",
      "\n",
      "        [[ 1.2072,  0.2567, -1.2889, -1.5255, -1.3400,  0.5121,  0.6608,\n",
      "          -0.2148, -0.2831,  1.4310],\n",
      "         [-0.7861,  0.3904, -0.4646, -0.1533,  0.6653, -0.3047, -0.0885,\n",
      "          -0.5744,  0.7044,  0.2542],\n",
      "         [-1.1362, -0.6653,  0.9210, -0.8413, -2.2070, -0.1942, -0.1740,\n",
      "           1.2312,  0.8335,  0.2429]],\n",
      "\n",
      "        [[ 0.0543, -1.1312, -2.2913,  0.1490,  0.6792, -0.4907, -0.7317,\n",
      "           0.8063, -1.1178, -0.3797],\n",
      "         [-1.3184, -0.4599, -0.0394,  1.0986,  0.4313,  0.1638, -0.8602,\n",
      "          -1.2861, -1.2918, -0.8032],\n",
      "         [ 0.8137,  0.5846, -1.2779,  1.6127,  0.2861,  0.4747,  0.5463,\n",
      "          -0.2385,  2.9946,  0.3179]]], dtype=torch.float64), tensor([[5],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]], dtype=torch.int32)]\n",
      "第 4 个Batch \n",
      "[tensor([[[ 1.2476,  0.0664,  0.8243,  0.7315,  0.8890, -0.3770,  1.1006,\n",
      "           0.2162, -0.9773,  0.7722],\n",
      "         [-2.5534, -0.3023, -0.5040, -0.5954, -0.2909,  1.0048, -1.1719,\n",
      "           1.2084, -0.5077, -0.4362],\n",
      "         [ 0.2572,  0.9917,  1.1758,  0.7229, -0.4803, -0.3817,  0.2294,\n",
      "          -1.1181, -0.0305,  0.4972]],\n",
      "\n",
      "        [[ 1.2983, -0.4175,  1.0302, -1.0713, -0.4236, -0.5372,  0.7951,\n",
      "          -1.2911,  1.4959, -0.6367],\n",
      "         [ 0.8821, -0.3426, -0.1836, -0.9706, -1.0084,  0.6380,  1.2972,\n",
      "           0.5705, -1.0941,  0.9452],\n",
      "         [-0.8010,  0.6604,  2.2809, -0.0318, -0.1239,  0.9109, -2.3298,\n",
      "           0.6747, -0.1639,  0.1964]],\n",
      "\n",
      "        [[-0.2348,  0.9549,  0.0607, -0.5008,  0.5363, -0.0817, -1.4568,\n",
      "          -0.3966,  0.5445,  0.6195],\n",
      "         [ 0.9860,  1.5625, -0.6870,  0.1691, -0.4497,  0.7267, -1.3507,\n",
      "          -0.5543,  0.3439,  0.5305],\n",
      "         [ 0.2197,  0.8385,  0.3287, -1.4835, -2.6550,  1.9982,  1.0703,\n",
      "          -0.7490, -0.6349, -0.8954]],\n",
      "\n",
      "        [[ 1.2559, -0.9134, -0.5697,  0.9118, -0.4926, -2.1872,  0.4535,\n",
      "           0.0121,  0.9907, -0.5246],\n",
      "         [-0.5047, -1.9358, -0.3455, -0.3975,  0.6847, -0.2936, -1.2656,\n",
      "          -0.1055, -0.2062, -1.3848],\n",
      "         [ 0.7959, -0.0668,  1.2892,  0.2322, -0.2942,  0.2511, -0.0517,\n",
      "          -0.2095, -0.7166,  0.0252]],\n",
      "\n",
      "        [[ 0.2681,  0.7501,  0.2096, -2.0080,  0.1667, -0.3904, -0.4364,\n",
      "          -0.8531, -1.0062,  0.2736],\n",
      "         [-0.7366,  0.2966, -0.5598,  1.2793,  0.3011, -1.3595, -0.5907,\n",
      "           0.0883,  0.7170,  1.8682],\n",
      "         [-0.7004,  1.8745,  0.7760,  0.2063,  1.1512, -0.1796,  0.2776,\n",
      "           0.1364, -0.3464, -0.2956]]], dtype=torch.float64), tensor([[2],\n",
      "        [0],\n",
      "        [5],\n",
      "        [0],\n",
      "        [3]], dtype=torch.int32)]\n",
      "第 5 个Batch \n",
      "[tensor([[[ 2.1954e+00,  2.0413e+00, -1.0302e+00,  5.9008e-01, -6.2682e-01,\n",
      "           1.5547e+00, -2.6049e+00,  1.3278e+00,  1.5147e+00,  1.5768e+00],\n",
      "         [ 1.0501e+00,  1.4774e+00,  4.4021e-01, -3.1458e-01, -1.0427e+00,\n",
      "           3.3037e-01, -5.9728e-01, -1.0346e+00, -1.2288e-03, -9.7175e-02],\n",
      "         [ 7.2961e-01,  1.8569e-01, -7.0533e-01, -2.6218e-03, -1.9602e-02,\n",
      "          -7.4849e-01,  4.0274e-01, -9.2556e-01, -1.1866e+00, -1.9086e+00]],\n",
      "\n",
      "        [[ 5.5677e-01,  4.0842e-01,  1.7454e+00, -1.3209e+00,  1.0772e+00,\n",
      "          -4.1005e-01, -1.7163e-01, -2.8440e-01, -9.5185e-01,  2.7571e-01],\n",
      "         [-1.9108e-01, -3.9086e-01,  1.4458e+00,  2.5428e-02,  4.9925e-01,\n",
      "           4.1370e-01,  1.0094e+00,  1.9200e-01,  1.9969e+00, -2.7468e-01],\n",
      "         [-3.7836e-01,  1.1542e+00, -1.4626e+00, -1.3466e+00,  3.5076e-01,\n",
      "          -8.9630e-01, -2.7254e-01,  4.0795e-01,  2.1489e+00,  1.0773e+00]],\n",
      "\n",
      "        [[-1.3204e+00,  5.7296e-01,  4.0872e-01,  1.1685e+00, -1.8644e+00,\n",
      "           3.5383e-01, -4.7345e-01,  4.5238e-01,  7.9784e-01, -1.3752e+00],\n",
      "         [-2.4723e-03, -6.5432e-01,  1.2994e+00,  2.8515e-01, -6.4645e-01,\n",
      "          -5.9459e-01,  1.5838e+00, -6.8981e-01, -2.6090e+00,  6.3390e-01],\n",
      "         [ 1.3993e+00, -1.5895e+00, -2.0165e-01, -1.1534e+00,  5.3631e-01,\n",
      "           4.3734e-01, -5.2542e-01, -1.6103e+00, -2.1887e-01, -1.1088e+00]],\n",
      "\n",
      "        [[ 1.9090e-03, -5.3440e-01, -3.6191e-01, -6.1268e-01, -5.9193e-01,\n",
      "          -7.0229e-01,  1.3135e+00, -5.7362e-01, -5.6966e-01, -2.6722e+00],\n",
      "         [ 2.2681e-01,  8.4205e-02, -6.3899e-01,  1.1040e+00, -3.9971e-01,\n",
      "           2.1528e-01,  8.4723e-02, -7.4526e-01, -8.3955e-03, -6.6525e-02],\n",
      "         [-4.0768e-01,  6.3407e-01,  1.4659e+00, -6.4440e-02,  4.9169e-01,\n",
      "          -1.6848e-01, -5.5436e-01, -7.9841e-01,  1.7186e-01,  8.9513e-01]],\n",
      "\n",
      "        [[-1.0495e-01,  1.5164e+00, -3.3694e-01, -3.7183e-01,  1.3115e-01,\n",
      "          -5.7142e-01, -1.7377e-01,  1.4472e-01, -1.6457e+00,  4.1116e-02],\n",
      "         [-1.2806e+00, -5.6779e-01, -3.6660e-01, -1.1165e+00,  7.7708e-02,\n",
      "          -8.8558e-01, -5.3287e-01, -3.9005e-01, -1.2065e+00,  4.7280e-01],\n",
      "         [ 7.4820e-01,  1.1602e+00, -2.5335e-01,  3.1846e-01, -6.1755e-01,\n",
      "           3.1391e-01, -5.7019e-01,  1.3936e+00,  7.9201e-01,  9.0119e-01]]],\n",
      "       dtype=torch.float64), tensor([[3],\n",
      "        [5],\n",
      "        [2],\n",
      "        [4],\n",
      "        [3]], dtype=torch.int32)]\n",
      "第 6 个Batch \n",
      "[tensor([[[-1.6616, -0.4362, -0.6296, -0.6937,  0.3366,  0.7174,  0.5820,\n",
      "           1.2031,  2.1291, -0.3023],\n",
      "         [ 0.4985, -1.0043,  1.3988,  0.3488, -2.2021,  0.2070,  0.9292,\n",
      "          -2.4826, -0.8595, -0.9881],\n",
      "         [ 1.4238,  0.1522, -0.8946,  0.6898,  0.6420, -0.4268, -0.3226,\n",
      "          -1.0279,  0.4537, -0.0803]],\n",
      "\n",
      "        [[ 0.3231, -1.2087,  2.6093,  0.5295, -1.4839,  0.0090,  0.2540,\n",
      "          -0.0144, -0.0572,  2.1276],\n",
      "         [ 0.6816,  0.4148, -1.8670, -0.7738, -0.3247, -0.2418,  1.2455,\n",
      "          -0.0736, -0.7175,  0.1884],\n",
      "         [ 0.6989,  0.1664, -1.3504,  0.4991,  0.8932, -0.8877,  1.0383,\n",
      "          -0.5141, -0.7636, -0.5667]],\n",
      "\n",
      "        [[ 0.2075, -1.1324, -0.3901, -2.6784, -0.6552,  1.6556,  1.0765,\n",
      "          -0.0815,  1.4088,  1.0757],\n",
      "         [-1.1479,  0.3607,  0.0546,  0.7663, -2.0182, -1.5295, -0.1570,\n",
      "          -1.5227, -1.0098, -0.5544],\n",
      "         [-0.3714, -0.9753,  0.9007, -1.1449,  0.8147, -1.6277, -1.0848,\n",
      "           1.0554, -1.4622,  0.0071]],\n",
      "\n",
      "        [[ 0.8802, -0.4782,  0.4724, -1.2683, -0.5889,  1.4097, -0.2903,\n",
      "          -0.3838,  1.2641,  0.6907],\n",
      "         [-0.9695, -1.0476, -2.1754,  0.9287,  0.8287,  1.3823,  0.9458,\n",
      "           2.0500, -1.6545, -0.7345],\n",
      "         [ 1.6669,  0.7129,  0.3521,  0.2093, -2.7757, -1.5469, -0.0143,\n",
      "           0.8303, -0.0948, -1.1195]],\n",
      "\n",
      "        [[-1.1023, -0.8379, -0.1031,  1.0183, -0.0735,  0.0923,  0.5871,\n",
      "           2.6212,  0.6271, -0.2106],\n",
      "         [ 0.2246, -0.1897, -1.8827, -1.4804, -1.5942, -1.6024, -0.9199,\n",
      "           0.0725,  1.6732,  0.8104],\n",
      "         [ 0.8738, -1.0933,  1.5869, -0.2717,  0.9565, -0.2368, -1.5000,\n",
      "           0.2308, -0.5263, -0.0483]]], dtype=torch.float64), tensor([[3],\n",
      "        [2],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5]], dtype=torch.int32)]\n",
      "第 7 个Batch \n",
      "[tensor([[[ 6.5692e-01,  1.5827e-01, -2.5506e+00, -2.7498e-01, -3.5804e-01,\n",
      "           2.6947e-01, -3.7414e-02, -3.6697e-01,  1.3588e-01, -3.0182e-01],\n",
      "         [-1.1481e+00,  4.0083e-01,  9.4261e-01,  1.0945e+00, -3.9219e-02,\n",
      "          -1.9225e+00,  1.6822e+00,  4.9638e-01,  2.2713e-01, -1.4095e+00],\n",
      "         [ 1.8321e+00,  6.7823e-01, -8.8254e-01,  1.7902e+00, -2.6494e-01,\n",
      "           3.2978e-01, -8.8683e-02,  3.6929e-01,  6.3852e-01,  1.2965e+00]],\n",
      "\n",
      "        [[ 5.6813e-01, -1.8251e+00, -6.5169e-02, -4.1962e-02, -1.8315e-01,\n",
      "           6.5254e-01, -1.7679e-01,  1.4152e+00, -2.4848e-01, -8.5534e-01],\n",
      "         [ 1.0736e+00,  5.2759e-01,  4.2943e-01, -1.8858e-01,  1.3029e+00,\n",
      "           2.1565e+00,  5.2678e-01, -1.0109e+00, -1.3542e+00, -7.5939e-01],\n",
      "         [ 1.2182e+00, -2.0402e+00, -1.5109e+00,  5.4246e-01,  1.3959e+00,\n",
      "          -6.0146e-01, -7.4382e-01, -5.0698e-01, -7.5603e-01, -9.6647e-01]],\n",
      "\n",
      "        [[ 2.1587e-02,  9.9096e-01, -5.3360e-02,  2.8061e-01,  1.9424e-01,\n",
      "           4.4628e-01,  5.0748e-01,  2.0203e-01, -2.5760e-01,  1.8560e-01],\n",
      "         [ 7.3957e-02,  1.3097e+00, -4.7241e-02, -1.4783e+00, -4.9962e-01,\n",
      "          -9.3071e-01, -7.6359e-01, -5.8344e-02, -4.7371e-01,  8.3757e-01],\n",
      "         [-9.0101e-01, -2.1035e-01, -1.5996e-01,  3.9335e-01,  1.1764e+00,\n",
      "           1.2078e+00, -3.8023e-01, -5.5291e-01,  2.0036e-01, -3.5962e-01]],\n",
      "\n",
      "        [[ 3.9517e-01,  6.7089e-01, -4.6188e-01,  7.8820e-01, -9.5673e-01,\n",
      "           1.1761e-01,  5.9658e-01,  6.8543e-01,  8.0924e-01,  8.0112e-01],\n",
      "         [ 1.5245e+00, -3.3428e-01,  7.2126e-01, -1.6932e-01,  6.6179e-02,\n",
      "          -6.5709e-01,  1.4023e+00, -3.1669e-01,  8.3220e-01, -1.5419e+00],\n",
      "         [ 9.3005e-01, -1.3252e-01, -8.2606e-01, -2.7602e-01, -1.6976e+00,\n",
      "          -5.2113e-01, -1.6797e+00, -4.2769e-01, -1.8019e+00, -1.1660e+00]],\n",
      "\n",
      "        [[-7.3531e-01,  1.5274e+00,  6.1390e-01, -9.4127e-02, -1.2202e+00,\n",
      "           1.9152e+00,  3.0494e-01, -1.3465e+00,  7.5965e-01, -8.1066e-02],\n",
      "         [-2.5328e-01,  3.7406e-01,  4.9813e-01, -2.3227e-03,  3.2558e-01,\n",
      "          -2.0350e+00, -9.0363e-01,  1.5670e+00, -1.8091e-01,  2.4967e+00],\n",
      "         [-9.6019e-01, -9.4251e-02,  1.1304e+00,  9.5042e-01,  4.8709e-02,\n",
      "           1.4631e-01, -1.0902e+00,  6.6368e-01,  5.4083e-01,  7.0352e-01]]],\n",
      "       dtype=torch.float64), tensor([[3],\n",
      "        [5],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2]], dtype=torch.int32)]\n",
      "第 8 个Batch \n",
      "[tensor([[[-1.8229e+00, -4.2188e-01,  4.0657e-02, -2.4550e-02, -6.8679e-01,\n",
      "          -1.9168e+00,  3.1839e-01, -5.8241e-01, -5.3345e-01, -4.6943e-01],\n",
      "         [ 6.7608e-01, -6.0399e-01,  1.5783e+00,  8.5429e-01, -1.6201e+00,\n",
      "          -9.3450e-01,  2.6995e-01,  6.7186e-01,  1.4181e+00,  7.3858e-01],\n",
      "         [-6.4064e-01,  1.1666e+00,  6.8678e-01, -1.2197e-01,  9.7301e-01,\n",
      "           1.8324e+00, -3.7502e-01,  3.1407e-01, -2.2832e-01,  4.3584e-01]],\n",
      "\n",
      "        [[-5.2214e-01, -3.8637e-01, -6.6671e-02, -1.8718e+00,  1.4981e-01,\n",
      "           1.2127e-01,  9.9175e-01, -1.7929e+00, -5.2725e-01, -8.2993e-01],\n",
      "         [-2.6528e-01, -1.7491e+00,  2.7889e-01,  3.8455e-01, -2.1122e-01,\n",
      "           1.0120e-01, -1.4726e+00,  1.9840e+00, -1.7575e+00, -2.9915e-01],\n",
      "         [-1.0477e+00, -1.3501e+00, -2.4942e-01, -6.5950e-01, -6.8669e-01,\n",
      "           2.1898e-01,  1.8586e-01, -9.3126e-01, -2.2479e-01, -1.9185e+00]],\n",
      "\n",
      "        [[ 5.2599e-01, -1.6682e+00, -2.7602e-01,  1.1611e+00, -2.5889e-01,\n",
      "           9.9123e-02, -1.1059e-01, -6.3031e-02, -1.3718e+00, -4.1905e-01],\n",
      "         [ 4.2992e-01,  7.9173e-01, -4.5854e-01,  4.9148e-02,  1.1203e+00,\n",
      "          -8.4525e-01, -6.3008e-02,  4.7827e-01, -3.1843e-01, -3.2342e-01],\n",
      "         [-1.4402e+00,  8.6052e-01, -5.1915e-01,  5.4713e-01, -9.8412e-01,\n",
      "           3.3205e-01, -1.3128e+00, -2.7503e+00, -4.2986e-01, -1.8068e+00]],\n",
      "\n",
      "        [[-2.5032e-01,  4.1707e-01, -4.8269e-01,  1.5547e-02, -3.2729e-01,\n",
      "          -2.3837e-01, -4.4244e-01,  2.7512e-01,  1.4367e+00, -2.4809e-01],\n",
      "         [-9.7232e-01, -5.6442e-01, -5.5746e-02,  5.0109e-01,  5.4768e-01,\n",
      "           8.1686e-01, -1.2662e-03,  5.1533e-02, -5.0900e-01, -9.0054e-01],\n",
      "         [ 2.1603e+00, -7.9490e-01, -6.5575e-01, -3.8299e-01, -8.9461e-01,\n",
      "          -1.2755e+00,  7.1577e-01, -1.6559e+00,  5.2484e-01, -1.2794e+00]],\n",
      "\n",
      "        [[-1.3723e+00, -1.5296e+00,  2.4836e-01,  7.0112e-01,  9.2906e-01,\n",
      "          -1.4513e+00,  4.4398e-01,  1.2787e+00, -5.8555e-01,  1.8864e-01],\n",
      "         [-8.3483e-01,  1.3961e-01,  5.5458e-01, -6.1143e-01,  2.3065e-01,\n",
      "           2.7577e-01, -2.2570e+00, -4.6077e-02,  1.6909e+00,  7.1686e-01],\n",
      "         [ 1.2791e-01, -8.7069e-01, -1.7591e+00,  7.0042e-01, -3.4449e-01,\n",
      "          -2.7313e-01,  7.1792e-01, -7.6194e-01,  1.3712e+00,  1.8802e-01]]],\n",
      "       dtype=torch.float64), tensor([[3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [3],\n",
      "        [3]], dtype=torch.int32)]\n",
      "第 9 个Batch \n",
      "[tensor([[[ 0.8709, -0.7901, -1.4789, -0.0964,  1.1457, -0.0642,  1.2311,\n",
      "          -0.7383,  0.6167, -0.4559],\n",
      "         [-2.0291,  1.5080, -1.1700,  0.4486,  1.2809,  0.1260,  0.3850,\n",
      "           0.9656, -0.0390,  0.9566],\n",
      "         [ 1.6328,  2.8585,  0.7102,  0.7285, -0.8805,  0.1032,  0.6447,\n",
      "          -0.2221, -0.1618,  0.1660]],\n",
      "\n",
      "        [[ 0.9605, -1.2466,  1.4023, -0.1510, -0.2676,  1.3207,  0.6033,\n",
      "          -1.1172,  1.9433, -0.0515],\n",
      "         [ 1.5221, -1.0091, -0.3065,  0.5690,  0.8471, -0.3572,  0.9809,\n",
      "          -0.0733, -0.6611,  0.4799],\n",
      "         [-0.0428,  0.7364,  1.4159, -1.7175,  0.5814,  0.1964, -0.2267,\n",
      "           0.7696, -0.5972, -0.6164]],\n",
      "\n",
      "        [[ 0.8998, -0.2609,  0.6246,  1.9578,  1.7188, -1.2667,  0.8076,\n",
      "           1.0300, -0.0784,  0.3197],\n",
      "         [ 0.5241,  1.8560, -0.0200,  1.2982, -0.3366, -1.3749, -0.4042,\n",
      "           1.2611, -0.5126,  0.2200],\n",
      "         [-1.7577,  1.0028,  0.5529, -1.4688, -0.1058,  1.5165,  1.5137,\n",
      "          -0.8366,  0.0795,  0.2757]],\n",
      "\n",
      "        [[-0.9608, -1.2207, -0.7676, -1.1971, -0.0207,  0.8582,  1.5307,\n",
      "           0.1603, -0.0731, -1.7888],\n",
      "         [-2.7782, -1.4237, -0.7878,  0.2441, -0.4907, -0.9918, -1.1921,\n",
      "          -1.1391,  2.0167,  0.9573],\n",
      "         [-1.7440, -0.6473, -0.5495,  0.0370,  0.0746, -0.6159, -0.2768,\n",
      "          -1.7208, -0.7289, -1.5608]],\n",
      "\n",
      "        [[-0.3970, -2.6007,  0.3353, -0.9591,  0.7765, -0.6974,  0.2804,\n",
      "           2.0103,  1.0839,  1.9008],\n",
      "         [-0.9839, -0.8165,  1.0935,  0.1768, -0.5347, -1.4411,  0.8348,\n",
      "          -0.9115,  0.6108,  0.0101],\n",
      "         [-1.1866, -0.3055, -0.2879,  0.2228, -0.3578, -2.9971,  0.2326,\n",
      "          -0.1810,  0.2027, -2.2666]]], dtype=torch.float64), tensor([[3],\n",
      "        [5],\n",
      "        [2],\n",
      "        [4],\n",
      "        [4]], dtype=torch.int32)]\n",
      "第 10 个Batch \n",
      "[tensor([[[-0.5963,  1.2567,  0.5359, -0.4420, -0.8003,  0.9363,  0.0055,\n",
      "           1.3395,  0.7272,  0.6201],\n",
      "         [ 0.1669, -0.6037,  0.9674, -1.4896, -2.1189, -1.5211,  1.0139,\n",
      "          -0.4225,  0.8618,  0.0352],\n",
      "         [ 1.1310, -1.6743, -1.2841,  0.5414, -0.5972, -0.8980, -0.2749,\n",
      "          -0.8151, -0.3849,  1.2985]],\n",
      "\n",
      "        [[-0.4018,  2.1061,  1.8805, -0.4380,  1.4920, -0.6180,  0.7227,\n",
      "           1.3750,  0.6798,  1.6252],\n",
      "         [-0.4738,  1.8661,  0.9733, -0.9393, -0.1914,  0.6447, -0.2075,\n",
      "          -0.2475, -0.3157,  1.0103],\n",
      "         [ 1.7660, -1.3461, -0.0565, -1.3891, -0.2085,  0.4665,  0.7021,\n",
      "          -1.0939,  1.0098, -0.8662]],\n",
      "\n",
      "        [[-1.3442,  1.1238, -0.9469, -0.7816, -2.6661, -2.2047,  0.9071,\n",
      "          -0.5736, -0.8904,  0.2574],\n",
      "         [ 0.9740, -0.9567,  0.3392,  0.7354,  0.3423,  0.1701,  1.0860,\n",
      "           0.1218,  1.1665,  0.6451],\n",
      "         [-0.0061, -0.2965,  2.9782, -0.1822, -0.6489,  1.2825, -0.5519,\n",
      "           0.5751,  0.6385,  1.9233]],\n",
      "\n",
      "        [[-0.1806, -0.3235, -0.8803,  0.0859, -0.2671,  0.8481,  0.4340,\n",
      "           2.0029,  1.8363,  0.7378],\n",
      "         [-0.4777,  0.3214, -0.0989,  0.0603, -0.3880, -1.3584,  0.3385,\n",
      "          -1.0516, -0.3866, -1.0971],\n",
      "         [-2.4667, -0.5785, -1.8920, -0.9923,  0.2123, -0.0700,  1.2326,\n",
      "          -0.3605,  0.4809, -0.7242]],\n",
      "\n",
      "        [[-1.5639, -0.1750, -0.3350,  0.8567,  1.1407,  1.1940, -0.4790,\n",
      "           0.6446, -0.6918,  3.9456],\n",
      "         [-0.8726,  1.2506,  0.8967, -0.6860,  0.4657,  1.4339,  0.5104,\n",
      "           2.1967, -0.3002,  0.1761],\n",
      "         [ 0.3291, -0.6200,  1.0180,  1.7202, -0.8191, -0.4687,  1.0281,\n",
      "          -0.0676, -0.6047, -2.4247]]], dtype=torch.float64), tensor([[0],\n",
      "        [4],\n",
      "        [4],\n",
      "        [3],\n",
      "        [2]], dtype=torch.int32)]\n",
      "第 11 个Batch \n",
      "[tensor([[[ 0.8749, -1.1422,  0.2591,  0.2737, -0.7894, -0.0530, -0.5102,\n",
      "          -0.2174,  0.5994,  0.9240],\n",
      "         [-0.1523,  2.0906, -1.3606,  0.1877,  1.0112, -0.8758, -1.0226,\n",
      "           1.0975,  0.2195,  0.0871],\n",
      "         [-0.1503, -0.5556, -0.0877,  0.3565,  2.4068, -0.3916, -1.2838,\n",
      "           0.5377, -0.5098, -0.6009]],\n",
      "\n",
      "        [[-0.3246, -1.0785,  1.9727, -0.5752,  0.5417,  0.9253,  0.1096,\n",
      "          -0.9036, -0.7518,  0.0310],\n",
      "         [-0.5500,  1.3074, -0.6310, -0.2122,  0.7581, -0.2971, -0.8723,\n",
      "           0.0888, -1.1083,  0.8603],\n",
      "         [ 0.4955,  1.4371,  1.3023, -0.5387, -0.6794, -0.8027,  0.4242,\n",
      "           0.7773,  0.2547,  0.4937]],\n",
      "\n",
      "        [[-0.0401,  0.9648, -1.2421,  0.9259, -1.5052,  0.1651, -0.2464,\n",
      "          -0.6448, -0.3069,  0.9209],\n",
      "         [ 0.0100, -0.2253,  0.2312,  0.4386,  0.5928, -0.1939, -1.8784,\n",
      "           0.5140, -0.8138, -0.5087],\n",
      "         [-1.5609, -1.1985, -0.1672,  0.0803,  0.0750, -0.3113,  1.0022,\n",
      "          -0.4182, -0.7101, -1.0872]],\n",
      "\n",
      "        [[ 1.6743, -0.1088,  0.8493, -0.1019, -0.0747, -0.0424, -0.1296,\n",
      "           0.1885,  1.2648, -0.1861],\n",
      "         [-0.1751, -0.8148,  0.0716,  1.2574, -0.0247,  1.1933,  0.3415,\n",
      "          -0.5254,  1.2236, -0.0812],\n",
      "         [ 1.2108,  0.0520, -0.3983,  0.2023,  1.7991, -0.8611, -0.2089,\n",
      "           0.9785, -0.5612, -0.7101]],\n",
      "\n",
      "        [[ 0.0866, -0.2128,  1.2280, -0.7317, -0.6931, -0.3195, -1.5446,\n",
      "          -1.8283,  0.0064,  0.3286],\n",
      "         [ 1.8030, -0.8234,  0.4600,  0.3003,  0.5771,  0.0697,  0.7319,\n",
      "          -0.7804, -0.3448, -0.4368],\n",
      "         [ 0.4080, -0.0665, -1.7367, -1.3661, -0.3806,  0.3014, -0.0599,\n",
      "           0.0865, -1.0006, -0.2317]]], dtype=torch.float64), tensor([[3],\n",
      "        [3],\n",
      "        [5],\n",
      "        [0],\n",
      "        [5]], dtype=torch.int32)]\n",
      "第 12 个Batch \n",
      "[tensor([[[-0.2486,  0.0187, -0.9267,  0.5687,  0.0316,  1.8365, -0.6928,\n",
      "          -0.3094, -1.1646, -1.6991],\n",
      "         [ 1.7072,  1.2584, -0.4794,  0.5146,  0.6566, -0.5943, -0.7954,\n",
      "           0.7190, -1.0893, -0.6320],\n",
      "         [ 0.9881, -0.4523, -1.2181, -0.9970,  0.5939, -0.0158,  0.7638,\n",
      "          -1.0787, -0.0651,  0.2986]],\n",
      "\n",
      "        [[-0.8001,  0.3683, -1.0915, -0.7268,  0.9762, -1.2403, -1.5997,\n",
      "          -0.2668,  0.1181, -0.9132],\n",
      "         [ 0.7976,  0.1993,  0.2155,  0.2699,  0.1950, -0.2085,  1.3340,\n",
      "           2.1257,  0.5479, -0.1881],\n",
      "         [ 0.3928, -0.6214,  0.7390,  0.6800,  0.5157, -0.9172,  1.9327,\n",
      "           1.4087, -1.1149,  0.2947]],\n",
      "\n",
      "        [[ 0.3801, -0.8357,  0.3765,  1.4153,  0.3834,  1.4883, -0.2363,\n",
      "          -0.0975, -1.3774, -0.6395],\n",
      "         [ 0.6548,  2.5587,  0.8459, -0.6849,  0.6154, -0.8756,  2.4440,\n",
      "          -0.3632, -0.5817, -1.5395],\n",
      "         [-0.4304, -1.6430, -1.9374, -0.3044, -0.3952, -1.2936,  0.6544,\n",
      "          -0.4498,  1.0207,  0.2118]],\n",
      "\n",
      "        [[-0.0271,  0.7145, -0.7281,  0.0587, -0.0041, -0.1194,  0.2393,\n",
      "          -0.4217,  1.1278, -0.4591],\n",
      "         [ 1.6479, -1.3090,  0.1279,  1.5867, -0.3817,  1.5907,  0.8100,\n",
      "          -0.1185,  0.6852,  0.8137],\n",
      "         [ 0.1461, -0.7329, -0.2139, -0.7900,  0.5716, -1.4353, -1.4812,\n",
      "          -1.0599,  0.4085,  2.0480]],\n",
      "\n",
      "        [[ 0.4170,  0.8654, -0.6161,  0.1520, -2.2998, -0.1183, -0.1483,\n",
      "           0.5263, -0.8085, -1.6461],\n",
      "         [ 0.9144, -0.5356, -0.4787, -1.6349, -2.1395,  0.5496, -0.8109,\n",
      "           0.1825,  0.3190,  1.5765],\n",
      "         [-0.4488, -0.1243, -0.9289,  0.2481, -0.2082,  0.4841, -0.9794,\n",
      "          -1.5957,  1.0379, -0.2863]]], dtype=torch.float64), tensor([[2],\n",
      "        [0],\n",
      "        [4],\n",
      "        [0],\n",
      "        [1]], dtype=torch.int32)]\n",
      "第 13 个Batch \n",
      "[tensor([[[-1.0331,  0.7678,  0.9204,  1.5904, -0.2694, -0.3173,  1.0601,\n",
      "           0.2834, -0.8552,  1.4086],\n",
      "         [-0.8804,  0.6278,  0.5260, -1.4553, -0.1812,  0.2841, -0.9927,\n",
      "           0.9540, -0.8106, -0.3721],\n",
      "         [-1.3165, -1.1219, -1.9285,  0.6265, -0.5539, -0.2115,  0.1672,\n",
      "           0.2745,  1.2939, -0.6496]],\n",
      "\n",
      "        [[ 0.1385,  0.4068,  1.2215, -0.4296,  0.6535,  0.1224,  0.6332,\n",
      "          -0.7107,  2.1146, -0.2166],\n",
      "         [-0.5371, -0.6121,  0.8866, -0.5338,  0.1897,  1.5594, -0.7018,\n",
      "          -1.7331, -0.3901, -0.3984],\n",
      "         [-0.3982, -0.2631,  0.0683,  1.9257, -1.8430, -0.9068,  0.8909,\n",
      "           1.8274,  1.2345,  0.1637]],\n",
      "\n",
      "        [[ 1.5444,  0.4480,  1.2115, -1.0744, -0.0941, -0.5957,  2.0063,\n",
      "          -1.0655, -1.5938, -1.2358],\n",
      "         [ 1.5356, -0.3569,  0.0466,  0.0457,  0.5572, -0.6076,  0.4535,\n",
      "          -2.0457, -0.5183,  0.7077],\n",
      "         [ 0.7301,  2.5882, -0.0502,  1.3577, -1.0116, -1.5892,  0.2767,\n",
      "           1.8522, -0.5088,  0.8174]],\n",
      "\n",
      "        [[-1.1622, -0.2369,  1.3552,  0.9923, -0.3115, -0.0213, -1.1956,\n",
      "          -0.7571, -0.2906,  1.2353],\n",
      "         [-0.6604, -0.7556,  0.3709,  0.1432,  0.0247, -0.4674,  0.2215,\n",
      "          -0.3746,  0.0362, -1.1245],\n",
      "         [ 0.9500, -1.1444,  1.5617, -0.8144, -0.1433,  0.4360,  0.0893,\n",
      "           1.6168, -0.2356, -0.9721]],\n",
      "\n",
      "        [[-0.2092,  1.2182, -0.5130,  0.4535,  1.9540, -0.3823,  1.7881,\n",
      "           0.1044, -1.7530, -0.9511],\n",
      "         [ 0.6607, -0.5704, -0.7847, -0.8039,  0.0673,  0.6672, -2.7785,\n",
      "          -0.5821, -0.1606,  0.5084],\n",
      "         [-1.6438,  0.7798,  0.2720,  1.0605,  1.9734,  0.6271,  0.6587,\n",
      "           0.6842, -0.1360, -1.7239]]], dtype=torch.float64), tensor([[2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [4]], dtype=torch.int32)]\n",
      "第 14 个Batch \n",
      "[tensor([[[-1.8831e+00, -1.2778e+00,  9.6487e-01, -2.6196e-01,  1.0138e-01,\n",
      "           1.3572e+00, -4.4614e-01,  1.7419e+00, -1.3699e+00,  5.0411e-01],\n",
      "         [ 3.9880e-01,  1.2966e+00,  1.2174e-01,  1.2775e+00, -7.6223e-01,\n",
      "          -4.8299e-01,  4.5207e-01,  4.6039e-01, -2.5747e+00, -4.2994e-01],\n",
      "         [ 2.6675e+00,  6.6050e-01, -5.2349e-01,  2.7695e+00,  1.5951e-01,\n",
      "           9.7562e-02,  4.5296e-01, -3.2900e-01, -1.3429e+00,  5.4895e-01]],\n",
      "\n",
      "        [[ 8.0974e-01,  2.3467e+00,  6.9933e-01,  7.0394e-01,  6.3585e-01,\n",
      "           5.3351e-01,  1.2765e+00,  1.3648e+00, -1.1239e+00,  6.9488e-01],\n",
      "         [ 2.5777e-02, -1.0130e-01, -4.2663e-01, -1.8196e-01,  1.2802e+00,\n",
      "          -1.0764e+00,  4.6832e-01,  8.7760e-01, -2.0474e-02,  1.2260e+00],\n",
      "         [-8.6371e-01, -2.6112e-01,  1.1968e+00,  3.6548e-01, -1.2422e-01,\n",
      "          -1.0030e+00,  1.3561e+00, -4.8139e-01,  9.6848e-01, -1.2521e+00]],\n",
      "\n",
      "        [[ 1.4578e+00,  1.4007e+00, -4.1358e-01,  1.4500e+00,  2.6171e-01,\n",
      "          -1.2629e+00,  1.5589e+00, -7.5511e-01, -3.2299e-01, -1.4283e+00],\n",
      "         [-7.9206e-01,  1.8439e+00, -3.7557e-01, -5.1064e-01,  1.7191e+00,\n",
      "          -5.4719e-02,  1.2931e+00, -1.1654e+00, -5.5435e-01, -8.4164e-01],\n",
      "         [ 1.5410e+00,  9.3669e-01, -4.6910e-01, -4.4797e-01,  6.8429e-03,\n",
      "           1.5544e+00, -1.0921e-01, -1.9937e+00, -5.9208e-01, -1.3850e+00]],\n",
      "\n",
      "        [[-6.7384e-01, -1.6555e+00,  7.6806e-01,  1.2829e+00,  8.9516e-01,\n",
      "           1.8130e-01,  6.1903e-01, -5.9428e-01,  1.5364e+00,  7.5152e-01],\n",
      "         [ 1.8051e+00, -2.6035e-01, -3.9272e-01,  9.6182e-01,  2.1301e-01,\n",
      "          -8.5444e-05,  4.8070e-01, -4.8090e-01,  6.6775e-01,  8.6739e-01],\n",
      "         [-1.5267e+00, -1.6650e+00, -1.8349e+00, -8.0716e-01, -2.3577e+00,\n",
      "           3.0761e-01,  1.1334e+00, -1.8813e-01, -4.4305e-01, -3.5500e-01]],\n",
      "\n",
      "        [[ 1.3284e+00, -2.3715e-01,  1.9856e-03, -6.0227e-01, -7.8676e-01,\n",
      "           2.7747e-02,  6.8617e-01, -6.4503e-01, -7.8201e-01, -6.6247e-01],\n",
      "         [ 7.9261e-01,  3.2618e-01, -1.4357e+00, -3.9920e-01,  6.1515e-02,\n",
      "          -1.9076e+00,  3.4716e-01,  2.6496e-01, -1.1353e+00, -2.3565e-01],\n",
      "         [-1.0185e-01,  7.6394e-03, -2.4557e-01, -9.7330e-01,  4.6963e-01,\n",
      "          -1.2638e+00,  4.6269e-01, -1.1632e+00, -4.1820e-01,  3.2696e-01]]],\n",
      "       dtype=torch.float64), tensor([[2],\n",
      "        [2],\n",
      "        [5],\n",
      "        [1],\n",
      "        [4]], dtype=torch.int32)]\n",
      "第 15 个Batch \n",
      "[tensor([[[ 1.3295,  0.7948,  1.0093, -2.2373, -0.0052, -1.5027, -0.4331,\n",
      "          -1.4540,  0.0510, -0.4577],\n",
      "         [ 0.7236,  0.7766,  0.2276,  0.9606, -0.6943,  1.9622,  2.0998,\n",
      "          -1.0685,  0.3413,  0.2951],\n",
      "         [ 0.5825,  0.4513, -1.0701, -0.6911, -0.8328,  0.7916, -0.2314,\n",
      "          -0.4438, -0.1022,  0.0751]],\n",
      "\n",
      "        [[ 2.1341, -0.5432,  1.0399, -0.6218,  0.8143,  0.7147,  0.8798,\n",
      "          -0.2306,  0.3811, -1.5206],\n",
      "         [-1.7231,  0.4183, -0.8888,  0.0920,  0.0552,  0.2086, -1.8265,\n",
      "          -0.0613,  0.2754, -1.8049],\n",
      "         [ 0.7628,  1.3807, -1.6412, -1.7414, -0.1225, -0.4877,  0.1744,\n",
      "          -1.5600, -1.4199,  0.2130]],\n",
      "\n",
      "        [[ 0.7316,  1.0082, -0.9975, -0.6804,  0.3295,  2.1050, -0.7152,\n",
      "          -0.0835,  0.9718,  0.0849],\n",
      "         [-1.1581,  2.2742, -0.7191, -0.1625, -1.5761, -1.2525, -0.9713,\n",
      "          -1.1614, -0.2613, -0.3311],\n",
      "         [-0.4119,  0.7482,  0.5434, -0.8849, -0.2444, -0.5347, -0.7700,\n",
      "          -0.6212, -0.4499,  0.6313]],\n",
      "\n",
      "        [[ 0.0437,  1.3592, -0.9289,  0.3429,  0.0652, -2.1405, -0.1966,\n",
      "           0.5339, -0.3681, -0.3405],\n",
      "         [-1.3595, -0.6711, -0.7025,  0.4012,  0.5866,  1.8305, -0.1013,\n",
      "          -0.0913,  1.1529,  0.4571],\n",
      "         [-0.4626,  0.3411,  0.5653,  1.8679,  0.3800,  1.0986, -0.4720,\n",
      "           0.9197, -0.6511,  1.1871]],\n",
      "\n",
      "        [[-0.1014,  1.2360,  0.3772, -1.0156,  1.6263,  0.7922,  0.5097,\n",
      "           0.7930,  0.0863,  0.6230],\n",
      "         [-0.4681, -0.1196,  0.2724,  0.3366,  0.1044, -0.2968, -0.3098,\n",
      "           0.1973, -0.1482, -2.0075],\n",
      "         [-0.0593, -0.8660, -0.8910,  1.5666,  0.8606, -0.4713,  0.8810,\n",
      "           1.0548,  0.8678, -0.9633]]], dtype=torch.float64), tensor([[0],\n",
      "        [5],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]], dtype=torch.int32)]\n",
      "第 16 个Batch \n",
      "[tensor([[[-0.1387, -0.1378, -0.4426, -0.4024, -1.9599,  0.7894, -1.8825,\n",
      "           1.7588,  0.5057,  0.6941],\n",
      "         [ 0.9415,  0.9415, -1.5377, -0.7049,  0.0754, -0.8757, -1.6195,\n",
      "          -1.1612, -0.8419, -0.5615],\n",
      "         [ 1.2492, -1.0840,  0.3661, -0.1981,  0.1369,  0.5760,  0.9790,\n",
      "           0.6402, -2.0673,  0.6146]],\n",
      "\n",
      "        [[-0.5147, -1.5793, -0.9492,  0.9377,  0.3823, -1.0301,  0.4916,\n",
      "           0.0219, -0.1144,  0.3462],\n",
      "         [ 0.5540,  1.8163, -1.2126, -0.4285,  0.8663,  0.6830, -0.2864,\n",
      "           0.0063,  1.1334,  0.2201],\n",
      "         [ 0.3197,  0.1771, -0.1498, -1.0396,  1.0246,  2.0046,  0.3115,\n",
      "          -1.0670,  0.2442, -1.8789]],\n",
      "\n",
      "        [[-1.6923,  1.5139, -0.1123, -1.8745, -0.6296,  0.6403, -0.2255,\n",
      "           0.2306, -0.3927, -0.5948],\n",
      "         [ 1.8715, -0.2030, -0.4952,  2.3092,  0.0229, -0.7460,  0.3828,\n",
      "           0.8821,  0.8727,  0.2124],\n",
      "         [-0.1908,  0.6711,  0.1929, -1.0749, -1.3589,  0.5145,  2.2001,\n",
      "          -1.9942, -1.9600,  0.1471]],\n",
      "\n",
      "        [[ 0.7251, -0.8512,  0.4877, -0.5182,  0.6046, -2.6028, -0.2704,\n",
      "           0.0366, -0.3629,  1.7918],\n",
      "         [-1.4171, -0.4809, -0.0153,  1.0743,  0.3310, -0.2712, -0.3287,\n",
      "           0.1721,  0.3579,  0.4853],\n",
      "         [ 1.2273, -0.4926, -0.3727, -1.0056,  0.2418, -1.3713,  1.1192,\n",
      "          -0.9253,  0.8102, -0.4748]],\n",
      "\n",
      "        [[ 0.3836,  0.0731, -1.5656, -1.7993, -0.8100, -1.4915, -1.1910,\n",
      "          -0.7087,  0.0495, -1.0706],\n",
      "         [ 1.8150, -0.0088,  0.6239,  0.4815, -1.0258,  0.4998, -0.5467,\n",
      "           0.8177, -1.2467,  1.3216],\n",
      "         [-0.3753,  0.6075, -1.2044, -0.6951,  0.3196,  1.1391, -0.0528,\n",
      "           0.9199,  1.0517,  1.7705]]], dtype=torch.float64), tensor([[0],\n",
      "        [4],\n",
      "        [3],\n",
      "        [3],\n",
      "        [5]], dtype=torch.int32)]\n",
      "第 17 个Batch \n",
      "[tensor([[[ 2.8305, -0.7733,  0.9616, -0.1314,  2.1867, -0.3367,  1.4247,\n",
      "           2.9995, -2.1161, -0.2387],\n",
      "         [ 2.5997,  0.2189, -0.0668, -0.6205, -1.2236,  1.0894,  0.4670,\n",
      "          -0.7637, -0.1144,  0.6006],\n",
      "         [ 0.3219,  0.0587,  0.0405, -0.0965, -0.3596, -0.1914, -1.4644,\n",
      "           0.4113,  2.4608,  1.6571]],\n",
      "\n",
      "        [[-0.3876, -1.7979,  0.6625,  0.7532,  0.4976, -0.5552, -1.0446,\n",
      "          -0.6214, -0.2353, -0.1708],\n",
      "         [-0.7675,  0.7697,  0.3167,  2.0004,  0.0828, -0.8133, -1.2535,\n",
      "          -0.6247,  1.0097,  0.6335],\n",
      "         [ 0.4382, -0.6753, -0.1603, -0.6491, -0.2831,  1.6529, -0.6801,\n",
      "          -0.4539,  0.5371,  1.6240]],\n",
      "\n",
      "        [[ 1.3289, -0.0429, -0.0947,  0.2062, -0.0250, -1.9846, -0.8438,\n",
      "          -0.2908,  1.7081, -1.9083],\n",
      "         [-0.8481, -0.1104, -0.9568, -0.9212,  0.6865,  0.3790,  1.1562,\n",
      "          -0.7139,  0.8592, -1.9722],\n",
      "         [ 2.2417,  1.1649, -0.1075,  0.1175, -0.4627, -0.6525,  2.4785,\n",
      "          -0.0462, -0.4335, -1.2640]],\n",
      "\n",
      "        [[ 2.1516,  0.2133,  0.8255, -1.2146, -0.4933,  1.0497, -0.0459,\n",
      "           0.8074, -0.0523, -1.2666],\n",
      "         [ 2.3068, -0.3106,  0.2243, -0.7980,  1.0488, -0.8406, -0.9392,\n",
      "          -1.4976, -0.5330, -1.7024],\n",
      "         [-0.0932, -0.4622, -1.1206,  0.8512,  0.0228, -1.4917, -1.8864,\n",
      "           0.7206,  0.0673, -0.5106]],\n",
      "\n",
      "        [[-1.2880,  2.4739, -1.0732,  1.7229,  1.1263,  0.3027, -1.1416,\n",
      "          -1.4414, -0.3253, -1.1007],\n",
      "         [ 0.3917, -2.3326, -0.0595,  0.0890, -0.6478, -0.1907,  0.3671,\n",
      "           0.1524,  0.3876, -0.2213],\n",
      "         [ 1.2380, -0.8271, -0.7212,  0.1526,  1.2627,  1.6915,  2.0799,\n",
      "           1.7343, -1.4956,  0.6886]]], dtype=torch.float64), tensor([[4],\n",
      "        [3],\n",
      "        [2],\n",
      "        [5],\n",
      "        [4]], dtype=torch.int32)]\n",
      "第 18 个Batch \n",
      "[tensor([[[ 0.1759,  0.4597,  1.6673,  1.2819, -0.4483, -0.1649, -2.4297,\n",
      "          -0.6954,  0.0698,  0.9635],\n",
      "         [ 0.3600,  2.0152,  0.8489,  0.4938, -0.0830,  0.0737, -1.1972,\n",
      "           0.0241, -0.6234, -1.1991],\n",
      "         [-1.6346, -0.3559,  1.9251,  1.2836,  0.4658, -0.0981,  0.8273,\n",
      "          -0.0594, -0.0780, -1.8383]],\n",
      "\n",
      "        [[-0.1069, -0.3994,  1.0789,  0.0354, -1.4266, -0.2821, -0.5042,\n",
      "          -2.3301,  1.0004,  1.1280],\n",
      "         [-0.0299, -2.1641, -0.5637, -0.1260,  0.1190,  1.0045, -0.1909,\n",
      "           0.9134, -0.1499,  0.7028],\n",
      "         [ 0.0360,  1.6404, -0.8304, -1.4296,  0.0984, -1.5339,  0.2075,\n",
      "          -0.3917,  0.4204, -1.5259]],\n",
      "\n",
      "        [[ 1.0917,  0.4771,  0.9914,  1.0565,  0.0040, -1.8628,  1.4074,\n",
      "          -0.4935, -0.5071,  0.3847],\n",
      "         [-1.3221, -0.2368,  0.3784,  0.3070, -0.3858, -0.4613, -0.7336,\n",
      "           0.3339,  0.7672,  0.0743],\n",
      "         [ 0.1692, -0.2498, -0.9317,  0.8377, -1.9176,  0.2482,  1.5264,\n",
      "           1.1034, -2.0450, -0.2053]],\n",
      "\n",
      "        [[-1.0490, -0.1430,  0.1528, -0.5119, -0.1319,  1.8096, -0.1682,\n",
      "          -0.1965,  0.9459,  2.2870],\n",
      "         [ 0.1163, -0.5132,  0.4183, -0.9297, -0.3846, -0.7250, -0.5630,\n",
      "           2.4522, -0.9293, -1.6303],\n",
      "         [-0.8886,  0.8732, -0.5757,  0.4799, -0.5185,  0.3991,  0.2299,\n",
      "           0.3490, -0.0886,  0.8398]],\n",
      "\n",
      "        [[ 0.2635, -0.4976,  0.0351, -0.2754,  2.0393,  0.0630,  0.1934,\n",
      "          -0.2812, -0.3247, -0.2497],\n",
      "         [-0.6556, -0.3518,  0.0837,  1.5807, -0.6449, -0.2812, -0.3074,\n",
      "           1.0879, -0.3511, -1.5218],\n",
      "         [ 0.0873, -2.4815,  0.7322, -0.8480,  0.3619,  0.6864,  0.2371,\n",
      "          -0.6637,  0.1836,  1.7176]]], dtype=torch.float64), tensor([[3],\n",
      "        [4],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2]], dtype=torch.int32)]\n",
      "第 19 个Batch \n",
      "[tensor([[[ 2.3362e-01,  6.1597e-01,  9.8933e-04,  3.7298e-01, -5.6701e-01,\n",
      "          -1.7045e+00, -5.4830e-01,  1.1333e+00, -7.1757e-01,  5.5733e-01],\n",
      "         [-1.2676e+00,  1.6952e+00,  2.6994e-01, -9.2099e-01, -1.0910e+00,\n",
      "          -1.3458e+00,  5.8945e-02,  5.7516e-02, -3.8298e-01,  3.0620e-01],\n",
      "         [ 6.7234e-01,  1.6726e+00,  2.8030e-02,  1.0764e+00,  3.4095e-03,\n",
      "           1.7870e-01, -4.6543e-01, -1.1706e+00, -1.8748e-01, -9.7308e-01]],\n",
      "\n",
      "        [[-8.4601e-01, -1.2267e-02,  2.6876e-01,  5.4652e-01,  1.4452e+00,\n",
      "           1.4397e+00, -1.1496e+00, -6.7270e-01, -2.0152e+00, -3.5457e-01],\n",
      "         [-4.2294e-01, -7.0251e-02,  1.2993e+00,  9.5108e-01,  1.4118e+00,\n",
      "           7.0071e-01,  6.3474e-01, -5.8975e-01, -2.4949e+00, -3.8309e-01],\n",
      "         [-8.8142e-01, -5.6056e-01,  8.8714e-01, -8.2614e-01,  2.3124e+00,\n",
      "           5.8005e-01, -2.3541e+00, -3.6049e-01, -1.5856e+00, -5.8257e-01]],\n",
      "\n",
      "        [[-6.6500e-01, -1.8652e+00, -2.7342e-01,  8.7448e-01, -7.6779e-01,\n",
      "          -1.3178e+00,  1.0958e+00, -9.0556e-01,  4.8190e-03,  1.1275e+00],\n",
      "         [-1.1703e+00, -2.4215e-01, -1.0727e+00, -1.5388e-02, -3.1739e-01,\n",
      "          -1.2681e+00, -1.0426e+00, -1.1718e+00, -1.0919e-01,  1.4476e+00],\n",
      "         [ 1.3115e-01,  8.7373e-01, -6.5596e-01, -8.0818e-01, -8.6850e-01,\n",
      "           2.0468e+00,  4.5248e-01, -1.1618e+00,  4.4834e-01, -4.9434e-01]],\n",
      "\n",
      "        [[ 1.5333e-02,  7.9503e-01, -2.0908e+00, -9.3809e-01,  3.4906e-01,\n",
      "           6.6645e-01,  1.2842e-01, -1.0455e-01,  2.6798e-01, -1.7941e-01],\n",
      "         [ 1.1078e+00,  1.5865e-01,  5.3361e-02,  8.8220e-01,  2.0352e+00,\n",
      "          -1.7988e+00,  1.1013e+00, -1.5224e+00,  8.4751e-01, -4.6754e-01],\n",
      "         [-7.4587e-01, -7.3626e-01, -1.3579e-01, -7.7555e-01, -9.8268e-01,\n",
      "          -8.2316e-01, -3.0877e-01,  2.1580e-01,  1.1113e+00,  1.1056e+00]],\n",
      "\n",
      "        [[-2.8321e-01, -1.9104e-02,  1.7689e+00, -7.6713e-02,  5.0915e-02,\n",
      "          -1.7225e+00,  2.3124e-01, -1.0766e+00,  1.3340e+00, -8.5688e-01],\n",
      "         [-7.6256e-01,  6.5435e-01,  2.0074e-01, -2.4792e-01, -5.9594e-01,\n",
      "           1.5894e+00,  8.8458e-01, -1.5882e-02,  8.3565e-01,  4.8899e-01],\n",
      "         [ 6.1850e-01, -7.6660e-01,  8.0023e-01,  1.4583e-01, -3.8996e-02,\n",
      "           7.3777e-02, -1.5397e+00, -8.6300e-01, -1.5117e+00, -7.0100e-01]]],\n",
      "       dtype=torch.float64), tensor([[0],\n",
      "        [1],\n",
      "        [4],\n",
      "        [3],\n",
      "        [2]], dtype=torch.int32)]\n"
     ]
    }
   ],
   "source": [
    "#train datasets \n",
    "train_loader = get_loaders()\n",
    "\n",
    "for i, data in enumerate(train_loader):\n",
    "    print(\"第 {} 个Batch \\n{}\".format(i, data))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Shape of `queries`: (`batch_size`, no. of queries, `d`)\n",
    "        # Shape of `keys`: (`batch_size`, no. of key-value pairs, `d`)\n",
    "        # Shape of `values`: (`batch_size`, no. of key-value pairs, value\n",
    "        # dimension)\n",
    "        # Shape of `valid_lens`: (`batch_size`,) or (`batch_size`, no. of queries)\n",
    "        \n",
    "    def forward(self, queries, keys, values):\n",
    "        d = queries.shape[-1]\n",
    "        # Set `transpose_b=True` to swap the last two dimensions of `keys`\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        return torch.bmm(self.dropout(scores), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "'''\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "num_layers = 2\n",
    "dropout = 0.5\n",
    "\n",
    "'''\n",
    "class AttentionGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout,sequence_length,classes, **kwargs ):\n",
    "        super(AttentionGRU,self).__init__(**kwargs)\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length \n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.classes = classes\n",
    "        # -> x needs to be: (batch_size, seq, input_size) #rnn = nn.GRU(10, 20, 2)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, bidirectional=False)\n",
    "        self.attention =  DotProductAttention(dropout)\n",
    "        self.fc = nn.Linear(hidden_size*sequence_length,classes)\n",
    "\n",
    "    \n",
    "    def forward(self,X):\n",
    "        h0 = torch.randn(2, 5, 20) #h0 = torch.randn(2, 3, 20)\n",
    "        output, hn = self.gru(X, h0)\n",
    "        output = self.attention(output,output,output)\n",
    "        output = output.view(5, -1)\n",
    "        output = self.fc(output)\n",
    "    \n",
    "        return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#train models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#二分类\n",
    "\n",
    "'''\n",
    "loss损失函数\n",
    "nn.BCEWithLogitsLoss()二分类\n",
    "nn.CrossEntropyLoss()多分类\n",
    "https://blog.csdn.net/weixin_35757704/article/details/118388424\n",
    "\n",
    "'''\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：100, Loss: -15609.322265625\n",
      "训练次数：200, Loss: -23130.73828125\n"
     ]
    }
   ],
   "source": [
    "#二分类\n",
    "total_train_step = 0\n",
    "epoch = 10\n",
    "for i in  range(epoch):\n",
    "    model.train()\n",
    "    for i,(x,target) in enumerate(train_loader):\n",
    "        #expected scalar type Double but found Float\n",
    "        \n",
    "        x = x.to(torch.float32)\n",
    "        #print(type(x),x)\n",
    "        target = target.to(torch.float32)\n",
    "        #print(type(target), target)\n",
    "        outputs = model(x)\n",
    "        #print(type(outputs), outputs)\n",
    "        \n",
    "        loss = loss_function(outputs,target)\n",
    "        \n",
    "        #优化器优化模型参数\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_step = total_train_step + 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}, Loss: {}\".format(total_train_step, loss.item()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datalader dataset\n",
    "1.https://shashikachamod4u.medium.com/excel-csv-to-pytorch-dataset-def496b6bcc1\n",
    "2.https://colab.research.google.com/github/biswajitsahoo1111/blog_notebooks/blob/master/Reading_multiple_csv_files_in_PyTorch.ipynb\n",
    "3.\n",
    "4.\n",
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch \n",
    "from torch.utils.data import Dataset \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self,file_name):\n",
    "        \n",
    "        #read csv file and load raw data into variables\n",
    "        file_out = pd.read_csv(file_name)\n",
    "        x = file_out.iloc[1:216,1:12].values\n",
    "        y = file_out[1:216,12].values\n",
    "        \n",
    "        #Feature Scaling\n",
    "        sc = StandardScaler()\n",
    "        x_train = sc.fit_transform(x)\n",
    "        y_train = y\n",
    "        \n",
    "        #converting to torch tensors\n",
    "        self.X_train = torch.tensor(x_train, dtype = torch.float32)\n",
    "        self.y_train = torch.tensor(y_train)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.X_train[idx],self.X_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
